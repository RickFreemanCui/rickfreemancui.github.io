[{"content":"This is a project that runs in the Lattice lab, starting from Dalao Hanlin, who first envisioned the possibility of substituting LWE-based cryptography with LPN (spoiler alert we currently do not know how to achieve this goal). A significant goal is to construct a digital signature a la Dilithium at least in terms of performance.\nAlas, the Fiat-Shamir with Abort technique does not work directly with LPN, although some folks have come up with variants of the LPN assumption to accommendate with this technqiue (e.g. (“Durandal: A Rank Metric Based Signature Scheme SpringerLink” n.d.)). We consider the status quo unsatisfactory.\nLuckily, the MPC-in-the-Head branch is constantly being optimized, with the state-of-the-art proposed under the name \u0026ldquo;VOLE-in-the-Head\u0026rdquo; (Baum et al. 2023) in Crypto 2023. We tried this new framework on the RSD problem at the first moment. Anyway, this framework proves to be effective when proving small circuits, and our work is summarized in a PKC 2024 paper.\nI have given three talks about this topic:\nOne in the group meeting last year (by that time we call the project SPED). Slides One on AC 2023 at Guangzhou during Rump Session \u0026lt;2023-12-06 三\u0026gt; Slides One on PKC 2024 at Syndey \u0026lt;2024-04-16 二\u0026gt;. Slides References Baum, Carsten, Lennart Braun, Cyprien Delpech De Saint Guilhem, Michael Klooß, Emmanuela Orsini, Lawrence Roy, and Peter Scholl. 2023. “Publicly Verifiable Zero-Knowledge and Post-Quantum Signatures from VOLE-in-the-Head.” In Advances in Cryptology – CRYPTO 2023, edited by Helena Handschuh and Anna Lysyanskaya, 14085:581–615. Cham: Springer Nature Switzerland. https://doi.org/10.1007/978-3-031-38554-4_19. “Durandal: A Rank Metric Based Signature Scheme SpringerLink.” n.d. https://link.springer.com/chapter/10.1007/978-3-030-17659-4\\_25. Accessed October 17, 2023. ","permalink":"http://localhost:1313/talk/resolved_talk/","summary":"\u003cp\u003eThis is a project that runs in the \u003cstrong\u003e\u003cstrong\u003eLattice\u003c/strong\u003e\u003c/strong\u003e lab, starting\nfrom Dalao Hanlin, who first envisioned the possibility of substituting\nLWE-based cryptography with LPN (spoiler alert we currently do not know\nhow to achieve this goal). A significant goal is to construct a digital\nsignature a la Dilithium at least in terms of performance.\u003c/p\u003e\n\u003cp\u003eAlas, the \u003cstrong\u003eFiat-Shamir with Abort\u003c/strong\u003e technique does not work directly with\nLPN, although some folks have come up with variants of the LPN assumption\nto accommendate with this technqiue (e.g. (\u003ca href=\"#citeproc_bib_item_2\"\u003e“Durandal: A Rank Metric Based Signature Scheme SpringerLink” n.d.\u003c/a\u003e)). We\nconsider the status quo unsatisfactory.\u003c/p\u003e","title":"Digital Signature from Regular Syndrome Decoding and VOLEitH"},{"content":" Ph.D. Student in Cryptography\nLATTICE Group, Shanghai Jiao Tong University\nInterests Theoretical Cryptography Multiparty Computation MPC-in-the-Head Education MSc in Computer Science, Shanghai Jiao Tong University, 2022 BSc in Information Security, Shanghai Jiao Tong University, 2019 About I am a second-year Ph.D. student majoring in Cryptography at SJTU. My past projects include MPC-in-the-Head, COT-AG, and ReSolveD. I am very interested in objects that are both theoretically interesting and of practical significance.\nHere\u0026rsquo;s my CV.\n","permalink":"http://localhost:1313/about/","summary":"\u003cp\u003e\u003cspan class=\"icons-item\"\u003e \u003ca href=\"https://github.com/freemanrickcui\" target=\"_blank\"\u003e\u003ci class=\"fab fa-github\"\u003e\u003c/i\u003e\u003c/a\u003e\u003c/span\u003e\n\u003cspan class=\"icons-item\"\u003e \u003ca href=\"https://www.stackoverflow.com/users/8865477/rick-freeman\" target=\"_blank\"\u003e\u003ci class=\"fab fa-stack-overflow fa-1x\"\u003e\u003c/i\u003e\u003c/a\u003e\u003c/span\u003e\n\u003cspan class=\"icons-item\"\u003e \u003ca href=\"https://orcid.org/0000-0002-6203-413X\" target=\"_blank\"\u003e\u003ci class=\"fab fa-orcid fa-1x\"\u003e\u003c/i\u003e\u003c/a\u003e\u003c/span\u003e\n\u003cspan class=\"icons-item\"\u003e \u003ca href=\"https://scholar.google.com/citations?user=bWNvN0UAAAAJ\" target=\"_blank\"\u003e\u003ci class=\"fab fa-google fa-1x\"\u003e\u003c/i\u003e\u003c/a\u003e\u003c/span\u003e\n\u003cspan class=\"icons-item\"\u003e \u003ca href=\"mailto:freemanrickcui@outlook.com\"\u003e\u003ci class=\"fas fa-envelope fa-1x\"\u003e\u003c/i\u003e\u003c/a\u003e\u003c/span\u003e\n\u003cspan class=\"icons-item\"\u003e \u003ca href=\"/gpg_public_key.txt\"\u003e\u003ci class=\"fas fa-key fa-1x\"\u003e\u003c/i\u003e\u003c/a\u003e\u003c/span\u003e\u003c/p\u003e\n\u003cp\u003ePh.D. Student in Cryptography\u003cbr /\u003e\n\u003ca href=\"https://crypto.sjtu.edu.cn/\"\u003eLATTICE Group\u003c/a\u003e, Shanghai Jiao Tong University\u003c/p\u003e\n\u003ch2 id=\"interests\"\u003eInterests\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eTheoretical Cryptography\u003c/li\u003e\n\u003cli\u003eMultiparty Computation\u003c/li\u003e\n\u003cli\u003eMPC-in-the-Head\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"education\"\u003eEducation\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eMSc in Computer Science, Shanghai Jiao Tong University, 2022\u003c/li\u003e\n\u003cli\u003eBSc in Information Security, Shanghai Jiao Tong University, 2019\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"about\"\u003eAbout\u003c/h2\u003e\n\u003cp\u003eI am a second-year Ph.D. student majoring in Cryptography at SJTU. My\npast projects include MPC-in-the-Head, COT-AG, and ReSolveD. I am very\ninterested in objects that are both theoretically interesting and of\npractical significance.\u003c/p\u003e","title":"Hongrui's Personal Information"},{"content":"This is a Crypto 2022 paper that describes how to construct authenticated garbled circuit using correlations that allow efficient PCGS (e.g., MT, VOLE). Using the AGC, we can run actively secure 2PC afterwards.\nThis work inspired us to conduct a follow-up work Authenticated Garbling From Correlated OT.\nHere is the slides I have prepared Slides.\n","permalink":"http://localhost:1313/talk/dilo/","summary":"\u003cp\u003eThis is a Crypto 2022 paper that describes how to construct\nauthenticated garbled circuit using correlations that allow efficient\nPCGS (e.g., MT, VOLE). Using the AGC, we can run actively secure 2PC\nafterwards.\u003c/p\u003e\n\u003cp\u003eThis work inspired us to conduct a follow-up work \u003ca href=\"/paper/cot_ag/\"\u003eAuthenticated Garbling From Correlated OT\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eHere is the slides I have prepared \u003ca href=\"/ox-hugo/Auth-GC-from-VOLE.pdf\"\u003eSlides\u003c/a\u003e.\u003c/p\u003e","title":"Authenticated Garbling from Compressed Randomness"},{"content":"Inspired by [DILO22], we investigate what is the bare minimum we can achieve using the correlated OT functionality in actively secure two-party computation. We found that with the following two techniques\nblock COT and compression idea of [DILO22] dual execution We can achieve constant (up to 5 bits per AND gate) overhead in terms of one-way communication compared to semi-honest half-gate [ZRE15].\nOne-way Communication The one-way communication result is published as Actively Secure Half-Gates with Minimum Overhead under Duplex Networks. In Advances in Cryptology–EUROCRYPT 2023: 42nd Annual International Conference on the Theory and Applications of Cryptographic Techniques, Lyon, France, April 23–27, 2023, Proceedings, Part II (pp. 35-67). Cham: Springer Nature Switzerland. PDF\nTwo-way Communication We then extended the result towards minimizing two-way communication. We manage to achieve \\( 2\\kappa + \\lambda + C \\) bits per AND gate where \\( \\kappa \\) is the computational security parameter and \\( \\lambda \\) is the statistical security parameter. This work is available at ePrint 2023/278.\n","permalink":"http://localhost:1313/paper/cot_ag/","summary":"\u003cp\u003eInspired by [DILO22], we investigate what is the bare minimum we can\nachieve using the correlated OT functionality in actively secure\ntwo-party computation. We found that with the following two techniques\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eblock COT and compression idea of [DILO22]\u003c/li\u003e\n\u003cli\u003edual execution\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eWe can achieve constant (up to 5 bits per AND gate) overhead in terms of\none-way communication compared to semi-honest half-gate [ZRE15].\u003c/p\u003e\n\u003ch2 id=\"one-way-communication\"\u003eOne-way Communication\u003c/h2\u003e\n\u003cp\u003eThe one-way communication result is published as \u003cem\u003eActively Secure\nHalf-Gates with Minimum Overhead under Duplex Networks. In Advances in\nCryptology–EUROCRYPT 2023: 42nd Annual International Conference on the\nTheory and Applications of Cryptographic Techniques, Lyon, France,\nApril 23–27, 2023, Proceedings, Part II (pp. 35-67). Cham: Springer\nNature Switzerland.\u003c/em\u003e \u003ca href=\"https://link.springer.com/content/pdf/10.1007/978-3-031-30617-4_2.pdf\"\u003ePDF\u003c/a\u003e\u003c/p\u003e","title":"Authenticated Garbling From Correlated OT"},{"content":"Since random vector commitment is used extensively in MPCitH and VOLEitH applications, with some of them being post quantum signatures, which is efficiency sensitive (e.g. TLS needs fast authentications for smooth browsing experience), it\u0026rsquo;s a natural question to optimize this component.\nOne possible way to do this is to replace the cryptograhpic hash function invocation at the bottom layer of the GGM tree with AES-based hash functions which are relatively lightweight when the key is fixed.\nTwo groups of researchers have proposed similar solutions. Bui, Cong, and Delpech de Saint Guilhem proposed a CCR-hash-based construction which they instantiate with the [GKWY20] construction with a \\(\\lambda\\)-bit permutation. The down-side is that AES only offers 128-bit block size and they have to resort to Rijndael for higher security parameters, which kind of goes against the initial goal of optimization since AES being fast is largely due to the instruction set AES-NI.\nSo Prof. Guo tries to tackle this problem using only AES. We are having an discussion about this topic at \u0026lt;2024-03-06 三\u0026gt;. Here are the slides.\n","permalink":"http://localhost:1313/talk/vc-aes/","summary":"\u003cp\u003eSince random vector commitment is used extensively in MPCitH and\nVOLEitH applications, with some of them being post quantum signatures,\nwhich is efficiency sensitive (e.g. TLS needs fast authentications for\nsmooth browsing experience), it\u0026rsquo;s a natural question to optimize\nthis component.\u003c/p\u003e\n\u003cp\u003eOne possible way to do this is to replace the cryptograhpic hash\nfunction invocation at the bottom layer of the GGM tree with AES-based\nhash functions which are relatively lightweight when the key is fixed.\u003c/p\u003e","title":"Efficient Random Vector Commitment from AES"},{"content":"This is a Crypto 2019 paper by Boneh et al. In this paper the authors utilize the fact that the verifier can only make linear queries to the instance string and the PCP/IOP proof string in order to make a decision. Building on this property, we can design proof systems that allow proving statements that are shared among multiple verifiers. This proof system in particular appear useful for the GMW transformation, which is the topic of another talk.\nAlso this work appear to be dual to our previous work multi-heads\n","permalink":"http://localhost:1313/talk/flpcp/","summary":"\u003cp\u003eThis is a Crypto 2019 paper by Boneh et al. In this paper the authors\nutilize the fact that the verifier can only make linear queries to the\ninstance string and the PCP/IOP proof string in order to make a\ndecision. Building on this property, we can design proof systems that\nallow proving statements that are shared among multiple verifiers.\nThis proof system in particular appear useful for the GMW transformation,\nwhich is the topic of another talk.\u003c/p\u003e","title":"Fully Linear PCP"},{"content":"The VOLE in the Head framework demonstrates very competetive performance as compared to the traditional MPC in the Head framework. This has been demonstrated in the FAEST signature scheme (Crypto 2023).\nOne natural ideal is to utilize this framework to prove other OWF, e.g. LPN-based. In this work, we apply the sketching technique of [BGI16] to prove that the LPN noise consists of a series of unit vectors, and then apply QuickSilver to prove the validity of LPN witness. After transforming the proof system under the VOLE in the Head framework from designated verifier to public verifier, we get a signature scheme called ReSolveD. The scheme shows smaller signature size as compared to previous state-of-the-art SDitH (Eurocrypt 2023, Asiacrypt 2023)\nThis work is published as ReSolveD: Shorter Signatures from Regular Syndrome Decoding and VOLE-in-the-Head, Public Key Cryptogrpahy 2024 ePrint 2024/040\nI gave several talks about this project, summarized in this post.\n","permalink":"http://localhost:1313/paper/resolved/","summary":"\u003cp\u003eThe \u003cstrong\u003eVOLE in the Head\u003c/strong\u003e framework demonstrates very competetive\nperformance as compared to the traditional MPC in the Head\nframework. This has been demonstrated in the \u003cstrong\u003eFAEST\u003c/strong\u003e signature scheme\n(Crypto 2023).\u003c/p\u003e\n\u003cp\u003eOne natural ideal is to utilize this framework to prove other OWF,\ne.g. LPN-based. In this work, we apply the sketching technique of\n[BGI16] to prove that the LPN noise consists of a series of unit\nvectors, and then apply QuickSilver to prove the validity of LPN\nwitness. After transforming the proof system under the VOLE in the\nHead framework from designated verifier to public verifier, we get a\nsignature scheme called \u003cstrong\u003eReSolveD\u003c/strong\u003e. The scheme shows smaller signature\nsize as compared to previous state-of-the-art \u003cstrong\u003eSDitH\u003c/strong\u003e (Eurocrypt 2023,\nAsiacrypt 2023)\u003c/p\u003e","title":"LPN-based Signature from VOLE in the Head"},{"content":"This paper is about extending the classical [IKOS07] MPC in the Head framework to prove statements that are shared among multiple provers.\nThis is somewhat dual to the distributed ZKP object. I gave a talk about this Crypto 2019 paper.\nPublished as A Multi-Prover Zero-Knowledge Proof System. In European Symposium on Research in Computer Security (pp. 332-351). Springer, Cham. PDF\n","permalink":"http://localhost:1313/paper/multi_heads/","summary":"\u003cp\u003eThis paper is about extending the classical [IKOS07] MPC in the Head\nframework to prove statements that are shared among multiple provers.\u003c/p\u003e\n\u003cp\u003eThis is somewhat dual to the distributed ZKP object. I gave a talk about\nthis \u003ca href=\"/talk/flpcp/\"\u003eCrypto 2019 paper\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003ePublished as \u003cem\u003eA Multi-Prover Zero-Knowledge Proof\nSystem.\u003c/em\u003e In European Symposium on Research in Computer Security\n(pp. 332-351). Springer, Cham. \u003ca href=\"https://link.springer.com/content/pdf/10.1007%2F978-3-030-88428-4_17.pdf\"\u003ePDF\u003c/a\u003e\u003c/p\u003e","title":"MPC in Multi Heads"},{"content":"My first misc is proabably clarify my CV\n","permalink":"http://localhost:1313/misc/first_misc/","summary":"\u003cp\u003eMy first misc is proabably clarify my CV\u003c/p\u003e","title":"My first misc"},{"content":"My first note is about the CIS 2019 winter school\n","permalink":"http://localhost:1313/note/first_note/","summary":"\u003cp\u003eMy first note is about the CIS 2019 winter school\u003c/p\u003e","title":"My first note"},{"content":"My first talk is about memory-hard functions but they are kind of lost\n","permalink":"http://localhost:1313/talk/first_talk/","summary":"\u003cp\u003eMy first talk is about memory-hard functions but they are kind of lost\u003c/p\u003e","title":"My first talk"},{"content":"Hash-based signature is to be standardized by NIST \u0026lt;2024-02-28 三\u0026gt;. So it is a natural question to study whether the currently being standarized algorithm SPHINCS+ is indeed optimal.\nTowards this end, we discovered that the constant-sum encoding method that appear previously in the literature, is encoding-size-optimal among all tree-based one-time signature schemes. Moreover, by refuting a DAG-based construction [BM96] our scheme appears to be the optimal among all existing constructions.\nThis work is published as Revisiting the Constant-Sum Winternitz One-Time Signature with Applications to and XMSS. In: Handschuh, H., Lysyanskaya, A. (eds) Advances in Cryptology – CRYPTO 2023. CRYPTO 2023. Lecture Notes in Computer Science, vol 14085. Springer, Cham. PDF\n","permalink":"http://localhost:1313/paper/cs_wots/","summary":"\u003cp\u003eHash-based signature is to be standardized by NIST \u003cspan class=\"timestamp-wrapper\"\u003e\u003cspan class=\"timestamp\"\u003e\u0026lt;2024-02-28 三\u0026gt;\u003c/span\u003e\u003c/span\u003e. So\nit is a natural question to study whether the currently being standarized\nalgorithm \u003cstrong\u003eSPHINCS+\u003c/strong\u003e is indeed optimal.\u003c/p\u003e\n\u003cp\u003eTowards this end, we discovered that the constant-sum encoding method\nthat appear previously in the literature, is encoding-size-optimal\namong all tree-based one-time signature schemes. Moreover, by refuting\na DAG-based construction [BM96] our scheme appears to be the optimal\namong all existing constructions.\u003c/p\u003e","title":"Optimal One-time Signature"},{"content":"Generating Boolean Beaver triples has always been an intriguing problem. On one hand, Overdrive-type FHE-based solutions offers asympototically-good solutions, and for suitable field size the concrete efficiency is also considered state-of-the-art. On the other hand, the current best practice for generating authenticated Boolean Beaver triples remains MASCOT-type COT-based protocols, which has communication of \\(O(N^2 m)\\) for generating \\(m\\) triples among \\(N\\) parties.\nI guess this is a follow-up of Ring-LPN PCG.\nThere has been a number of works (Bombar et al. 2024, 2023; Boyle et al. 2022, 2020b, 2020a) trying to change the status quo, with the ultimate goal of creating a concretely efficient end-to-end MPC protocol. I made some slides about them.\nReferences Bombar, Maxime, Dung Bui, Geoffroy Couteau, Alain Couvreur, Clément Ducros, and Sacha Servan-Schreiber. 2024. “FOLEAGE: \\$mathbb\\\\F\\\\\\_4\\$OLE-Based Multi-Party Computation for Boolean Circuits.” Bombar, Maxime, Geoffroy Couteau, Alain Couvreur, and Clément Ducros. 2023. “Correlated Pseudorandomness from the Hardness of Quasi-Abelian Decoding.” Boyle, Elette, Geoffroy Couteau, Niv Gilboa, Yuval Ishai, Lisa Kohl, Nicolas Resch, and Peter Scholl. 2022. “Correlated Pseudorandomness from Expand-Accumulate Codes.” In Advances in Cryptology – CRYPTO 2022, edited by Yevgeniy Dodis and Thomas Shrimpton, 13508:603–33. Cham: Springer Nature Switzerland. https://doi.org/10.1007/978-3-031-15979-4_21. Boyle, Elette, Geoffroy Couteau, Niv Gilboa, Yuval Ishai, Lisa Kohl, and Peter Scholl. 2020a. “Efficient Pseudorandom Correlation Generators from Ring-LPN.” In Advances in Cryptology – CRYPTO 2020, edited by Daniele Micciancio and Thomas Ristenpart, 12171:387–416. Cham: Springer International Publishing. https://doi.org/10.1007/978-3-030-56880-1_14. ———. 2020b. “Correlated Pseudorandom Functions from Variable-Density LPN.” In 2020 IEEE 61st Annual Symposium on Foundations of Computer Science (FOCS), 1069–80. Durham, NC, USA: IEEE. https://doi.org/10.1109/FOCS46700.2020.00103. ","permalink":"http://localhost:1313/talk/boolean-beaver-pcg/","summary":"\u003cp\u003eGenerating Boolean Beaver triples has always been an intriguing\nproblem.  On one hand, Overdrive-type FHE-based solutions offers\nasympototically-good solutions, and for suitable field size the\nconcrete efficiency is also considered state-of-the-art. On the other\nhand, the current best practice for generating authenticated Boolean\nBeaver triples remains MASCOT-type COT-based protocols, which has\ncommunication of \\(O(N^2 m)\\) for generating \\(m\\) triples among \\(N\\)\nparties.\u003c/p\u003e\n\u003cp\u003eI guess this is a follow-up of \u003ca href=\"/talk/ring_lpn_pcg/\"\u003eRing-LPN PCG\u003c/a\u003e.\u003c/p\u003e","title":"PCG for Boolean Beaver Triples"},{"content":"This is a Eurocrypt 2023 submission that describes the application of EA-LPN in constructing PCF for garbled circuit correlations. They also present three applications of their construction, albeit not very convincing in their practical values.\nI gave a talk about this paper and also discussed the merit of it at \u0026lt;2024-02-27 二\u0026gt;. Here is the ipe source.\n","permalink":"http://localhost:1313/talk/gcpcgpcf/","summary":"\u003cp\u003eThis is a Eurocrypt 2023 submission that describes the application of\nEA-LPN in constructing PCF for garbled circuit correlations. They also\npresent three applications of their construction, albeit not very\nconvincing in their practical values.\u003c/p\u003e\n\u003cp\u003eI gave a talk about this paper and also discussed the merit of it at\n\u003cspan class=\"timestamp-wrapper\"\u003e\u003cspan class=\"timestamp\"\u003e\u0026lt;2024-02-27 二\u0026gt;\u003c/span\u003e\u003c/span\u003e. Here is the \u003ca href=\"Slides/GC-PCG-PCF.ipe\"\u003eipe source\u003c/a\u003e.\u003c/p\u003e","title":"PCG for Garbled Circuit Correlations"},{"content":"The \\( n^2 \\) computational overhead of PCGs for the OLE/MT correlation has long been a trouble and only recently have we come up with some creative solution (for authenticated triples over \\( \\mathbb{F}_2 \\)).\nThis is a Crypto 2020 paper that shows how to create such a correlation over \\( \\mathbb{F}_{2^{\\rho}} \\) using Ring-LPN. I recall giving talks about this construction in various occacions but the details have been lost now. \u0026lt;2024-02-28 三\u0026gt;\nAnyway, here is the slides I have prepared for a LATTICE group meeting at Dec. 2021 Slides.\n","permalink":"http://localhost:1313/talk/ring_lpn_pcg/","summary":"\u003cp\u003eThe \\( n^2 \\) computational overhead of PCGs for the OLE/MT correlation\nhas long been a trouble and only recently have we come up with some\ncreative solution (for authenticated triples over \\( \\mathbb{F}_2 \\)).\u003c/p\u003e\n\u003cp\u003eThis is a Crypto 2020 paper that shows how to create such a\ncorrelation over \\( \\mathbb{F}_{2^{\\rho}} \\) using Ring-LPN. I recall\ngiving talks about this construction in various occacions but the\ndetails have been lost now. \u003cspan class=\"timestamp-wrapper\"\u003e\u003cspan class=\"timestamp\"\u003e\u0026lt;2024-02-28 三\u0026gt;\u003c/span\u003e\u003c/span\u003e\u003c/p\u003e","title":"Ring-LPN PCG"},{"content":"In this paper we describe a simple GCZK protocol that works in the reverse order compared to [JKO16]. Here the prover is the garbler and the verifier use cut-and-choose to verify that the correct verification circuit is garbled. In this way, the protocol can be made public-coin.\nPublished as A Simple Post-Quantum Non-interactive Zero-Knowledge Proof from Garbled Circuits. In International Conference on Information Security and Cryptology (pp. 269-280). Springer, Cham. PDF\n","permalink":"http://localhost:1313/paper/simple_gczk/","summary":"\u003cp\u003eIn this paper we describe a simple GCZK protocol that works in the\nreverse order compared to [JKO16]. Here the prover is the garbler and\nthe verifier use cut-and-choose to verify that the correct\nverification circuit is garbled. In this way, the protocol can be made\npublic-coin.\u003c/p\u003e\n\u003cp\u003ePublished as \u003cem\u003eA Simple Post-Quantum Non-interactive Zero-Knowledge\nProof from Garbled Circuits. In International Conference on\nInformation Security and Cryptology (pp. 269-280). Springer, Cham.\u003c/em\u003e\n\u003ca href=\"https://eprint.iacr.org/2021/1068.pdf\"\u003ePDF\u003c/a\u003e\u003c/p\u003e","title":"Simple GCZK"},{"content":"This is a follow-up work of .\nLATTICE group meeting at \u0026lt;2021-10-27 三\u0026gt; Slides Meeting with Huawei at \u0026lt;2021-11-18 四\u0026gt; Slides ","permalink":"http://localhost:1313/talk/sublinear_gmw/","summary":"\u003cp\u003eThis is a follow-up work of .\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eLATTICE group meeting at \u003cspan class=\"timestamp-wrapper\"\u003e\u003cspan class=\"timestamp\"\u003e\u0026lt;2021-10-27 三\u0026gt; \u003c/span\u003e\u003c/span\u003e \u003ca href=\"/ox-hugo/Sublinear-GMW.pptx\"\u003eSlides\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003eMeeting with Huawei at \u003cspan class=\"timestamp-wrapper\"\u003e\u003cspan class=\"timestamp\"\u003e\u0026lt;2021-11-18 四\u0026gt; \u003c/span\u003e\u003c/span\u003e \u003ca href=\"/ox-hugo/Sublinear-GMW-Huawei.pptx\"\u003eSlides\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","title":"Sublinear GMW"},{"content":"BASIC INFORMATION This is the notes of the course \u0026ldquo;Provable Security\u0026rdquo;. The first few courses will be taught online. While subsequent courses are still unsettled.\nI took this course last year, and I am pretty confident about my grasp of basic concepts like universal hash function, GL theorem, basic PRG, PRF constructions, etc. But contents like CRHF and PRP are still rather alien to me, so in this course I will review the previous contents and try to master the missing pieces. Also it is desireable to incopreate the previous notes and complete the notes altogegher.\nTable 1: Basic Information TEACHER 郁昱，刘振 LOCATION 陈瑞球楼108 CODE C033728200203300M01 ZOOM NUMBER 284739677 ZOOM CODE 09333040 LINK https://zoom.com.cn/j/284739677 Homework This section is dedicated to all homework and exercises throughout the lecture (along with their solutions of course).\n18-19-2 Lecture 2 Prove conditional LHL Non-existence of deterministic randomness extractor one-time message authentication code equivalence between min-entropy and collision entropy For solutions please refer to Here.\n18-19-2 Lecture 4 Improving advantage in GL-theorem proof,i.e., difference between guessing game (exact preimage) and inverting game (any satisfying preimage). Exercies 6.1 6.2 6.4 6.6 from KL book Answer can be found here.\n19-20-2 Lecture 2 Existence of independent code here.\nFor an event \\(E\\), we use the indicator function\n\\[ I(E) = \\begin{cases} 1 \u0026amp; E\\\\ 0 \u0026amp; \\bar{E} \\end{cases}\\enspace. \\]\nFix an \\(i\\), we bound the probability\n\\[ p = \\Pr_{C}[\\Pr_{r\\leftarrow R_i^m}[Cr = 0] \u0026gt; \\frac{1+\\zeta}{2^n}]. \\]\nFirst we expand the inner probability expression\n\\[ p = \\Pr_C[\\frac{1}{\\binom{m}{i}} (\\sum_{r^{\\prime}: |r^{\\prime}| = i}I(Cr^{\\prime} = 0)) \u0026gt; \\frac{1+\\zeta}{2^n}]. \\]\nAnd then we transform the form to facilitate Chebyshev\u0026rsquo;s Inequality. (It is easy to observe that \\(\\mathsf{E}_{C}[I(Cr=0)] = \\frac{1}{2^n}\\).)\n\\begin{align*} p \u0026amp;= \\Pr_C[(\\sum_{r^{\\prime}: |r^{\\prime}| = i}I(Cr^{\\prime} = 0)) - \\frac{\\binom{m}{i}}{2^n} \u0026gt; \\binom{m}{i} \\frac{\\zeta}{2^n}] \\\\ \u0026amp;\\le \\Pr_C[\\left| (\\sum_{r^{\\prime}: |r^{\\prime}| = i}I(Cr^{\\prime} = 0)) - \\frac{\\binom{m}{i}}{2^n} \\right| \u0026gt; \\binom{m}{i} \\frac{\\zeta}{2^n}] \\\\ \u0026amp;\\le \\frac{\\underset{C}{Var}{(\\sum_{r^{\\prime}: |r^{\\prime}| = i}I(Cr^{\\prime} = 0))}} {(\\binom{m}{i} {\\frac{\\zeta}{2^n}})^2}\\enspace. \\end{align*}\nNotice that for distinct \\(r_1\\) and \\(r_2\\), the random variable \\(I(C r_1 = 0\\) and \\(I(C r_2 = 0\\) are independent since \\(I(C (r_1 - r_2)\\) follows the same distribution as either of them. This means we can further expand the expression as\n\\[ p \\le \\frac{ \\sum_{r^{\\prime}: |r^{\\prime}| = i}\\underset{C}{Var}{(I(Cr^{\\prime} = 0))}}{(\\binom{m}{i} {\\frac{\\zeta}{2^n}})^2}\\enspace. \\]\nSince once \\(r\\) is fixed, \\(I(Cr = 0)\\) follows the Bernoulli distribution with \\(\\mu = \\frac{1}{2^n}\\), we can further write the expression as\n\\begin{align*}~ p \u0026amp;\\le \\frac{ \\binom{m}{i} \\mu - \\mu^2}{(\\binom{m}{i} {\\frac{\\zeta}{2^n}})^2} \\\\ \u0026amp;\\le \\frac{2^n \\binom{m}{i}^{-1}}{\\zeta^2}\\enspace. \\end{align*}\nSince \\(i \\le \\frac{k}{2}\\) and \\(\\binom{m}{i} \\ge \\binom{m}{k/2} \\ge (\\frac{m}{k/2})^{k/2}\\), we have\n\\begin{align*} p \u0026amp;\\le \\frac{2^{n - \\frac{k}{2} \\log{\\frac{2m}{k}}}}{\\zeta^2} \\\\ \u0026amp;\\le \\frac{2^{n - \\frac{k}{2} \\log{\\frac{m}{k}} + \\frac{\\log m}{2}}} {\\zeta^2}\\enspace. \\end{align*}\nUsing a union bound on all possible values of \\(i\\), we conclude the proof of this lemma.\n19-20-2 Lecture 5 PRG from LPN Link: Lecture 5\nFollowing usual LPN conventions, we define the LPN distribution \\(LPN_{n,\\mu}^m := (A, As+e)\\), where \\(A\\leftarrow U_{m\\times n}\\), \\(s\\leftarrow U_n\\), and \\(e \\leftarrow Ber_{\\mu}^m\\). The (\\(n\\), \\(\\mu\\), \\(m\\))-DLPN assumption postulate that for any probablistic polynomial time distinguisher, the advantage of distinguishing \\(LPN_{n,\\mu}^m\\) apart from uniform distribution is at most \\(\\epsilon = \\mathsf{negl}\\). We now construct a PRG from (\\(n\\), \\(1/16\\), \\(m\\))-DLPN assumption.\nThe construction is very simple. On \\(4m + n\\) bit input, the algorithm \\(g\\) produces \\(4.2m\\) bits of output from the following procedure:\nParse the \\(4m\\) bits of input (denoted as \\(r\\)) as \\(m\\) 4-bit blocks, and produce noise \\(e\\) by taking the logical AND of each block. Produce first \\(m\\) bit by \\(y_1 = A\\cdot s + e\\) where \\(s\\) is the remaining \\(n\\) bits of input. Produce the rest \\(3.2m\\) bits by using the universal hash function \\(h\\). Note that the matrix \\(A\\) and hash function \\(f\\) are both public randomness, and can be considered as part of both input and output. We prove the pseudorandomness of output below.\nProof (sketch). We consider the more general case of generating \\(\\mu = 2^t\\) Bernoulli noise from \\(mt\\) random bits. The aforementioned sampling algorithm actually wasted a lot of randomness, which can actually be recycled to facilitate a positive stretch.\nClaim. The min-entropy of \\(r\\) conditioned on \\(e\\) is at least \\(mt(1 - 2^{-\\Omega{t}})\\) except with probability \\(e^{-m2^{-t}/3}\\).\nThis can be shown from the following argument. By Chernoff bound, the probability of \\(e\\) having more than \\(2^{-t+1}m\\) ones is at most \\(2^{-m 2^{-t}/3}\\). Thus, conditioned on this event, at least \\(m(1-2^{-t+1})\\log(2^t-1)\\) bits of \\(r\\) are unpredictable. Using the fact that \\(\\log(2^t-1) \u0026gt; \\log(2^{t(1 - 2\\Omega(t))})\\) we can conclude that the conditional min-entropy of \\(r\\) in this case is at least \\(mt(1 - 2^{-\\Omega{t}})\\).\nThe rest of the proof follows by a standard hybrid argument. In particular,\nHybrid 1 The algorithm \\(g\\) aborts whenever \\(|e| \u0026gt; 2^{-t+1}m\\). From the Chernoff bound, the output in this case is statistically close to the real distribution. Hybrid 2 Replace hashed output \\(h( r)\\) with uniform randomness. The output is indistinguishable from Hybrid 1 from Leftover Hash Lemma. Hybrid 3 Replace the first part of output by uniform randomness. The output is indistinguishable from Hybrid 2 from Decisional LPN assumption under constant noise rate. Hybrid 4 Remove artifitial abort introduced in Hybrid 1. Once again, this is statistically indistinguishable from Hybrid 2. This is also the uniform distribution. The constants in the aformentioned construction are chosen so that \\( m (1 - 2^{-t+1}) \\log(2^t-1) \u0026gt; m(t-1) + d\\) where \\(d = \\omega(\\log n)\\) is an appropriate entropy loss.\nCLPN and DLPN Equivalence Link: Exercises Proof is in the link.\n19-20-2 Lecture 6 Levin\u0026rsquo;s Trick: Exercise: Domain Extension for PRFs Proof is in the link.\n18-19-2 Lecture 2 In this note, the content of this week\u0026rsquo;s lecture on provable security by Prof. Yu is summarized, from the handout and my own note taken at the lecture. Additionally, I will give my answers to the homework given at the end of this week\u0026rsquo;s handout.\nLecture Content Several key concepts were introduced in this week\u0026rsquo;s lecture along with their definitions. These includes \\(\\varepsilon\\) -security of private key encryption schemes, statistical distance, minimum entropy and unpredictability, randomness extractor, and leftover hash lemma. The reader might be already familiar with these concepts, and if that is the case, they should agree with my opinion that the theory of probability are heavily used in those definition and results.\nAnyway, the following is derived from my notes taken during the lecture.\nIndistinguishability Indistinguishability and resilience to key recovery attack are the two primary means to defining the security of a encryption scheme. We define the following indistinguishability experiment:\nprivk\nThere are several points to note here:\nUnlike the indistinguishability experiment in the public key encryption scheme, the adversarial algorithm \\(A=(A_1,D)\\) here does not output a state. This is because the adversary\u0026rsquo;s power is unlimited, and therefore (in my opinion) the decryption algorithm can run the message generation algorithm again to get all the state information it needs, ergo the state need not to be passed.\nThe advantage of the adversary here is defined as the probability \\(\\Pr[\\mathsf{PrivK}^{eav}_{\\mathsf{A,\\mathcal{P}i}}] - 1/2\\).\nStatistical Security There are two ways to define statistical security (i.e. \\(\\varepsilon\\) -secure), and they are equivalent. Note that in the indistinguishability experiment version of the definition, the probability \\[ \\Pr[\\mathsf{PrivK}^{eav}_{\\mathsf{A,\\mathcal{P}i}}] \u0026lt; 1/2 + \\varepsilon/2 \\] implies \\[ 1/2 - \\varepsilon/2 \u0026lt; \\Pr[\\mathsf{PrivK}^{eav}_{\\mathsf{A,\\mathcal{P}i}}] \u0026lt; 1/2 + \\varepsilon/2.\\] This is because if the upper bound of the success probability is bounded, then the lower bound must follow the same margin. If not, negate the distinguisher with very low success probability will get an adversary that breaks the upper bound.\nWhen an encryption scheme achieves \\(0\\) -security, we say that it is perfectly secure. Vernam\u0026rsquo;s Cipher (One-time pad) is such a cipher.\nStatistical Distance (SD) The definition of statistical distance is as follows: \\[ \\mathsf{SD}(X,Y) \\overset{\\text{def}}{=} 1/2 \\sum_x{|\\Pr[X=x]-\\Pr[Y=x]|}, \\]\nand we say \\(X\\) is \\(\\varepsilon\\) -close to \\(Y\\) if \\(\\mathsf{SD}(X,Y) \u0026lt; \\varepsilon\\).\nThere is also a lemma about the advantage limit of any distinguisher on two distributions with limited statistical distance. For random variables \\(X\\) and \\(Y\\) defined over set \\(\\mathcal{S}\\), and for any distinguisher \\(\\mathsf{D} : \\mathcal{S} \\rightarrow \\{0,1\\}\\), we have\n\\[ \\left| \\Pr[\\mathsf{D}(X)=1]-\\Pr[\\mathsf{D}(Y)=1] \\right| \\leq \\mathsf{SD}(X,Y). \\] The proof is actually not hard, since the distinguisher \\(\\mathsf{D}\\) is all-powerful, we can think of it as deterministic, and therefore (w.l.o.g. we assume \\(\\Pr[\\mathsf{D}(X)=1]\\geq\\Pr[\\mathsf{D}(Y)=1]\\))\n\\begin{align*} |\\Pr[\\mathsf{D}(X)=1]-\\Pr[\\mathsf{D}(Y)=1]| \u0026amp;= |\\sum_{x\\in S:\\mathsf{D}(x)=1}{\\Pr[X=x]-\\Pr[Y=x]} |\\\\ \u0026amp;\\leq |\\sum_{x\\in S:\\mathsf{D}(x)=1 \\cap S:\\Pr[X=x]\\geq\\Pr[Y=x]} {\\Pr[X=x]-\\Pr[Y=x]}|\\\\ \u0026amp;\\leq |\\sum_{x\\in S:\\Pr[X=x]\\geq\\Pr[Y=x]}{\\Pr[X=x]-\\Pr[Y=x]} |\\\\ \u0026amp;=\\mathsf{SD}(X,Y)\\enspace. \\end{align*}\nThe two inequality holds if and only if the two sets are equal. (The last equality is a little tricky.)\nThe statistical distance \\(\\mathsf{SD}\\) is a metric, meaning the following properties holds:\nnon-negativity identity of indiscernibles symmetry triangle inequality. Statistical distance also has the following additional properties:\nno greater than 1 (the equality holds if and only if the elements with positive probability in the two distributions does not intersect.) replacement: for every function \\(f\\), it holds that \\(\\mathsf{SD}(f(X),f(Y)) \\leq \\mathsf{SD}(X,Y)\\). (the equality holds if and only if \\(f\\) is a bijective map.) Statistical Security of OTP Replacing the key-generation algorithm \\(\\mathsf{Gen}\\) in OTP by an algorithm \\(\\mathsf{Gen}^{\\prime}\\) that draws key according to some distribution \\(\\tilde{K}\\) that is \\(\\varepsilon\\) -close to \\(U_n\\) will gives us an encryption scheme that is \\(2\\varepsilon\\) -secure.\nThe proof is as follows, fix message \\(m_0, m_1 \\in \\{0,1\\}^n\\), \\(m_0 \\neq m_1\\). We have for any distinguisher \\(\\mathsf{D}\\),\n\\begin{align*} |\\Pr[\\mathsf{D}(m_0 \\oplus \\tilde{K})=1] - \\Pr[\\mathsf{D}(m_1 \\oplus \\tilde{K})=1]| \u0026amp;\\leq \\mathsf{SD}(m_0 \\oplus \\tilde{K}, m_1 \\oplus \\tilde{K})\\\\ \u0026amp;\\leq \\mathsf{SD}(m_0 \\oplus \\tilde{K},m_0 \\oplus U_n) + \\mathsf{SD}(m_1 \\oplus \\tilde{K},m_0 \\oplus U_n)\\\\ \u0026amp;\\leq \\mathsf{SD}(\\tilde{K}, U_n) + \\mathsf{SD}(\\tilde{K}, U_n)\\\\ \u0026amp;= 2\\varepsilon\\enspace. \\end{align*}\nUnpredictability and Min-Entropy Definition for unpredictability is as follows, a random variable \\(X\\) is \\(\\varepsilon\\) -unpredictable if for any algorithm \\(A\\), we have \\(\\Pr[A(1^n) = X] \\leq \\varepsilon\\).\nMin-entropy is defined as \\[ \\mathbf{H}_{\\infty}(X)\\overset{\\text{def}}{=} -\\log(\\max_{x\\in \\mathcal{X}}\\Pr[X=x]).\\]\nThere are also average min-entropy and conditional unpredictability definitions. For joint random variable \\((X,Z)\\), we say that \\(X\\) is \\(\\varepsilon\\) -unpredictable given \\(Z\\) if for every algorithm \\(A\\) it holds that \\(\\Pr[A(1^n,Z)=X]\\leq \\varepsilon\\). While the average min-entropy of \\(X\\) conditioned on \\(Z\\), denoted by \\(\\mathbf{H}_{\\infty}(X|Z)\\), is defined by \\[ \\mathbf{H}_{\\infty}(X|Z) \\overset{\\text{def}}{=} \\mathop{\\mathbb{E}}_{z \\leftarrow Z}(\\max_{x\\in \\mathcal{X}} \\Pr[X=x|Z=z]). \\]\nIt holds that a random variable \\(X\\) is \\(\\varepsilon\\) -unpredictable if and only if its min-entropy \\(\\mathbf{H}_{\\infty}(X) \\geq \\log(1/\\varepsilon)\\).\nRandomness Extractor This part is not covered in the handout, as Prof. Yu added them to his slides that he personally said \u0026ldquo;specially prepared since so many students showed up in his class\u0026rdquo;. Therefore, I would not be able to get more detailed content apart from my notes.\nFirst observe that a key with high min-entropy does not guarantee security. To see this, observe that if there is a distribution that always output \\(0\\) on the first bit, followed by \\(n-1\\) uniformly random bits. Now, if we use this distribution as the key distribution in place of the uniform distribution in OTP, and test it in the indistinguishability experiment, the adversary will always win, ergo the scheme is completely insecure. We want to have a randomness extractor, that given input with some min-entropy, gives output that is has some small statistical distance to the uniform distribution. That is, for a (\\(n\\), \\(k\\), \\(m\\), \\(\\varepsilon\\))-randomness extractor, if its input is \\(n\\) -bit long and has min-entropy of \\(k\\), the output will be \\(\\varepsilon\\) -close to \\(U_m\\). However, even for \\(m=1\\), \\(k=n-1\\), such a deterministic extractor does not exist. In order to see this, for any deterministic extractors, we can get the set \\(S_0:\\mathsf{Ext}(x) = 0\\) and \\(S_1:\\mathsf{Ext}(x) = 1\\), and w.l.o.g. assume \\(|S_0|\\geq|S_1|\\). Then consider the distribution on \\(\\{0,1\\}^{n}\\) that has probability \\(1/|S_0|\\) when \\(x\\in S_0\\) and \\(0\\) otherwise. The output of the extractor \\(\\mathsf{Ext}\\) will have \\(1/2\\) statistical distance from \\(U_1\\).\nAnd therefore to achieve our goal of randomness extractor, additional modification must be added. The approach introduced is randomness extractor with a seed (i.e. universal hash functions).\nUniversal Hash Function and Leftover Hash Lemma The definition of universal hash function is as follows. \\(\\mathcal{H} \\subseteq \\{0,1\\}^l\\rightarrow\\{0,1\\}^t\\) is a family of universal hash function if for any distinct \\(x_1,x_2\\in \\{0,1\\}^l\\), it holds that\n\\[ \\Pr_{h\\overset{\\$}{\\leftarrow}\\mathcal{H}}[h(x_1)=h(x_2)] \\leq 2^{-t}.\\]\nFor example, \\(\\mathcal{H}=\\{h_a:h_a(x)\\overset{\\text{def}}{=}(a \\cdot x)_{[t]}\\}\\) is a family of universal hash functions, and \\(|\\mathcal{H}|=2^{l}\\).\nThe leftover hash lemma states that universal hash functions are good randomness extractors.\nFor any integers \\(d \\leq k \\leq l\\), let \\(\\mathcal{H} \\subseteq \\{0,1\\}^l\\rightarrow\\{0,1\\}^{k-d}\\) be a family of universal hash functions. Then, for any random variables \\(X\\) defined over \\(\\{0,1\\}^l\\) with min-entropy no less than \\(k\\), it holds that\n\\[\\mathsf{SD}(H(X),U_{k-d}|H) \\leq 2^{-d/2-1},\\]\nwhere \\(H\\) is the random variable that is uniformly distributed over all members of \\(\\mathcal{H}\\).\nProf. Yu skipped the proof at the lecture, but I think he will catch up with that in the next lecture. Nevertheless, I have read the proof and proved corollary 3.1 which is a conditional version of leftover hash lemma, and also the first homework. The key to the proof is to use a Cauchy-Schwartz inequality to create a quadratic term, which also introduces a square root.\nOne application of the leftover hash lemma is the privacy amplification. Prof. Yu also introduced another concept called non-malleable extractor, which is like \\(\\forall A,\\forall s, A(s) \\neq s\\), and for \\(X\\) with min-entropy \\(k\\), we have\n\\[ (\\mathsf{Ext}(X,U_d), \\mathsf{Ext}(X,A(U_d)),U_d) \\overset{\\varepsilon}{\\approx}(U_m, \\mathsf{Ext}(X,A(U_d)),U_d). \\]\nHonestly, I have not grasped the idea of this definition until now. Maybe I will consult with others later.\nHomework The following is my solutions to the four homework problems in handout2\nProve Corollary 3.1 (Conditional Leftover Hash Lemma)\nSuppose for integers \\(d\\leq k \\le l\\) and \\(\\mathcal{H}:\\{0,1\\}^{l}\\to\\{0,1\\}^{k-d}\\) be the same as assumed in leftover hash lemma (a universal hash function family). For any random variable \\((X,Z)\\) where \\(X\\) is over \\(\\{0,1\\}^l\\) with average min-entropy \\(\\mathbf{H}_\\infty(X|Z) \\geq k\\) it holds that \\[ \\mathsf{SD}(H(X),U_{k-d}|H,Z)\\le 2^{-d/2-1}\\] where \\(H\\) is the random variable that is uniformly distributed over all members of \\(\\mathcal{H}\\).\nThe proof is as follows. By \\(\\mathbf{H}_\\infty(X|Z) \\geq k\\), we have that \\[ \\mathop{\\mathbb{E}}_{z \\leftarrow Z}(\\max_{x\\in \\mathcal{X}} \\Pr[X=x|Z=z]) \\le 2^{-k}.\\] Now lets analyze the statistical distance (let \\(S=\\{0,1\\}^{k-d}\\)),\n\\begin{align*} \\mathsf{SD}\u0026amp;(H(X),U_{k-d}|H,Z) = \\mathsf{SD}((H(X),H,Z),(U_{k-d},H,Z))\\\\ \u0026amp;=1/2\\cdot\\sum_{h\\in\\mathcal{H},z\\in Z,s\\in S}|\\Pr[H(X)=s\\land H=h\\land Z=z]-\\Pr[U_{k-d}=s\\land H=h\\land Z=z]|\\\\ \u0026amp;=1/2\\cdot\\sum_{h\\in\\mathcal{H},z\\in Z,s\\in S}|1/|\\mathcal{H}|\\cdot(\\Pr[h(X)=s|Z=z]\\cdot\\Pr[Z=z]-1/|S|\\cdot\\Pr[Z=z])|\\\\ \u0026amp;=1/2\\cdot\\sum_{h\\in\\mathcal{H},s\\in S}|\\frac{1}{\\sqrt{|\\mathcal{H}||S|}}|\\cdot|\\sum_{z\\in Z}(\\frac{\\sqrt{|S|}}{\\sqrt{|\\mathcal{H}|}}\\cdot(\\Pr[h(X)=s\\land Z=z]-1/|S|\\cdot\\Pr[Z=z]))|\\\\ \u0026amp;\\leq1/2\\cdot\\left( \\sum_{h\\in\\mathcal{H},s\\in S}(\\sum_{z\\in Z}\\Pr[Z=z]^2(\\frac{|S|}{|\\mathcal{H}|}\\Pr[h(X)=s|Z=z]^2-\\frac{2\\Pr[h(X)=s|Z=z]}{|\\mathcal{H}|}+\\frac{1}{|S||\\mathcal{H}|})) \\right)^{1/2}\\\\ \u0026amp;=1/2\\cdot\\left(\\sum_{z\\in Z}\\Pr[Z=z]^2[(\\sum_{h\\in\\mathcal{H},s\\in S}\\frac{|S|}{|\\mathcal{H}|}\\Pr[h(X)=s|Z=z]^2)-1]\\right)^{1/2}\\\\ \u0026amp;\\leq 1/2\\cdot\\left(\\sum_{z\\in Z}\\Pr[Z=z]^2\\cdot\\max_{x\\in X}\\Pr[X=x|Z=z]\\cdot|S|\\right)^{1/2}\\\\ \u0026amp;\\leq 2^{-d/2-1}. \\end{align*}\nThe final inequality relies on the fact that \\(\\Pr[Z=z]^2\\leq\\Pr[Z=z]\\).\nNon-Existence of Deterministic Randomness Extractor\nFor any deterministic function \\(h:\\{0,1\\}^n\\to\\{0,1\\}\\), define the sets \\(S_0:=\\{x|h(x)=0\\}\\) and \\(S_1:=\\{x|h(x)=1\\}\\). Then there must exist a set \\(S_b\\) such that \\(|S_b|\\geq2^{n-1}\\). Construct such a distribution that has probability \\(1/|S_b|\\) for any element in \\(S_b\\) and \\(0\\) for \\(S_{1-b}\\). The distribution has min-entropy at least \\(n-1\\). But applying such input to \\(h\\) would get result that has \\(1/2\\) statistical distance to \\(U_1\\).\nOne-Time Message Authentication Code\nWe only need to compute the probability that the adversary succeeds. Consider that such event happens would indicate \\(w_2\\cdot(m-m^\\prime)=\\sigma-\\sigma^\\prime\\), and therefore the adversary can completely compute \\(W_2\\). And completely succeeding in getting \\(W_2\\) would indicate such an attack is successful. This gives us the crude equivalence of the two events. The probability of successfully guessing \\(W_2\\), conditioned on \\(Z\\) is at most \\(2^n \\cdot 2^{-n-t}\\), completing the proof.\nEquivalence Between Min-Entropy and Collision Entropy\nFor random variable \\(X\\), define the collision probability\n\\[ \\mathsf{CP}(X)\\overset{\\text{def}}{=}\\sum_x{\\Pr[X=x]^2}\\enspace, \\]\nand collision entropy\n\\[ \\mathbf{H}_2(X)=-\\log(\\mathsf{CP}(X))\\enspace.\\]\nShow that for any \\(X\\) with \\(\\mathbf{H}_2(X)\\geq k\\) and any \\(0\u0026lt;\\delta\u0026lt;1\\) there exists some \\(Y\\) with \\(\\mathbf{H}_\\infty(Y)\\ge k-\\log(1/\\delta)\\) such that \\(\\mathsf{SD}(X,Y)\\leq \\delta\\).\nFirst observe that \\(\\sum_x{\\Pr[X=x]^2}\\le 2^{-k}\\) implies \\(\\mathbf{H}_0(X)\\ge k\\), which implies \\(|\\mathcal{X}|\\ge 2^k\\) (the sample space). Then define the set \\(S:=\\{x|\\Pr[X=x]\\le 1/\\delta \\cdot 2^{-k}\\}\\). Define the distribution \\(Y\\) such that for every \\(x\\in \\mathcal{X}\\setminus S\\), \\(\\Pr[Y=x]=1/\\delta \\cdot 2^{-k}\\). And distribute the difference between \\(X\\) in to the values \\(x\\in S\\) on top of \\(\\Pr[X=x]\\) while keeping \\(\\Pr[Y=x]\\le 1/\\delta\\cdot 2^{-k}\\). This is possible since \\(|\\mathcal{X}|\\ge 2^k\\). The resulting distribution will have statistical distance less than \\(\\delta\\).\n18-19-2 Lecture 3 In this note, the content of this week\u0026rsquo;s lecture on provable security by Prof. Yu is summarized, from the handout and my own note taken at the lecture. Additionally, I will try to prove the equivalence of semantic security and indistinguishability here.\nLecture Content As some important proofs were skipped in the last lecture, the lecture started by explaining the proof of the leftover hash lemma in the second handout. The rest of the lecture continued on the computational approach to modern cryptography (computational complexity based approach), and introduced very important concepts like pseudorandom generator, replacement lemma, and hybrid argument. The lecture ended right after hybrid argument was introduced and explained in detail.\nProof of Leftover Hash Lemma Recall that the leftover hash lemma states that for any integers \\(d \\leq k \\leq l\\), let \\(\\mathcal{H} \\subseteq \\{0,1\\}^l\\rightarrow\\{0,1\\}^{k-d}\\) be a family of universal hash functions. Then, for any random variables \\(X\\) defined over \\(\\{0,1\\}^l\\) with min-entropy no less than \\(k\\), it holds that \\[ \\mathsf{SD}(H(X),U_{k-d}|H) \\leq 2^{-d/2-1},\\] where \\(H\\) is the random variable that is uniformly distributed over all members of \\(\\mathcal{H}\\).\nInformally, the leftover hash lemma states that universal hash function is a \\((l,k,k-d,2^{-d/2-1})\\) -randomness extractor. The proof uses Cauchy-Schwartz inequality, which is quite common in the reductions on lattice, according to Wenling, since the equality can be achieved (whey the two vectors have the same direction), and can be easily extended to the complex number field. In my opinion, the core part of the proof is to analyze the collision probability. The proof is as follows (for convenience I denote the set \\(\\{0,1\\}^{k-d}\\) by \\(S\\)):\n\\begin{align*} \\mathsf{SD}\u0026amp;(H(X),U_{k-d}|H) = \\mathsf{SD}((H(X),H),(U_{k-d},H))\\\\ \u0026amp;=1/2\\sum_{s\\in\\{0,1\\}^{k-d},h\\in\\mathcal{H}}|\\Pr[H(X)=s\\land H=h]- \\Pr[U_{k-d}=s\\land H=h]|\\\\ \u0026amp;=1/2\\sum_{h\\in\\mathcal{H}}1/|\\mathcal{H}|\\cdot\\sum_{s\\in S} | \\Pr[H(X)=s|H=h]-1/|S||\\\\ \u0026amp;=1/2\\sum_{s\\in\\{0,1\\}^{k-d},h\\in\\mathcal{H}} \\frac{1}{\\sqrt{|S||\\mathcal{H}|}} \\cdot|\\frac{\\sqrt{|S|}}{\\sqrt{|\\mathcal{H}|}} (\\Pr[H(X)=s|H=h]-1/|S|)|\\\\ \u0026amp;=1/2(\\sum_{s\\in\\{0,1\\}^{k-d},h\\in\\mathcal{H}} \\frac{|S|}{|\\mathcal{H}|} (\\Pr[H(X)=s|H=h]^2-2\\Pr[H(X)=s|H=h]/|S|+1/|S|^2))^{1/2}\\\\ \u0026amp;=1/2((\\sum_{s\\in\\{0,1\\}^{k-d},h\\in\\mathcal{H}} \\frac{|S|}{|\\mathcal{H}|} \\Pr[H(X)=s|H=h]^2)-1)^{1/2}\\\\ \u0026amp;=1/2(|S|(\\sum_{h\\in\\mathcal{H}} \\frac{1}{|\\mathcal{H}|}\\sum_{s\\in S} \\Pr[H(X)=s|H=h]^2)-1)^{1/2} \\end{align*}\nIn this step, we should consider the meaning of the quadratic probability term. It essentially means the expectation of the probability of two identically independent variables sampled according to distribution \\(X\\), after applied to \\(h\\in\\mathcal{H}\\), collides. The expectation is over the uniformly random choice of \\(h\\). According to the fact that \\(\\mathcal{H}\\) is a family of universal hash functions, we can split the probability into two cases.\nCase 1: \\(X_1=X_2\\) (we denote the two random variables by \\(X_1\\) and \\(X_2\\)). In this case, the collision will always happen.\nCase 2: \\(X_1 \\neq X_2\\). In this case, by the property of universal hash function, for any \\(x_1\\neq x_2\\), the probability of \\(h(x_1)=h(x_2)\\) when applying a uniformly random \\(h\\leftarrow\\mathcal{H}\\) is less than \\(2^{k-d}\\).\nFor convenience, denote \\(\\mathbf{Collide}\\) the event that such collision happens (the sample space is \\(S\\times\\mathcal{H}\\)), we have\n\\begin{align*} \\Pr[\\mathbf{Collide}] \u0026amp;= \\Pr[X_1= X_2]\\cdot \\Pr[\\mathbf{Collide}|X_1=X_2]+\\Pr[X_1\\neq X_2]\\cdot \\Pr[\\mathbf{Collide}|X_1\\neq X_2]\\\\ \u0026amp;\\leq \\Pr[X_1=X_2]+\\Pr[\\mathbf{Collide}|X_1\\neq X_2]\\\\ \u0026amp;\\leq \\sum_{s\\in S}\\Pr[X_1=s]^2+2^{^{-k+d}}\\\\ \u0026amp;\\leq \\max_{s\\in S}\\Pr[X=s] + 2^{^{-k+d}}\\\\ \u0026amp;\\leq 2^{-k}+2^{-k+d}\\enspace. \\end{align*}\nPutting this into the previous equation, we have\n\\begin{align*} \\mathsf{SD}(H(X),U_{k-d}|H) \u0026amp;\\leq 1/2 (|S|(\\sum_{h\\in\\mathcal{H}}\\frac{1}{|\\mathcal{H}|} \\sum_{s\\in S}\\Pr[H(X)=s|H=h]^2)-1)^{1/2}\\\\ \u0026amp;=1/2(2^{k-d}(2^{-k}+2^{-k+d})-1)^{1/2}\\\\ \u0026amp;=2^{-d/2-1}\\enspace. \\end{align*}\nAnd that completes the proof.\nOther Points that Arise in the Proof\nThe above was exactly as explained in the lecture, except for one detail. I think the probability \\(\\Pr[X_1=X_2]\\) can be enlarged pretty easily by writing it in the quadratic form and enlarging every term to a probability times the maximumly possible probability, and nothing is wrong with this notion. However, in the lecture, a different approach is used. In particular, Prof. Yu first introduced a lemma concerning random variables. The lemma states that Any X of min-entropy k can be represented as a convex combination of flat distributions over sets of size \\(2^k\\). The notion written on the blackboard that day was \\[ X = p_1X_1+p_2X_2+\\ldots+p_mX_m.\\] In the above equation, we have \\(\\sum_{i\\in[m]}p_i=1\\), ergo convex combination. But the idea was that with probability \\(p_i\\), \\(X\\) will take value from random variable \\(X_i\\). Hanlin explained to me that this can be treated as breaking the large probability into smaller ones, and placing them in different distributions. When thinking in this way, the collision probability can be easily understood. In particular, if all the \\(m\\) subsets are the same, the collision probability is exactly \\(2^{-k}\\). However, if there is any event in the set that takes probability less than \\(2^{-k}\\), the total collision probability will be less than \\(2^{-k}\\). This can easily be obtained by observing \\((p_1+p_2)^2 \\geq p_1^2 +p_2^2\\). According to Hanlin, the convex combination approach is simply a more formal way of stating this fact.\nThere is another way of deriving this fact. There is a uniform way of defining entropy, called Renyi entropy, defined as \\[ \\text{H}_\\alpha(X)=\\frac{1}{1-\\alpha}\\log\\left(\\sum_{i\\in[n]}p_i^\\alpha\\right).\\] When \\(\\alpha=0\\), we get the max-entropy, which is the logarithmic of the size of sample space; when \\(\\alpha \\to 1\\), we get Shannon Entropy (I have not proved it myself); when \\(\\alpha=2\\), we get collision entropy, which is exactly what we need in the previous example; and when \\(\\alpha \\to \\infty\\), we get min-entropy. More importantly, for any discrete random variable \\(X\\) with finite sample space (I added the constraint myself, since currently I know under such conditions the fact holds), we have the following relations \\[ \\text{H}_0(X)\\ge\\text{H}_1(X)\\ge\\text{H}_2(X)\\ge\\ldots\\ge\\text{H}_\\infty(X). \\] The equality holds when \\(X\\) is uniformly random. From this fact we can easily derive that in the proof of leftover hash lemma, we have \\[ \\Pr[X_1=X_2]=2^{-\\text{H}_2(X)}\\le 2^{-\\text{H}_\\infty(X)}=2^{-k}. \\] And that is the second way to derive the probability, which seems more natural. In fact, the requirement on min-entropy in the lemma can be relaxed to requiring the random variable \\(X\\) have collision entropy at least \\(k\\).\nPrivacy Amplification: an Application of Leftover Hash Lemma The problem setting of privacy amplification is that when the communicating parties share a secret \\(W\\), which has some information leaked to an eavesdropping adversary, which we denote by \\(Z\\). By a corollary of the leftover hash lemma, when \\(\\text{H}_\\infty(W|Z)\\geq k\\), applying a universal hash function \\(\\mathcal{H}:\\{0,1\\}^l\\to\\{0,1\\}^{k-d}\\) will get output that is \\(2^{-d/2-1}\\) -close to uniform random distribution \\(U_{k-d}\\), conditioned on \\(W\\) and \\(H\\). And that can be used as good source of randomness (at least it can be used as key in Vernam\u0026rsquo;s cipher to get statistically-secure encryption). The process is illustrated in the figure below.\nFigure 2: Privacy Amplification\nHowever, this scheme is only secure against an eavesdropping only adversary. An active adversary may temper with the message sent between parties, and easily make the two parties have inconsistent results. Prof. Yu then mentioned that using message authentication code, parties can detect message tempering. And that is also is the third problem of the second lecture\u0026rsquo;s problem set.\nOne-Time Message Authentication Code By adding message authentication code (MAC), the receiving party can effectively detect tempering during the transmission with high probability. The third problem of the problem set in the previous lecture proposes a MAC scheme when the two parties share a secret and only use it once (ergo one-time). The scheme works as follows:\nFigure 3: One-time MAC (IT-MAC)\nThe two parties of communication share a \\(2n\\) bit secret, denoted by \\(W=(W_1,W_2)\\), of which some information \\(Z\\) is leaked to an adversary. The average min-entropy of \\(W\\) conditioned on \\(Z\\) is at least \\(n+t\\), namely, \\(\\text{H}_\\infty(W|Z) \\ge n+t\\). It can be proved that in this scheme, for any message \\(m\\), the adversary\u0026rsquo;s success probability\n\\[ \\Pr_{(w_1,w_2)\\gets W,z\\gets Z}[m^\\prime=A(m,\\sigma,z):m\\ne m^\\prime\\land\\sigma^\\prime=w_1+m^\\prime\\cdot w_2]\\le 2^{-t}. \\]\nHowever, as Prof. Yu mentioned in his lecture, the min-entropy of the shared secret is at least \\(n+t\\) bits, while the constructed scheme can only guarantee at least \\(t\\) bit of security (I do not know for sure such notion is correct, but from the $ε$-secure notion in the previous lecture I am confident about that). In other words, there is a \\(n\\) bit entropy loss. He then stated by using pseudorandomness, such problem can be solved.\nModern Cryptography: Computational Approach The content of the third handout starts from here, meaning the previous contents focus on perfect or statistical security, which although being secure against all-mighty adversaries, is utterly inefficient in practice. In particular, notice that the key space of a perfectly-secure encryption scheme has to be at least as large as its message space. This means that if we consider the key and message as binary strings, the key must be at least as long as the message, and that is obviously ineffective.\nThe modern approach of cryptography (i.e. the computational-complexity based approach) resolves this problem by relaxing the notion of security, in particular, only requiring security against efficient adversaries (since the asymptotic notion is considered in most cases, this means the advantage of the adversary ends in time polynomial in the security parameter). In this way, not only the efficiency can be improved, but also many other interesting and useful constructions can be built. (Recall that in the first course of Prof. Liu\u0026rsquo;s Modern Cryptographic Algorithm, it is explained that assuming one-way function exists, the entire symmetric cryptography can be constructed, e.g. pseudorandom generator, IND-CPA secure encryption etc.)\nThe lecture has different focus with the third handout. In particular, the handout proved several facts concerning the indistinguishability encryption test in the KL book, namely, any \\(\\mathsf{PPT}\\) adversary cannot guess with probability better than negligible one bit of the plaintext given the ciphertext in an indistinguishable encryption scheme. Another fact is one very similar to semantic security, except that auxiliary information is not considered. Once again, the Prof. Yu proves in the handout that the indistinguishability definition implies this semantic security-like definition. But the proof of the equivalence between indistinguishability and semantic security was not mentioned in the handout. I think in the lecture all of the above content was gone through in less than five minutes. The focus here was on computational-indistinguishability (the more general definition, on any distributions) and pseudorandom generator (which comes with the first hybrid argument proof).\nComputational Indistinguishable Encryptions Similar to the definition in the previous lecture, we define the indistinguishability experiment for private-key encryption scheme \\(\\mathcal{P}i = (\\mathsf{Gen},\\mathsf{Enc},\\mathsf{Dec})​\\) with respect to \\(\\mathsf{PPT}​\\) adversary \\(A=(A_1,D)​\\) here.\nFigure 4: Symmetric Key Encryption Security Experiment\nNote that in this experiment, since \\(A\\) is not all-mighty, and could use randomness in \\(A_1\\), state information (e.g. random coin used) is passed from \\(A_1\\) to \\(D\\). We call the encryption scheme \\(\\mathcal{P}i = (\\mathsf{Gen},\\mathsf{Enc},\\mathsf{Dec})\\) has indistinguishable encryptions in the presence of an eavesdropper if for all \\(\\mathsf{PPT}\\) adversaries \\(A\\), there exists a negligible function \\(negl(\\cdot)\\) such that \\(\\Pr[\\mathsf{PrivK}_{A,\\mathcal{P}i}^{eav}=1]\\le 1/2 + negl(\\kappa)\\), the probability is over the choice of key \\(k\\), bit \\(b\\), randomness used in the encryption, and randomness used in \\(A\\). An alternative way of defining this is to state that for all \\(\\mathsf{PPT}\\) adversaries \\(A\\), there exists a negligible function \\(negl(\\cdot)\\) such that \\(\\Pr[D(1^\\kappa,\\mathsf{Enc}_k(m_0),state)=1]-\\Pr[D(1^\\kappa,\\mathsf{Enc}_k(m_1),state)=1]\\le negl(\\kappa)\\), where \\((m_0,m_1,state)\\gets A_1(1^\\kappa)\\). The proof is similar to the one in the previous lecture. One point to note though, is that in the previous proof, \\(m_0\\) and \\(m_1\\) are arbitrary so long as they are not identical. This is because the definition considered all possible adversaries, and therefore it is equivalent to the case when \\((m_0,m_1)\\gets A_1(1^\\kappa)\\).\nPseudorandom Generator The definition of pseudorandom generator is as follows. Let \\(l(\\cdot)\\) be a polynomial and let \\(g\\) be a deterministic polynomial-time algorithm such that upon any input \\(s\\in\\{0,1\\}^n\\), the algorithm \\(g\\) outputs a string of length \\(l(n)\u0026gt;n\\). We say that \\(g\\) is a pseudorandom generator (PRG) if for all \\(\\mathsf{PPT}\\) distinguishers \\(D\\), there exists a negligible function \\(negl(\\cdot)\\) such that\n\\[ |\\Pr[D(g(U_n)=1)-\\Pr[D(U_{l(n)})=1]|\\leq \\mathsf{negl}(n), \\]\nwhere the probability is take over the random coins used by \\(D\\) and \\(U_n\\) (respectively \\(U_{l(n)}\\)). The difference between the output and input lengths \\(l(n)-n\\) is called the stretch factor of \\(g\\).\nAn Alternative Definition of PRG\u0026rsquo;s Security\nProf. Yu then introduced an alternative definition of PRG, namely \\((t,\\varepsilon)​\\) n-secure PRG. This is similar to the \\((t,\\varepsilon)​\\) -indistinguishable encryption in the handout. The definition states that if for any \\(\\mathsf{PPT}​\\) distinguisher \\(D​\\) of running time at most \\(t​\\), the advantage of the distinguisher on \\(g(U_n)​\\) and \\(U_{l(n)}​\\) is at most \\(\\varepsilon​\\). Prof. Yu then mentioned that when setting the parameters \\(t=n^{\\omega(1)}​\\) and \\(\\varepsilon=n^{o(1)}​\\), the two definitions are equivalent. (Right now I am convinced that \\((t,\\varepsilon)​\\) -secure implies the previous definition, but remain skeptical whether it is possible to construct an advantage that becomes non-negligible when \\(t​\\) becomes super-polynomial. But this seems not worthy of pursuing compared to the definitions and hybrid argument to be introduced later.)\nAt this point, Prof. Yu mentioned in the lecture (and also in the handout), that PRG\u0026rsquo;s security is only guaranteed against efficient adversaries. Consider \\(g:\\{0,1\\}^n\\to\\{0,1\\}^{l(n)}\\) as a PRG and an adversary \\(D: x\\mapsto x\\in g(\\{0,1\\}^n)\\), then the advantage of the adversary is\n\\begin{align*} \\Pr[D(g(U_n))=1]-\\Pr[D(U_{l(n)})=1] \u0026amp;= 1 - |g(\\{0,1\\}^n)|/2^{l(n)}\\\\ \u0026amp;\\ge 1-2^{n-l(n)}\\\\ \u0026amp;\\ge 1/2\\enspace. \\end{align*}\nThe last inequality holds since the stretch of the PRG is at least \\(1\\). This means the distinguisher \\(D\\) has constant advantage, and therefore the PRG \\(g\\) is definitely not secure in this case.\nReplacement Lemma\nThe \\((t,\\varepsilon)\\) -security of PRG enables a very versatile lemma called replacement lemma. I remember Prof. Yu mentioned this some afternoon in the lab the year before. He wrote this on the window of the lab and I remembered he asked someone to answer that. Anyway, the lemma states that if distribution \\(X\\) and \\(Y\\) is \\((t,\\varepsilon)\\) -indistinguishable, and function \\(f\\) (defined over the union of the two distributions\u0026rsquo; sample space) is \\(T\\) -computable, then the derived distribution \\(f(X)\\) and \\(f(Y)\\) is at least \\((t-T,\\varepsilon)\\) -indistinguishable.\nThe proof is actually rather simple. Suppose that the result does not hold, then by contradiction, there exists a distinguisher \\(D\\) that runs in time at most \\(t-T\\), and distinguishes the two distributions with probability larger than \\(\\varepsilon\\), namely \\[ |\\Pr[D(f(X))=1]-\\Pr[D(f(Y))=1]|\u0026gt;\\varepsilon. \\] This already implies contradiction to the assumption. In order to see this, consider a distinguisher \\(D^\\prime(\\cdot)=D(f(\\cdot))\\). This distinguisher will run in time at most \\(t\\), but will distinguish \\(X\\) and \\(Y\\) with probability greater than \\(\\varepsilon\\). And therefore the distribution \\(f(X)\\) and \\(f(Y)\\) is at least \\((t-T,\\varepsilon)\\) -indistinguishable.\nNote that this lemma can be used to explain the replacement property of statistical distance. Prof. Yu explained this in brevity but I think I can elaborate a little here. First consider the equivalent definition of statistical distance as the maximum advantage among all distinguishers (no constraint on computational power here), and that could be roughly translated into \\((\\infty,\\mathsf{SD}(X,Y))\\) -indistinguishable. By applying substracting a \\(T\\) from the infinity limit of the running time, no actual limit is applied to the distinguisher. Now, we have when \\(\\mathsf{SD}(X,Y)\\ge \\varepsilon\\), \\(f(X)\\) and \\(f(Y)\\) are at least \\((\\infty,\\varepsilon)\\) -indistinguishable, the advantage of any distinguishers on these two distributions is at most \\(\\varepsilon\\). By the fact that the maximum of advantage is just statistical distance, we get \\(\\mathsf{SD}(f(X),f(Y)) \\le\\varepsilon=\\mathsf{SD}(X,Y)\\).\nStretching the Output Length of PRG: Hybrid Argument By sequentially composing PRG to itself, a PRG with small stretch can be extended to get arbitrarily long pseudorandom bits. This is presented in the following lemma.\nLet\n\\begin{align*} g:\\{0,1\\}^{n}\u0026amp;\\to\\{0,1\\}^{n+s(n)}\\\\ s_i\u0026amp;\\mapsto(s_{i+1},r_{i+1})\\enspace, \\end{align*}\nwhere \\(s_i,s_{i+1}\\in\\{0,1\\}^n\\), \\(r_{i+1}\\in\\{0,1\\}^{s(n)}\\) be a \\((t(n),\\varepsilon(n))\\) -secure PRG, and for any \\(q(n)\\in\\mathbb{N}\\), define\n\\begin{align*} g^q:\\{0,1\\}^n\u0026amp;\\to\\{0,1\\}^{n+q(n)s(n)}\\\\ s_0\u0026amp;\\mapsto(s_{q(n)},r_{q(n)},r_{q(n)-1},\\ldots,r_1)\\enspace, \\end{align*}\nwhere for \\(0\\le i\\le q(n)-1\\), iteratively compute \\((s_{i+1},r_{i+1}):=g(s_i)\\). Then, we have that \\(g^{q(n)}\\) is a \\((t(n)-q(n)\\cdot\\mathsf{poly}(n), q(n)\\cdot\\varepsilon(n))\\) -secure PRG, where \\(\\mathsf{poly}(n)\\) is the running time of computing function \\(g\\).\nThe proof of this lemma demonstrated hybrid argument, which is extensively used in the field of cryptography. And since this is the first time it appears, it is worthwhile to pay more attention to that. I found that by using replacement lemma, some of the details of the proof in the handout can be hidden. The following is my slightly modified proof.\nLike in the handout, we define the following distributions (note by placing the old output in the right hand side, the output of the function can be depicted as growing to the left, leaving pseudorandom stretches on the right hand side, and the notion actually aligned the seeds on the left hand side, the blank space on the right side can be filled with anything, so long as they are identically distributed, the adjacent two distributions will only have one iteration\u0026rsquo;s difference. I think this is the intuition behind constructing the series of distributions, a series of padded mimic snapshots along with the growth of the pseudorandom bits.)\n\\begin{align*} H_0\u0026amp;\\overset{\\text{def}}{=}g^q(U_n)\\\\ H_1\u0026amp;\\overset{\\text{def}}{=}(g^{q-1}(U_n),U_s)\\\\ H_2\u0026amp;\\overset{\\text{def}}{=}(g^{q-2}(U_n),U_{2s})\\\\ \u0026amp;\\vdots\\\\ H_{q-1}\u0026amp;\\overset{\\text{def}}{=}(g(U_n),U_{(q-1)s})\\\\ H_{q}\u0026amp;\\overset{\\text{def}}{=}U_{n+qs}\\enspace.\\\\ \\end{align*}\nAfter this, we can observe that for any \\(i\\in[q]\\), the adjacent distributions \\(H_i\\) and \\(H_{i-1}\\) can be derived by applying $gq-i to the distribution in the assumption, namely, \\(g(U_n)\\) and \\(U_{n+s}\\), and padding \\(U_{(i-1)s}\\) to the right hand side of the random variables. By replacement lemma, \\(g(U_n)\\) and \\(U_{n+s}\\) is \\((t,\\varepsilon)\\) -indistinguishable, then the resulting distribution is \\((t-(q-i)\\cdot\\mathsf{poly}(n),\\varepsilon)\\) -indistinguishable, which implies it is \\((t-q\\cdot\\mathsf{poly}(n),\\varepsilon)\\) -indistinguishable. Then by using the triangle inequality, we have for any probabilistic distinguisher \\(D\\) with running time no more than \\(t-q\\cdot\\mathsf{poly}(n)\\), the advantage of \\(D\\) distinguishing $H_0 and \\(H_q\\) is\n\\begin{align*} |\\Pr[D(H_0)=1]-\\Pr[D(H_q)=1]| \u0026amp;\\leq \\sum_{i=1}^q|\\Pr[D(H_{i-1})=1]-\\Pr[D(H_i)=1]|\\\\ \u0026amp;\\leq q\\cdot\\varepsilon\\enspace, \\end{align*}\nand that completes the proof.\n18-19-2 Lecture 4 In this note, the content of this week\u0026rsquo;s lecture on provable security by Prof. Yu is summarized, from the handout and my own note taken at the lecture. This week\u0026rsquo;s lecture focuses on hardcore predicate of one-way function and Goldreich-Levin Theorem.\nLecture Content In this lecture the main focus is on the theoretical construction of pseudorandom generators. Namely, a lemma concerning hardcore bit of one-way permutation implies pseudorandom generator (which works the other way as well) and Goldreich-Levin theorem were introduced. The proof of Goldreich-Levin theorem uses a concept called list decoding, which is a little mind-blowing for me. The lecture begins by giving hints on the last homework of the second lecture.\nEquivalence Between Min-Entropy and Collision Entropy In the first ten minute of the lecture, Prof. Yu explained to the class how to give answer to the fourth question of the homework in the second handout. The problem is that given a distribution \\(X\\) with collision-entropy \\(\\mathbf{H}_2(X)\\geq k\\), \\(\\forall\\delta: 0\u0026lt; \\delta \u0026lt;1\\), it is possible to construct another distribution \\(Y\\) such that \\(\\mathbf{H}_\\infty(Y)\\geq k-\\log(1/\\delta)\\), and \\(\\mathsf{SD}(X,Y)\\le \\delta\\).\nThe answer to this question is given in the note of lecture 2. I think Prof. Yu\u0026rsquo;s answer implies that the rest of the set \\(S:=\\{x|\\Pr[X=x]\u0026gt;1/\\delta\\cdot2^{-k}\\}\\) can be ignored in the distribution of \\(Y\\). However, I think this will make the question rather disappointing, since constructing another distribution over the exact sample space of \\(X\\) seems like a stronger guarantee. This is why I argued about the upper bound of minimum probability in the previous answer. This guarantees that when putting the extra probability to the probability over the set \\(S\\), there exists an assignment that does not exceed the maximum probability requirement \\(\\Pr[Y=x]\\le 1/\\delta\\cdot2^{-k}\\).\nAnother point to note is that the result \\(\\Pr[X\\in S]\u0026lt;\\delta\\) can be treated as the result of Markov\u0026rsquo;s inequality. This is because we can treat the collision probability as the expectation of random variable \\(\\Pr[X]\\), which is no more than \\(2^{-k}\\). And ergo the result.\nOne-Way Functions and Permutations The definition of one-way function here is the same with that given in Prof. Liu\u0026rsquo;s lecture. Namely, given a function family \\(f:\\{0,1\\}^{n}\\to\\{0,1\\}^{l(n)}\\) is a one-way function ensemble if it is\nEasy-to-Compute: \\(f\\) can be computed by some algorithm in time \\(\\mathsf{poly}(n)\\),\nHard-to-Invert: for every \\(\\mathsf{PPT} A\\), there exists a negligible function \\(negl(\\cdot)\\) such that\n\\[ \\Pr_{X\\gets U_n,x^\\prime\\gets A(1^n,f(X))}[f(x)=f(x^\\prime)]\\le negl(n). \\]\nDespite the similarity, Prof. Yu did argued in the handout that the more formal definition, where the domain and ranges are arbitrary sets and explicit sampling algorithms may be needed to sample a random element over the domain.\nAn Intuitive Interpretation of Implication\nThe relationship between one-way function exists (denoted by \\(\\mathsf{OWF}\\)) and \\(\\mathcal{P}\\ne\\mathcal{NP}\\) was also mentioned in the class. \\(\\mathsf{OWF}\\) implies \\(\\mathcal{P}\\ne\\mathcal{NP}\\), or written in a more standard form, \\(\\mathsf{OWF}\\le\\mathcal{P}\\ne\\mathcal{NP}\\). In my intuitive opinion, this can be interpreted as there are two big truth tables with some entries\u0026rsquo; value unknown. But from some evidence we can conjecture that they are true. Now the stronger assumption (the one that implies others) has more entries that are conjectured correct, and the ones that need to be conjectured correct is only a subset of the first one. This already explained the first one\u0026rsquo;s conjecture correctness implies the second one\u0026rsquo;s correctness. What\u0026rsquo;s more, if by contradiction, an entry of the second one is wrong (contradicting the assumption), then we can surely say that the first conjecture is not correct (since all the conjectured entries need to be correct to make the assumption correct), which also means that the contradicting entry is more \u0026rsquo;lethal\u0026rsquo; than the other entries outside the subset in the first assumption. Since finding a more powerful false entry is harder, this explains why intuitively, the implies sign \u0026lsquo;\\(\\le\\)\u0026rsquo; can be understood as \u0026ldquo;the hardness is lesser or equal than\u0026rdquo;.\nOne-Way Functions based on Different Assuptions\nThere are different assumption on which one-way functions can be constructed. Some of them are listed in the handout, they are\nInteger Factorization, Subset Sum, and Discrete Logarithm. The first and third one have been extensively studied and tested in practice.\nHard-core Predicates of One-Way Functions The definition of hard-core predicate is as follows. A polynomial-time computable predicate \\(h_c:\\{0,1\\}^n\\to \\{0,1\\}\\) is called a hard-core predicate of a function \\(f\\) if for every \\(\\mathsf{PPT}\\) algorithm \\(A\\), there exists a negligible function \\(negl(\\cdot)\\) such that \\[ \\Pr_{X\\gets U_n}[A(1^n,f(X)=h_c(X)]\\leq 1/2+negl(n), \\] where the probability is take over the choice of \\(X\\) and the random coins of \\(A\\).\nNote that hard-core predicate exists implies one-wayness. The following theorem states that for one-way permutations, hard-core predicates imply the explicit construction of pseudorandom generators. The theorem is as follows.\nIf a permutation \\(f:\\{0,1\\}^n\\to\\{0,1\\}^n\\) has a hard-core predicate \\(h_c:\\{0,1\\}^n\\to\\{0,1\\}\\), then the function \\(g(x) = (f(x),h_c(x))\\) is a pseudorandom generator with a single bit stretch.\nThe proof given in the handout concerns deterministic distinguisher of pseudorandomness, and imposes stronger limit to the distinguisher of pseudorandomness (in that proof if the hard-core predicate is \\((t(n),\\varepsilon(n))\\) -hard then the output of \\(g(\\cdot)\\) is \\((t(n)/2,\\varepsilon(n))\\) -indistinguishable from \\(U_{n+1}\\)). I tried to improve the proof by concerning \\(\\mathsf{PPT}\\) adversaries and remove the loss in running time limit. The proof is as follows.\nSuppose by contradiction, there is a \\(\\mathsf{PPT}\\) adversary \\(A\\) of running time \\(t(n)\\) that can distinguish pseudorandomness such that\n\\[ \\Pr_{X\\gets U_n}[A(f(X),h_c(X))=1]- \\Pr_{X_1\\gets U_{n}, X_2\\gets U_1}[A(X_1,X_2)=1]\u0026gt; \\varepsilon(n)\\enspace. \\]\nObserve the latter probability can be written as \\[ 1/2\\cdot\\Pr[A(X_1,h_c(X_1))] + 1/2\\cdot\\Pr[A(X_1,1\\oplus h_c(X_1))], \\] which means \\[ 1/2\\cdot\\Pr_{X\\gets U_n}[A(f(X),h_c(X))=1]-1/2\\cdot\\Pr[A(X_1,1\\oplus h_c(X_1))]\u0026gt;\\varepsilon(n)\\enspace. \\] Now construct a \\(\\mathsf{PPT}\\) algorithm \\(D\\) that computes the hardcode bit of input, given the output of the one-way permutation. After \\(D\\) gets its input \\(f(X)\\), it samples a random bit \\(b\\gets U_1\\), and then calls \\(A\\), and get \\(b^\\prime \\gets A(f(X),b)\\). If \\(b^\\prime = 1\\), output \\(b\\); else, output \\(1\\oplus b\\).\nThe probability that \\(D\\) succeed is as follows,\n\\begin{align*} \\Pr_{X,b,r}[\\text{D wins}]\u0026amp;=\\Pr[b=h_c(X)]\\cdot \\Pr[b^\\prime=1|b=h_c(X)]+\\Pr[b=1\\oplus h_c(X)]\\cdot \\Pr[b^\\prime=0|b=1\\oplus h_c(X)]\\\\ \u0026amp;=1/2\\cdot\\Pr[A(f(X),h_c(X))=1]+ 1/2\\cdot(1-\\Pr[A(f(X),1\\oplus h_c(X))=1])\\\\ \u0026amp;\u0026gt;1/2 + \\varepsilon(n)\\enspace. \\end{align*}\nAnd that contradicts the assumption that \\(h_c(\\cdot)\\) is a (\\(t(n)\\),\\(\\varepsilon(n)\\))-hard-core predicate for one-way permutation \\(f\\).\nReverse Thinking\nNote that the previous theorem essentially states that next bit unpredictability implies pseudorandomness. Actually the result works in the other direction as well. Namely, for a pseudorandom generator \\(g:\\{0,1\\}^n\\to\\{0,1\\}^{l(n)}\\), \\(\\forall i \\in [l(n)-1]\\), \\(\\forall \\mathsf{PPT} A\\), there exists a negligible function \\(negl(\\cdot)\\), such that \\[ \\Pr_{X\\gets U_n}[A(f(X)_{[1:i]})=f(X)_{[i+1]}] \\le 1/2 + negl(n). \\] This is actually quite trivial (which I failed to realize after it was brought up in class, when Prof. Yu noticed me mumbling, as if I knew how to prove it, but it turned out I could not present the complete answer). Suppose that there exists some position \\(i\\) and a algorithm $A that satisfies the above probability\u0026rsquo;s negation, then for the construction of pseudorandom distinguisher \\(D\\), apply the first \\(i\\) bits of the input to \\(A\\) and output \\(1\\) if the predicted bit equals \\(f(X)_{[i+1]}\\). The probability of \\(D\\) outputting \\(1\\) in the case of real randomness is \\(1/2\\), and in the pseudorandom case, it is \\(\\Pr_{X\\gets U_n}[A(f(X)_{[1:i]})=f(X)_{[i+1]}]\\). It is obvious that the advantage of the adversary is non-negligible.\nUniversal Construction of Hard-Core Predicates: Goldreich-Levin Theorem\nDigested from the handout, we have \u0026ldquo;It was conjectured that every one-way function has a hard-core predicate, and this was proven by Goldreich and Levin in STOC 1989.\u0026rdquo; Prof. Yu mentioned that the creativity of this proof is that it uses Chebyshev\u0026rsquo;s inequality instead of Chernoff bound, which does not require all components are independent, but only pairwise independent. And that reduces the number of guesses needed in the proof, and therefore increases the success probability as well.\nThe proof given in the handout is the complete proof, unlike in the KL book, where the proof is given in steps, first a simplified case, then the full proof. Prof. Yu did managed to organize the proof in separate independent modules. There are mainly two techniques in this proof, in my opinion. The first one is how to use list decoding to convert a couple of guesses of the hard-core bit into an inversion of the preimage with high probability (\\(1/2\\) to be specific). The other one is to use Chebyshev\u0026rsquo;s inequality instead of Chernoff bound, which could reduce the number of guesses needed, ergo increasing the success probability of the inversion algorithm.\nThere is one remaining problem to be solved. I think the number of guesses \\(l=\\lceil\\log(1+2n/\\varepsilon(n)^2)\\rceil\\) does not guarantees \\(2^{-l}\\ge\\varepsilon(n)^2/4n\\) (although $2-l≥ε(n)^2/8n can be guaranteed).\nThe proof is as follows. Suppose by contradiction there exists a \\(\\mathsf{PPT}\\) algorithm \\(A\\) such that \\[ \\Pr_{x\\gets U_n,r\\gets U_n}[A(f(x),r)=\\mathsf{gl}(x,r)]\u0026gt;1/2+\\varepsilon(n), \\] where the probability is taken over the choice of \\(x, r​\\) and the internal random coins of \\(A​\\). We first argue there exists a set \\(S​\\) of size \\(|S| \\ge \\varepsilon(n)/2​\\) such that \\(\\forall x \\in S, \\Pr_{r\\gets U_n}[A(f(x),r)=\\mathsf{gl}(x,r)]\u0026gt;1/2+\\varepsilon(n)/2​\\). This is due to Markov\u0026rsquo;s inequality (not the normal form, since the direction of inequality is inversed). Note that\n\\begin{align*} \\Pr_{x\\gets U_n,r\\gets U_n}[A(f(x),r)=\\mathsf{gl}(x,r)] \u0026amp;=\\sum_{x}\\Pr[X=x]\\cdot\\Pr_{r\\gets U_n}[A(f(x),r)=\\mathsf{gl}(x,r)]\\\\ \u0026amp;\\le\\Pr[X\\not\\in S]\\cdot(1/2+\\varepsilon(n)/2)+\\Pr[X\\in S]\\\\ \u0026amp;\\le 1/2+\\varepsilon(n)/2 +\\Pr[X\\in S]\\enspace, \\end{align*}\nwhich means \\(\\Pr[X\\in S]\\ge \\varepsilon(n)/2\\). Conditioned on \\(X\\in S\\), we construct the following efficient algorithm that can invert \\(f\\) given \\(f(x):x\\in S\\) with probability no less than \\(\\varepsilon(n)^2/16n\\) (in the handout this is \\(\\varepsilon(n)^2/8n\\) but I think that might have a tiny problem). This reduces our problem to constructing such an algorithm.\nThe inversion algorithm \\(A^\\prime​\\) works as follows. (Let \\(l = \\lceil\\log(2n/\\varepsilon(n)^2+1)\\rceil​\\).)\nUniformly and independently samples \\(s^1,\\ldots,s^l\\gets U_n\\), and \\(\\sigma^1,\\ldots,\\sigma^l\\gets U_1\\), where \\(\\sigma^i\\) is a guess for \\(\\mathsf{gl}(x,s^i)\\). For every non-empty subset \\(\\mathcal{I}\\subseteq [l]\\), let \\(r^{\\mathcal{I}}\\overset{\\text{def}}{=}\\mathop{\\oplus}_{i\\in\\mathcal{I}}s^i\\), \\(\\tau^{\\mathcal{I}}\\overset{\\text{def}}{=}\\mathop{\\oplus}_{i\\in\\mathcal{I}}\\sigma^i\\). Each \\(\\tau^{\\mathcal{I}}\\) is a guess for \\(r^{\\mathcal{I}}\\), because if all the \\(\\sigma^i\\)\u0026rsquo;s are correct guesses, the resulting \\(\\tau^{\\mathcal{I}}\\)\u0026rsquo;s are also correct guesses. For every \\(j \\in [n]\\), make a guess about the \\(j^{\\text{th}}\\) bit of input \\(x\\), denoted by \\(x_j\\), as follows: For every non-empty subset \\(\\mathcal{I}\\subseteq [l]\\), set \\(v_j^{\\mathcal{I}}:=\\tau^\\mathcal{I}\\oplus A(f(x),r^{\\mathcal{I}}\\oplus e_j)\\), where\n\\[ e_j \\overset{\\text{def}}{=}\\underbrace{0\\ldots0}_{j-1} 1\\underbrace{0\\ldots0}_{n-j}. \\]\nDo a majority voting on candidate values \\(\\{v_j^{\\mathcal{I}}:\\emptyset \\ne\\mathcal{I}\\subseteq[l]\\}\\), and let \\(x_j^\\prime\\) be the majority bit of them.\nNow we claim that conditioned on \\(x \\in S\\), the success probability of \\(A^\\prime\\) is over \\(\\varepsilon(n)^2/16n\\). First of all, The probability of \\(\\sigma^1,\\ldots,\\sigma^{l}\\) all being correct guesses is $2-l which is greater than \\(\\epsilon(n)^2/8n\\) (this is where the divergence comes from). Conditioned on that, we now analyze the probability that voting on bit \\(x_j\\) succeeds. Recall that we have already proved\n\\begin{align*} \\Pr_{X\\gets U_n}[A^\\prime(f(X)) = X]\u0026amp;\\ge\\Pr_{X\\gets U_n}[X\\in S]\\cdot\\min_{x\\in S}\\Pr[A^\\prime(x)=x]\\\\ \u0026amp;\\ge \\varepsilon(n)/2 \\cdot\\varepsilon(n)^2/8n \\cdot\\min_{x\\in S} \\Pr[x^\\prime_1=x_1\\land x^\\prime_2=x_2\\land\\ldots\\land x^\\prime_n=x_n]\\\\ \u0026amp;=\\varepsilon(n)/2 \\cdot\\varepsilon(n)^2/8n\\cdot (1- \\min_{x\\in S} \\Pr[x^\\prime_1\\ne x_1\\lor x^\\prime_2\\ne x_2 \\lor\\ldots\\lor x^\\prime_n\\ne x_n])\\\\ \u0026amp;\\ge\\varepsilon(n)/2 \\cdot\\varepsilon(n)^2/8n\\cdot (1- \\sum_{i\\in[n]}\\Pr[x^\\prime_i\\ne x_i])\\enspace, \\end{align*}\nwhere from the second line the probability is conditioned on all \\(\\sigma^i\\)\u0026rsquo;s are correct guesses and the last inequality is from union bound and the requirement of \\(x\\) is from the previous equation. It suffices to prove for any \\(x\\in S\\), \\(\\Pr[x^\\prime_i\\ne x_i]\\le 1/2n\\) for all \\(i\\in [n]\\), and we will prove it below.\nNote that in the third step of \\(A^\\prime\\), if the \\(j^{\\text{th}}\\) bit of \\(x\\) is \\(0\\), then adding \\(e_j\\) to \\(r^{\\mathcal{I}}\\) does not change the hard-core bit, and the output \\(v_j^{\\mathcal{I}}\\) will be \\(0\\). On the other hand, if \\(x_j = 1\\), then the output will be inverted and \\(v_j^{\\mathcal{I}}=1\\). This means \\[ \\Pr[v_j^{\\mathcal{I}}\\text{ is correct}] = \\Pr[A(f(x),r^{\\mathcal{I}}) = \\mathsf{gl}(x,r^\\mathcal{I})] \\ge1/2+\\varepsilon(n)/2. \\] Let \\(m = 2^{l}-1 \u0026gt; 2n/\\varepsilon(n)^2\\), which is the number of candidates for the majority voting, and denote \\(\\mathsf{E}^\\mathcal{I}\\) be the event that \\(v_j^{\\mathcal{I}}\\) is correct. By the construction of \\(r^{\\mathcal{I}}\\)\u0026rsquo;s, we have that they are pairwise independent. Now we analyze the probability of the event that less than half of the \\(v_j^{\\mathcal{I}}\\)\u0026rsquo;s are correct, which is\n\\begin{align*} \\Pr[\\sum_{\\mathcal{I}\\in[l]}\\mathsf{E}^{\\mathcal{I}}\u0026lt;m/2] \u0026amp;= \\Pr[\\sum_{\\mathcal{I}\\in[l]}\\mathsf{E}^{\\mathcal{I}}-m\\mu\u0026lt;m/2-m\\mu]\\\\ \u0026amp;\\le\\Pr[\\sum_{\\mathcal{I}\\in[l]}\\mathsf{E}^{\\mathcal{I}}-m\\mu\u0026lt;-m\\cdot\\varepsilon(n)/2]\\\\ \u0026amp;\\le\\Pr[|\\sum_{\\mathcal{I}\\in[l]}\\mathsf{E}^{\\mathcal{I}}-m\\mu|\u0026gt;m\\cdot\\varepsilon(n)/2]\\\\ \u0026amp;\\le \\frac{Var(\\sum_{\\mathcal{I}\\in[l]}\\mathsf{E}^{\\mathcal{I}})} {(m\\cdot\\varepsilon(n)/2)^2}. \\end{align*}\nThe last inequality is due to Chebyshev\u0026rsquo;s inequality. Note that since each two \\(\\mathsf{E}^{\\mathcal{I}}\\)\u0026rsquo;s are pairwise independent, this means\n\\[ Var(\\sum_{\\mathcal{I}\\in[l]}\\mathsf{E}^{\\mathcal{I}}) = \\sum_{\\mathcal{I}\\in[l]}Var(\\mathsf{E}^{\\mathcal{I}}) \\le m\\cdot 1/4. \\]\nBringing that to the equation above, we have\n\\begin{align*} \\Pr[\\sum_{\\mathcal{I}\\in[l]}\\mathsf{E}^{\\mathcal{I}}\u0026lt;m/2] \u0026amp;\\le \\frac{Var(\\sum_{\\mathcal{I}\\in[l]}\\mathsf{E}^{\\mathcal{I}})}{(m\\cdot\\varepsilon(n)/2)^2}\\\\ \u0026amp;\\le\\frac{m\\cdot1/4}{m^2\\cdot\\varepsilon(n)^2\\cdot1/4}\\\\ \u0026amp;\\le\\frac{1}{2n/\\varepsilon(n)^2\\cdot\\varepsilon(n)^2}\\\\ \u0026amp;=1/2n. \\end{align*}\nAnd that completes the proof of Goldreich-Levin Theorem.\nA Central Theorem in Cryptography The previous two lemma combined gives us the result one-way permutation implies pseudorandom generators. In fact, a more general statement that one-way function implies pseudorandom generators is also true. This is proved by Håstad et al. in [HILL99]. The proof is much more involved and not suitable for this lecture. Prof. Yu mentioned in class that this construction is more of theoretical interest than of practical value, since the loss in efficiency, although polynomial, is still very large. The simplified cases are that of one-way permutations (which has already been proved), and regular one-way functions (every image has the same number of preimages).\nHomework The handout of this lecture has five homework problems. The first one is to improve the advantage loss in the original proof. The rest of the problems are from KL book.\nImproving the Advantage Loss in the Proof of Goldreich-Levin Theorem\nWhat the previous proof proves is essentially assuming some algorithm \\(A\\) of running time \\(t(n)\\) can guess the hard-core bit with probability better than \\(1/2 + \\varepsilon(n)\\), then there is another algorithm \\(A^\\prime\\) of running time \\(\\mathsf{poly}(1/\\varepsilon(n),n)\\) that can compute \\(x\\) from \\(f(x)\\) with probability better than \\(\\varepsilon(n)^3/16n\\) (which is non-negligible if \\(\\varepsilon(n)\\) is). This is a stronger guarantee than the one required in one-wayness experiment, where only \\(x^\\prime \\in f^{-1}(f(x))\\) is needed. If we add a simple check after \\(A^\\prime\\) output \\(x^\\prime\\), and re-guess \\(x\\) with fresh randomness if \\(f(x^\\prime)\\ne f(x)\\), we can increase the success probability to \\(\\varepsilon(n)/4\\).\nThere is a detail that need to be paid attention to in the previous argument. The first probability that \\(x\\in S\\) only considers the very preimage \\(x\\), while in the modified proof, we need to consider all other preimages. Actually, this is not a problem, since the only information that \\(A\\) learns is \\(f(x)\\), and that is the same for all other preimages \\(x^\\prime \\in f^{-1}(f(x))\\). Conditioned on \\(x\\in S\\), we can safely conclude that all other preimages are in \\(S\\).\nThe other point I think may be a caveat is that by repeating the guessing process, we need to calculate the expected running time of \\(A^\\prime\\), since it\u0026rsquo;s halting is probabilistic now. This should not be a big problem, since the success probability of one guessing is more one over some polynomial, and the inverse is smaller than that polynomial, on infinitely many \\(n\\)\u0026rsquo;s. Despite this, the specific halting strategy should be specified to make sure \\(A^\\prime\\) runs in polynomial time.\nExercise 6.1 from KL Book\nFor \\(f(x,y) = x+y\\), output \\((x+y,0)\\) on the output; for \\(f(x)=x^2\\), just use interpolation to find \\(x\\).\nExercise 6.2 from KL Book\nAssuming \\(f:\\{0,1\\}^n\\to\\{0,1\\}^{l(n)}​\\) is a one-way function (family), it follows from one-wayness that for all \\(\\mathsf{PPT}​\\) algorithm \\(A​\\), there exists a negligible function \\(negl(\\cdot)​\\) such that \\[ \\Pr_{X\\gets U_n,x^\\prime\\gets A(f(X))}[f(x^\\prime)=f(X)] \u0026lt; negl(n). \\] Now construct another function \\(f^\\prime:\\{0,1\\}^n\\to\\{0,1\\}^{l(n)}\\) that behaves exactly like \\(f\\) except on \\(x=0^n\\), where it outputs \\(0^{l(n)}\\). For any \\(\\mathsf{PPT}\\) algorithm \\(A\\), the success probability of inverting \\(f^\\prime\\) is\n\\begin{align*} \\Pr_{X\\gets U_n,x^\\prime\\gets A(f^\\prime(X))}[f^\\prime(x^\\prime)=f^\\prime(X)]\\leq2^{-n}+\\Pr_{X\\gets U_n,x^\\prime\\gets A(f(X))}[f(x^\\prime)=f(X)]\\enspace, \\end{align*}\nwhich is still negligible. This means \\(f^\\prime\\) is also a one-way function. The KL book maybe tries to tell me one-wayness is a statistical result, changing one term will not essentially change the overall characteristics.\nExercise 6.4 from KL Book\nThe proof is trivial.\nExercise 6.6 from KL Book\nIf \\(f(\\cdot)\\) is a one-way function, then \\(g(x) = f(f(x))\\) is a one-way function. This is because \\(f\\) is efficiently computable, and therefore it is easy to construct an algorithm to invert \\(f\\) given an algorithm to invert \\(g\\). The second part is essentially the same.\nPilot Course Basic Information Lecturers: 郁昱, 刘振 Canvas website: oc.sjtu.edu.cn/courses/19984 Outline Testing Signing in (not accounted as score reference) Since this is only a testing course, absence will not be penatied. Testing Zoom website Begin at exactly 8:55 15 students enrolled Class Outline Classical Cryptography Modern Cryptography Post-quantum Cryptography Concluding Remarks Natural Proof: inbetween area between security and insecurity. Correspondence between crypto, complexity and math Cryptography Complexity Math PRG, Stream Cipher PRG, Derandomization PRF, Block Ciphers, Authentication Hardness of learning, Natural proof barrriers Privacy amplification Randomness extraction Expanders, Ramsey Graphs Succinct ZK arguments PCP, Locally testable Codes Leakage-resilient crypto Dense model theorems, hardcore sets primes in arithmetic progression Obfuscation Hard search problems private information retrieval locally decodable codes extremal set theory HE, homomorphic secret sharing locally random reductions, program checking Lecture 1 Introduction Not all slides will be uploaded to canvas prior to the lecture.\nProvable security is an important aspect of modern cryptography.\nPrerequisites:\nread formal proofs analyze complexity of algorithms familiarity with basic probability theory Textbooks:\nKL book Foundations of cryptography research papers What is Cryptography Cryptography is a part of modern theoretical computer science. Pseudorandomness, communication complexity, and ZK are also useful tools in TCS in general.\nGodel prize topics:\nNatural proof \u0026ndash; problems that are hard to prove or disprove, natural proof proves that the proof itself is hard. Cryptography is not all like mathematics. In crypto, people are only concerned with moderate problems, and efficient algorithms.\nMore on that table:\nCryptography Complexity Math PRG, Stream Cipher PRG, Derandomization PRF, Block Ciphers, Authentication Hardness of learning, Natural proof barrriers Privacy amplification Randomness extraction Expanders, Ramsey Graphs Succinct ZK arguments PCP, Locally testable Codes Leakage-resilient crypto Dense model theorems, hardcore sets primes in arithmetic progression Obfuscation Hard search problems private information retrieval locally decodable codes extremal set theory HE, homomorphic secret sharing locally random reductions, program checking Classic Cryptography Traditionally the definition is about secure communication, while the modern verison is more versatile.\nBasic primitives: one-way function: for randomly chosen pre-image, it is hard to find any pre-image correponding to the image. pseudorandom generator: randomness amplification pseudorandom function: PRG, but even better Some basic tasks: encryption: transformation of message that protects message against evasdroppers MAC/Signature: protect message integrity the previous is the symmetric case while the latter one is public-key case Secure computation: protect input privacy while preserving functionality Applications: Secure communication authetication digital signature (MAC, but better) privacy-preserving computation: MPC, HE, Obfuscation, etc. Obfuscation originates from software code protection, crypto community wants to formalize it and enhance upon it, but so far no satisfying results.\nCombination of previous tools Symmetric Key Encryption (SKE) A triplet of algorithms\nKey Generation: \\(k \\gets KeyGen(1^\\kappa)\\) Encryption: \\(c \\gets Enc(m, k)\\) Decryption: \\(m^\\prime \\gets Dec(c, k)\\) Symmetric in the sense that the two parties share common secret knowledge beforehand.\nProperties:\nCorrectness: BPP or P Security: passive or active, computaitonally bounded or unbounded (not like oracles) Examples in classical cryptography:\nCaesar Cipher, Enigma\nShannon\u0026rsquo;s OTP\nJust operations on the GF2 field. Perfectly secure in the sense that ciphertext is independent of message. In other words, the mutual information between ct and message is zero.\nPerfect secrecy\u0026rsquo;s limitation: \\(|K| = |M|\\)\nShannon\u0026rsquo;s Entropy \\(H = \\sum_i p_i \\cdot \\log(1/p_i)\\) \\(I(X;Y) = H(X) - H(X|Y)\\)\nAdversarial Model Cihpertext-only attack known-plaintext attack chosen-plaintext attack chosen-ciphertext attack How to argue security Using reduction based proofs. If problem A is computationally hard, then crytpo system B is secure against PPT adversaries. In practice, this is done through showing that algorithm for B can be efficiently converted to algorithm for A.\nPublic Key Cryptogrpahy Also a triplet of algorithms\nKeygen Encryption Decryption Definition of security: CPA game.\nModern Cryptography Modern crypto bases security upon computationally hard problems, which is what PKE do. But SKE normally does not have this requirement (e.g. AES, DES).\nThe dawn of modern cryptogrphy: DH, RSA.\nDecisional DH assumption: \\((g^x, g^y, g^{xy}) \\sim (g^x, g^y, g^z)\\)\nPseudorandomness to break shannon\u0026rsquo;s barrier: BMY generator (hybrid argument)\nThe hierarchy of cryptography Algorithmica: \\(\\mathcal{P}=\\mathcal{NP}\\) Heuristica: \\(\\mathcal{P}\\neq \\mathcal{NP}\\) Pessiland: no OWF Minicrypt: exists OWF Cryptomania: exists PKC and MPC One-way functions: the minimal assumption for cryptography. Notice this is in the average case sense. HILL theorem states that OWF implies PRG.\nNot all cryptographic primitive has secret CRHF: hard to find collision for a random instance of hash function. \\[\\Pr_{h\\gets H}[A(h)=(x,x^\\prime): x\\neq x^\\prime, h(x) = h(x^\\prime)]\\]\nPractical instantiations of CRHF: MD5, SHA1, SHA256, SHA3\nBut what about a family of algorithms? This is due to definitional problems.\nTwo party computation Garbled circuit in [Yao82b]. For practical application, c.f. Netherland sugar beat auction case.\nThe Quantum CRYSIS Shor\u0026rsquo;s algorithm: solves DL and Factoring in poly-time Grover\u0026rsquo;s algorithm: general quadratic speed-up It is believed that \\(BQP \\ne NP\\).\nNIST PQC candidate announcement.\n``GOOD\u0026rsquo;\u0026rsquo; assumptions include:\nLattice-based: e.g. LWE Code-based: e.g. LPN Hash-based: limited to digital sinature Multivariate: no provable security? LWE and LPN problem, solving noisy equations over finite-field, similar to solving equations over finite-field (plain elimination) or solving noisy equations over infinite-field (projection), but actually different.\nDecoding Random Linear q-ary codes. Message is \\(s\\), generation matrix is \\(A\\), noisy codeword is \\(A \\cdot s + e\\). This problem is NPC in the worst case, also hard in the average case (the famous reduction).\nLPN: sub-exponential algorithm exists but that\u0026rsquo;s all for the status quo. BKW: time complexity is \\(2^{n/\\log n}\\) for constant noise rate.\nLPN-based PKE (one-bit) Alice (the receiver): \\(a\\gets \\{0,1\\}^{n\\times n}\\), \\(sk = s^T\\), \\(e^T \\gets B_\\mu^n\\) \\(pk = (a, s^T \\cdot a + e^T)\\)\nBob (the sender): \\(s_1,e_1\\gets B_\\mu^n\\) \\(c_1 = a\\cdot s_1 + e_1\\), \\(c_2 = b^T \\cdot s_1 + m\\)\nSecurity is easy to prove since all the messages are LPN instances or hard core bits.\nPiling-up lemma: for \\(x,y\\gets B_\\mu^{2n}\\): \\(\\Pr[x^T\\cdot y = 0]\\ge 1/2 + 2^{O(-n\\mu^2)}\\).\nLecture 2 Recaping Last Lecture CRHF Hard to find collision, and it can be based on several mathematical assumptions. Another caveat is that in this definition, we consider a family of functions \\(\\mathcal{H}\\), while in practice we only have only one algorithm, e.g. SHA256, MD5.\nNote that in non-uniform model the collision can be modelled as auxiliary input, and thus the one-algorithm definition can be trivially broken.\nMultiparty Computation Nothing is leaked beyond the input and output information.\nDecoding Random Linear Code Lattice / LPN based assumptions are these types of assumption. The latest achievement based on these assumptions are Gentry in STOC 2009.\nIntroducing the homomorphic evaluation function \\(\\mathsf{Eval}(pk, f, c_1,\\ldots,c_t)\\)\nImportant Limitation: Complexity of decrypting \\(c^*\\) must not depend on the complexity of \\(f\\). Otherwise, one trivial solution is to keep all the ciphertext inputs and the description of function f, then in decryption, just decrypt and then evaluate. This goes against the goal of computation outsourcing.\nCryptography is full of conjecture, surprisingly equivalence, and impossibility results.\nA good / famous example is Alice\u0026rsquo;s Jewelry Store. Worker (server) works (evaluates) on raw materials (inputs) to produce jewelry (output).\nThis is like MPC, but only one round of communication, very efficient in communication.\nPre-2009 schemes are so called somewhat homomorphic, not fully.\nPreliminaries of Provable Security Writing a formal proof Conditionally by a reduction Unconditionally constructively or existentially Most crypto proofs are conditional, the minimal assumption is the existence of one-way function. And the existence of OWF considers average-case hardness (most instances are hard), while \\(\\mathcal{P} \\ne \\mathcal{NP}\\) considers worst case hardness.\nThough seemingly groundless, conjectures like RSA seems robust enough. A French team successfully conducts cryptanalysis on ~ 800bits RSA.\nUnconditionally proof usually involves information theory. Constructive results are surely more satisfying than existential solution (which only provides one-bit).\nDisproof provide one counterexample is sufficient Proof hard to prove shows that the proof itself is hard to come up with. Examples\nShows the number of primes are infinite Use simple proof technique For sequentially ordered primes \\(p_1,\\ldots,p_n\\), is \\(p_1\\cdot p_2 \\cdot \\ldots \\cdot p_n \\pm 1\\) prime as well? No, the prime list is not complete. Related problems are twin prime conjecture. Binary linear code. A binary (m,n)-code has dimension n and length m. The generator matrix is of size n by m. Nearest Codeword Problem (NCP): given the generator matrix C and noisy codeword \\(t^T = s^T \\cdot C + x^T\\). Noise x is limited by its hamming weight which is exactly \\(d\\). The solution is \\(s^\\prime\\) such that\n\\[ s^T \\cdot C + x^T = s^{\\prime T} \\cdot C + x^{\\prime T} \\]\nShow most linear codes have unique decoding when codeword length \\(m\\) is large enough.\nFigure 5: Proof of Unique Decoding of LPN\nThis is an example of existential probablistic proof.\nNotations on rv\u0026rsquo;s and sets Sets \\(\\{0,1\\}\\) is the most common one.\nNotations of probability distribution non-negativity maps from sample space to real number in [0,1] add up to one Random variables very similar to distribution\nEvents and Independence Event is actually a subset of sample space, independent events are two \u0026ldquo;regular\u0026rdquo; subspace. By regular I mean conditioning on one event the other one has the same probability.\nIndependent variables: for every possible value, the corresponding events are independent.\nPolynomial and friends Efficient algorithm means polynomial-time computable. In cryptogrpahy, we want the problem for adversary is super-polynomial hard while the success probability is some inverse of super-polynomial function.\nA function \\(f\\) is superpolynomial if for every constant \\(c\u0026gt;0\\) and all sufficiently large \\(n\\) we have \\(f(n) \u0026gt; n^c\\).\nNegligible function is the inverse of some superpolynomial. E.g. \\(2^{n/2}\\), \\(n^{\\log n}\\)\nOverwhelming and non-negligible overwhelming 1 - negligible non-negligible not negligible (larger than some polynomial for infinitely-many n\u0026rsquo;s) noticible larger than some inverse of polynomial Example of non-negligible but non-noticible function: \u0026ldquo;punch-out\u0026rdquo; function at all even / odd points.\nAsymptotic functions big-oh notations.\nAsymptotic Meaning \\(o\\) \\(\\leq\\) \\(\\omega\\) \\(\\geq\\) \\(\\theta\\) \\(=\\) \\(o\\) \\(\u0026lt;\\) \\(\\omega\\) \\(\u0026gt;\\) Function Ensembles Different functions for different problem scale.\nExample: one-way function\nUsual mathematical objects are functions of the security parameter.\nUnion bound and Markov inequality Union Bound:\nMarkov Bound: \\(\\Pr[X \\ge \\delta \\mathbb{E}[X] ]\\le 1/\\delta\\)\nChebyshev\u0026rsquo;s Inequality \\[ \\Pr[|X-\\mu|\\ge \\delta\\sigma] \\le 1/{\\delta^2} \\]\nChernoff bound and Hoeffding Bound There are additive form and multiplicative form\nPiling up Lemma and misc We have \\(\\Pr[\\bar{x} = 1] = 1/2 - 1/2 \\cdot (1 - 2\\mu)^n\\)\nExtreme cases: \\(\\mu = 0\\) nothing changes; one \\(\\mu = 1/2\\) then the result is random.\nFact 1. For any \\(0\\le x \\le 1\\) it holds that \\(\\log_2 (1+x) \\ge x\\). For any \\(x \u0026gt; -1\\) we have \\(\\log (1+x) \\le x / \\ln 2\\) Fact 2. Binominal approximation ANOTHER HOMEWORK on the existence of independent code Lecture 3 How to do last lecture\u0026rsquo;s homework If C is a random matrix, then Cr is uniformly random. The answer will not be distributed today, though.\nStatistical distance / indistinguishability and the LHL First define the indistinguishability experiment.\nThere are three levels of security:\nUnconditionally secure / information-theoretically secure advantage has zero advantage Statistically secure adversary has negligible advantage Computationally secure pseudorandomness, etc. The experiment here is about private key encryption\nFigure 6: Private Key Encryption Experiment\nThe adversary\u0026rsquo;s advantage is \\(\\mathsf{Adv}{eav}{\\mathcal{A},\\mathcal{P}i} = \\Pr[b^\\prime = b] -1/2\\) Notice here the adversary is considered to be all-powerful, and so it can determine which random coin is the most advantageous, and so it doesnot has to be a randomized algorithm, or to keep state information.\nThe above algorithm can also be transformed into an indistinguishability game, such that the same \\(\\varepsilon\\) is still the bound. We can use conditional probability to prove this equivalence.\nOne-time pad is perfectly secure OTP is defined over \\(\\{0,1\\}^n\\), we want to prove that this is perfect-secure. And it is so simple, since any two ciphertexts are distributed identically, so any adversary\u0026rsquo;s advantage is zero.\nStatistical Distance For two distributions X,Y, the statistical distance is defined as:\n\\[\\mathsf{SD}(X,Y):=1/2 \\sum_x \\left|\\Pr[X=x]-\\Pr[Y=x]\\right|\\]\nAnd we can define conditional statistical distance \\(\\mathsf{SD}(X,Y|Z):= \\mathsf{SD}((X,Z),(Y,Z))\\).\nThe 1/2 in the definition is to normalize the output to the range of [0,1].\nSD provides a upper bound of the advantage of distinguishing two distributions. This can be seen as \\(D\\) defines a distribution on the support. The best we can do is to let it maximize the success probability (in the distinguishing game) on every input.\nSD is a metric since it has:\nnon-negativity identity of indiscernibles symmetry \\(\\mathsf{SD}(X,Z) \\leq \\mathsf{SD}(X,Y) + \\mathsf{SD}(Y,Z)\\) Furthermore, it has the following property: the equality holds when supports of \\(X,Y\\) are disjoint. for every function \\(f\\), \\(\\mathsf{SD}(f(X),f(Y))\\leq\\mathsf{SD}(X,Y)\\) Statistical Security for OTP An application of replacement lemma can prove the indistinguishability when replacing the key distribution from uniformly random to statistically close to uniformly random. This can be understood intuitively by that the two ciphertexts are both \\(\\varepsilon\\) close to the uniform distribution, and they are at most \\(2\\varepsilon\\) far away.\nEntropy Renyi entropy of order \\(\\alpha \\ge 0\\) and \\(\\alpha \\ne 1\\) is defined as: \\[H_{\\alpha}(X):=\\frac{1}{1-\\alpha}\\log\\left(\\sum_{i}p_i^\\alpha\\right)\\]\n\\(\\alpha = 0\\) we have max-entropy; \\(\\alpha = 2\\) we have collision entropy, i.e. \\(-\\log(\\sum_i p_i^2)\\); \\(\\alpha \\to 1\\) it converges to Shannon entropy; \\(\\alpha \\to \\infty\\) we have min-entropy, minus log of the maximum probability. A classical example: a key that has 1/2 probability to take all zeros, and the other cases uniform over all other possibilities. It has about n/2 Shannon entropy, but still a very bad key source. We should instead focus on min-entropy.\nTwo lemmas about indistinguishability Pilling-up lemma\nIndistinguishablility amplification. For independent bit-strings \\(S_1,\\ldots,S_l \\in \\mathbb{F}^n_2\\), we have the following bound on the statistical distance of their XOR sum from uniform\n\\[\\mathsf{SD}(\\mathop{\\oplus}_i S_i, U_n) \\leq 1/2\\prod_i(2\\delta_i)\\]\nAverage Min-entropy and Conditional Unpredictability X is \\(\\epsilon\\) -unpredictable conditioned on \\(Z\\) means that\n\\[\\Pr[\\mathcal{A}(1^n, Z) = X]\\le \\varepsilon\\]\nAnd its entropic counterpart:\n\\[H_{\\infty}(X|Z):=-\\log(\\mathbb{E}[\\max_x{\\Pr[X=x|Z=z]}])\\]\nRandomness Extractors Since min-entropy is not so good, can we extract unifrom randomness from flawed sources? This is called a randomness extractor.\nUnfortunately, a deterministic randomness extractor does not exist.\nSo, extractors must be probablistic. \\((n,k,m,d,\\varepsilon)\\) extractor. Invest d-bit randomness, when input is n-bit with k-bit min-entropy, the output is \\(varepsilon\\) close to \\(U_m\\).\nUniversal Hash Functions A family of hash functions \\(H\\subseteq \\{h:\\{0,1\\}^l\\to\\{0,1\\}^t\\}\\) is called unifersal hash function if for every pair of distinct input \\(x_1,x_2\\), we have \\[\\Pr[h(x_1) = h(x_2):h\\leftarrow H]\\le 1/2^t\\] A trivial example of hash function based on multiplication over finite field \\(\\mathbb{F}_2^n\\).\nLeftover Hash Lemma For any integer \\(d \\le k \\le l\\), let \\(H\\subseteq \\{h:\\{0,1\\}^l\\to\\{0,1\\}^{k-d}\\}\\) be a family of universal hash functions, then for any r.v. \\(X\\) defined over \\(\\{0,1\\}^l\\) with min-entropy at least k-bit, then it holds that\n\\[\\mathsf{SD}(H(X),U_{k-d}|H) \\leq 2^{-1-d/2}\\]\nThe proof is deferred to the next lecture.\nPrivacy Amplification This is an application of LHL. Say Alice and Bob shares non-perfect source, they can publicly sample a random hash function, and then transform their imperfect randomness into randomness that is statistically close to uniform random. This can then subsequently used as, say private key.\nLecture 4 Recap of last lecture Two definitions (interactive game or indistinguishability plain) of indistinguishability is equivalent. All of them can be generalized to computational sense.\nStatistical distance: difference between two distributions. The greatest advantage is to output 1 every time \\(\\Pr[X=x] \u0026gt; \\Pr[Y=x]\\), which is SD.\nStatistical secure OTP: using randomness statistically close to uniform to replace the random key. The advantage is times 2 since we uses a hybrid.\nEntropy: Renyi Entropy\n\\[H_0(X) \\ge H_1(X) \\ge \\ldots \\ge \\mathbf{H}_{\\infty}(X)\\]\nEquality takes when X is uniformly random\nPiling-up Lemma Generalization:\nDiffernet \\(\\mu\\) multiplication (though still independent) Biased towards 1\nBit-vector XOR still independent \\[\\mathsf{SD}(\\mathop\\oplus_i X_i, U_n) = 1/2 \\prod_i (2\\mathsf{SD}(X_i, U_n))\\]\nRandomness Extractors How to prove the existential result (from the inability result) ???\nLeftover hash lemma LHL: for any integer \\(d\\le k \\le n\\), let \\(H \\subseteq \\{0,1\\}^l \\to \\{0,1\\}^{k-d}\\) be universal hash function. Then suppose \\(X\\) has minentropy k, it holds that\n\\[\\mathsf{SD}(H(X),U_{k-s} | H) \\le 2^{-1-d/2}\\]\nProof. Using Cauchy Inequality, then collision probability, and finally collision entropy is big enough (\\(\\geq k\\)).\nIn some proof the \\(1/2\\) coefficient is skipped for simplicity.\nConditional LHL Chain rule of min-entropy: for any \\(Z\\in\\{0,1\\}^L\\), we have\n\\[\\mathbf{H}_{\\infty}(Z) \\ge \\mathbf{H}_{\\infty}(X) - L\\]\nProof 1. Suppose contradiction, first guess Z, whose success probability is more than \\(1/2^L\\), and then use this as leakage to guess \\(X\\), which will have success probability greater than \\(2^{-\\mathbf{H}_{\\infty}(X)}\\)\nProof 2. Consider probability distribution of \\(X\\). It holds that the maximum probability of \\(X\\) satisfies that \\(\\sup_x\\Pr[X=x] = 2^{-\\mathbf{H}_{\\infty}(X)}\\), then consider conditioning on a \\(L\\) -bit leakage. The best this leakage can do is to \u0026ldquo;shrink\u0026rdquo; the table by \\(2^L\\), which is our case.\nWe can further extend LHL to the case with leakage.\nExericise Equivalence between collision entropy and min-entropy Consider any \\(X\\) such that \\(H_2(X)\\ge k\\) and \\(0\u0026lt;\\delta\u0026lt;1\\). We have\nComputational Security If we are constrained in information-theoretic world, then pkc is impossible. So we need computational security.\nE is \\((t,\\epsilon)\\) secure if any \\(A\\) less than time \\(t\\) has advantage at most \\(\\epsilon\\).\nPerfect security \\(t = \\infty\\), \\(\\epsilon = 0\\) Statistical Security \\(t = \\infty\\), \\(\\epsilon = n^{-\\omega(1)}\\) Computational Security \\(t=n^{\\omega{1}}\\), \\(\\epsilon = n^{-\\omega(1)}\\) Requirements (asympototic):\nEfficiency all algorithms must be poly time Security for any efficient adversary, the success probability of it must be bounded by some negligible function. Efficiency (slightly stronger) \\(t=n^{\\omega(1)}\\), \\(\\epsilon=n^{-\\omega(1)}\\) this implies the second one. But the second one strictly does not imply this one. Private-Key Encryption Three algorithms: KeyGen, Enc, Dec.\nImplications of indistinguishability:\nImpossible to guess any one-bit. Impossible to compute any poly-time function of any efficiently samplable \\(m\\). Semantic Security. For any efficient auxiliary information \\(h\\) and efficiently function \\(f\\). No efficiently sampable \\(m\\) can be learned \\(f(m)\\) from its encryption with more advantage than without the encryption. Pseudorandom Generator (PRG) PRG is an algorithm \\(g:\\{0,1\\}^n\\to\\{0,1\\}^l\\) and \\(l\u0026gt;n\\) such that for any efficient \\(D\\) we have:\n\\[|\\Pr[D(g(U_n))] - \\Pr[D(U_l)] | = \\mathsf{negl}\\]\nWe can generalize it a bit by \\((t,\\varepsilon)\\) i.e. quantifying the running time.\nUseful Lemmas Replacement Lemma If X, Y are \\((t, \\varepsilon)\\) indistinguishable, and \\(f\\) is \\(T\\) computable, then \\(f(X)\\), \\(f(Y)\\) are \\((t-T, \\varepsilon)\\) ind. Notice that here if we take \\(t = \\infty\\) we have \\(\\mathsf{SD}(X,Y) \\geq \\mathsf{SD} (f(X), f(Y))\\)\nSwitching Lemma If \\(X_1\\), \\(X_2\\), \\(\\ldots\\), \\(X_m\\) satisfies that for any \\(1\\le i \\le m\\), \\((t_i, \\epsilon_i)\\) ind. then \\(X_1\\) and \\(X_m\\) are \\((t, \\epsilon)\\) ind. where \\(t = \\min_i{t_i}\\) and \\(\\epsilon = \\sum_i \\epsilon_i\\). The minimum time needs to be considered.\nOne-bit stretch implies poly-bit stretch Sequential composition of PRG.\nIf PRG is (\\(t\\), \\(\\epsilon\\)) secure with stretch \\(s\\) then we can construct PRG that is (\\(t-q\\cdot\\mathsf{poly}\\), \\(q\\cdot \\epsilon\\)) secure with stretch \\(q\\cdot s\\).\nConsider \\(q-1\\) hybrid states that interpolates between total pesudorandom and ture randomness. We achieve this by replacing the previous \\(i\\cdot s +n\\) blocks with true randomness. Then any subsequent hybirds are bounded by \\(t-q\\mathsf{poly}\\), \\(\\epsilon\\) ind. The two ends are therefore (\\(t-q\\cdot \\mathsf{poly}\\), \\(q\\varepsilon\\)) ind.\nLecture 5 PRG-based fixed encryption: use PRG-generated pseudorandomness to implement OTP. Now the security is computational rather than perfect or statistical.\nBoth perfect and statistical security are \u0026ldquo;trivial\u0026rdquo;. It is in the sense that key space must be larger than message space. For statistical security there is similar result.\nA proof using hybrid-like argument shows that the advantage of distinguishing (any) two ciphertexts is bounded by \\(2\\varepsilon(n)\\) where \\(\\epsilon(n)\\) is the advantage of distinguishing \\(g(U_n)\\) and \\(U_l\\).\nHomework: Decisional LPN with constant noise rate \\(\\mu=1/4\\) and query \\(q=2n\\). How to construct a PRG?\nOne-Way Functions and Permutations Unlike complexity folks, we consider average-case hardness here.\nWe consider a family of functions \\(f_n\\) one-way if it is\nEasy to compute computable by a poly-time turing machine hard to invert randomly sample a pre-image, it is hard (super-polynomial) complexity to come up with a \\(x^prime\\) given \\(y = f(x)\\) such that \\(f(x^\\prime) = y\\). Note here hardness is defined with repect to coming up with any one satisfying preimage, not the exact preimage, since the function might be lossy. I.d. input information is much larger than output information.\nCandidate OWFs Integer factorization RSA-type Subset-sum problem Very Similar to LPN Discrete* logarithm Notice how non-discrete version is actually easy. Hardcore Predicate By definition, a one-way function is hard-to-invert. Some information about the preimage must be hard to get in some way.\nHardcore predicate formalizes this intuition.\nA hardcore predicate \\(h_c:\\{0,1\\}^n\\to\\{0,1\\}\\) is called a hard core predicate of a function \\(f:\\{0,1\\}^n\\to\\{0,1\\}^l\\) if for every ppt \\(\\mathcal{A}\\), we have \\[ \\Pr_{x\\leftarrow U_n}[\\mathcal{A}(f(x)) = h_c(x)] = 1/2 + \\mathsf{negl}.\\]\nResult: one-way permutation + hardcore predicate -\u0026gt; pseudorandom generator. Or: Next-bit unpredictability implies pseudorandomness.\nExercise proof: How the existence of hardcore predicate implies one-wayness. Notice that when inversion algorithm fails, we need to output a random bit to guess the hard-core predicate to preserve non-negative advantage.\nStatement. Suppose the probability of predicting \\(h_c(x)\\) from \\(f(x): x\\leftarrow U_n\\) is \\(1/2 + \\epsilon\\) for any t-time adversary, then \\((f(U_n),h_c(U_n))\\) and \\(U_{n+1}\\) is \\(t/2\\), \\(\\varepsilon\\) indistinguishable.\nProof. Suppose there is a distinguisher \\(D\\) contradicting the assumption, then we can conclude that \\[\\Pr[D(U_n),h_c(U_n)] - \\Pr[D(U_n),1-h_c(U_n)] \\ge 2\\varepsilon\\]\nThen we design another algorithm \\(D^\\prime(y)\\) that computes \\(b_1 = D^\\prime(y,1)\\) and \\(b_0 = D^\\prime(y,0)\\). It outputs 1 if \\(b_1 \u0026gt; b_0\\) and 0 if \\(b_0 \u0026gt; b_1\\) and random bit otherwise. We claim that the success probability of this algorithm is \\(\\varepsilon\\)\nThis statement is proved in 1982, but general hardcore construction for any owf did not appear until 1989 (Golereich-Levin).\nProof of Goldreich-Levin Theorem First recall the statement of GL theorem: for any oneway function\n\\[ f_n : \\{0,1\\}^n \\to \\{0,1\\}^l,\\]\nwe have the following hardcore predicate \\(h_c\\) for \\(f^\\prime\\)\n\\begin{align*} f^\\prime(x,r) \u0026amp;= f(x), r\\\\ h_c(x,r) \u0026amp;= r^T \\cdot x. \\end{align*}\nTechnical roadmap:\nFirst prove the size of set \\[S: \\Pr_r[\\mathcal{A}(f(x),r) = h_c(x,r)] \\ge 1/2 +\\epsilon /2\\] is at least \\(\\epsilon /2\\).\nUsing Markov argument.\n\\[1/2 + \\epsilon \\le \\Pr_{x,r}[\\mathcal{A}(f(x),r) = h_c(x,r)]\\le 1\\cdot p + (1/2+\\epsilon/2)\\cdot (1-p),\\]\nWhich implies \\(p \\ge \\epsilon /2\\)\nThen design an algorithm \\(\\mathcal{A}^\\prime\\) that invert \\(f(x)\\) with probability at least \\(\\epsilon^3/(8n)\\).\nThe trick here is using pair-wise independence. Let \\(l\\) be a small enough \u0026ldquo;row\u0026rdquo; sample number. \\(l = \\ceil{\\log(2n/\\epsilon^2 + 1)}\\).\nDefine \\(\\sigma^i \\leftarrow \\{0,1\\}^n\\) and \\(\\tau^i \\leftarrow \\{0,1\\}\\) for \\(i\\in[l]\\). Then let \\(\\tau^i\\) be the guess of \\(h_c(x, \\sigma_i)\\). Notice that since we choose \\(l\\) small enough, the success probability \\[1/2^l \\ge \\epsilon^2/(4n)\\] is just fine.\nNow define \\(I\\) to be any non-empty subset of \\([l]\\) and\n\\begin{align*} r^I \u0026amp;= \\mathop{\\oplus}_{i\\in I}\\sigma^i\\\\ \\tau^I \u0026amp;= \\mathop{\\oplus}_{i\\in I}\\tau^i \\end{align*}\nThen let\n\\begin{align*} v_j^I \u0026amp;:= \\tau^I \\oplus \\mathcal{A}(y, r^I\\oplus e_j)\\\\ \u0026amp;= \\tau^I \\oplus \\mathcal{A}(y, r^I) \\oplus x_j\\enspace. \\end{align*}\nThen do a majority voting on \\(2^{l}-1\\) candidates to determine \\(x_j\\).\nConditioned on all the guesses are correct, we then bound the probability that there exists one vote that is wrong. First use a union bound. Then for any \\(j\\) voting output \\(x_j^\\prime \\ne x_j\\) indicates that the number of correct vote is less than \\(m/2\\) where \\(m = 2^l - 1\\). Now by chebyshev inequality, the mean is \\(m/2 + \\epsilon m/2\\), this probability is bounded by \\(Var/(\\epsilon m /2)^2\\). Since the votes are pair-wise independent, we can conclude that this probability is bounded by \\(1/2n\\).\nA Central Theorem in Cryptography One-way functions imply pseudorandom generator. [HILL99]\nWhat we actually proved is a decoding algorithm that convert \\(\\epsilon\\) advangage in distinguishing hardcore predicate into \\(\\epsilon^3/(16n)\\) advantage in decoding.\nExercises Show the equivalence between Computational-LPN and Decisional-LPN.\nSolution: Given LPN sample (\\(a\\), \\(b\\)), add uniformly random \\(r\\leftarrow\\{0,1\\}\\) to first bit of \\(a\\) i.e. output (\\(a + e_{1}\\cdot r\\), \\(b\\)).\nWhen \\(s_{1} = 0\\) the output is LPN sample, When \\(s_{1} = 1\\) the output is random sample. So we transformed a distinguisher for DLPN to an algorithm that solves Search-LPN (first bit). We can then continue to solve for the rest of bits.\nLecture 6 Basing Pseudorandom Generators on Regular One-way Functions\nPRG from Regular OWF Definition: \\(f:\\{0,1\\}^{n}\\to\\{0,1\\}^{m}\\) is an \\(\\epsilon\\)-OWF if for all polynomial adversary\u0026rsquo;s inversion probability is smaller than \\(\\epsilon\\):\n\\[ \\Pr_{x\\leftarrow U_{n}}[A(1^{n}, f(x))\\in f^{-1}(f(x))] \\le \\epsilon \\]\nFolklore: OWFs can be assumed to be length-preserving, i.e. \\(m = n\\): If \\(m \u0026gt; n\\) then pad zeros to input; if \\(m \u0026lt; n\\) then pad zeros to output.\nRegular OWF Preimage size \\(\\alpha = |f^{-1}(y)|\\) (to which we refer as regularity) is fixed. We can further divide it into known-regular and unknown-regular.\nPRG Usual parameterized definition: advantage at most \\(\\epsilon\\) when running time is limited to \\(t\\).\nThe PRG introduced in previous lecture (the BM-Y Generator) relies on one-way permutations. In this lecture, we want to extend it into regular one-way function. Of course, the ultimate goal is PRG from any one-way function, but it seems a little bit too involved for this lecture.\nEntropy Min entropy measures unpredictability. Conditional entropy is expectation on the conditional maximum entropy.\nMin Entropy \\(\\mathbf{H}_{\\infty}(X) := -\\log \\max_{x} \\Pr[X=x]\\) Average Min Entropy \\( \\mathbf{H}_{\\infty}(Z) := -\\log \\mathsf{E}_{z}[\\max_{x}\\Pr[X=x|Z=z]]\\) The condition \\(Z\\) can be understood as leakage: if \\(\\mathbf{H}_{\\infty}(Z) \\ge k\\) then \\[\\Pr_{X,Z}[A(z) = x]\\le 2^{{-k}}\\]\nConsider the game of guessing randomly sampled \\(x\\) given \\(f(x)\\) \u0026ndash; modified inversion game (but succeed only if \\(x^{\\prime}\\) is exactly the sampled \\(x\\)).\nWe can relax \\(A\\) to PPT to get pseudo-entropy.\nThe unpredictable pseudoentropy is thus defined as\n\\[H_{u}(X|Z) = -\\log \\max_{A}\\Pr_{x,z}[x = A(z)].\\]\nConsider a \\(2^{k}\\)-regular \\(\\epsilon\\)-regular OWF. We have\n\\[H_{u}(X|f(X)) = \\log{1/\\epsilon} + k.\\]\nStatistical and Computational Distance Statistical distance is the maximum distinguishing probability of any algorithm distinguishing two distributions.\n\\[\\mathsf{SD}(X,Y) := \\max_{D}\\left|\\Pr[D(X)= 1] - \\Pr[D(Y) = 1]\\right|,\\]\nHere \\(D\\) can be unbounded.\nComputational distance is the result when relaxing the algorithm to PPT.\n\\[\\mathsf{CD}(X,Y) := \\max_{D}\\left|\\Pr[D(X) = 1] - \\Pr[D(Y) = 1]\\right|,\\]\nhere \\(D\\) is limited to PPT.\nRandomness Extraction In short LHL and GL-theorem are both randomness extractors. The former one is statistical while the latter one is computational.\nLeftover Hash Lemma: Let (\\(X\\), \\(Z\\)) be any r.v. with \\(\\mathbf{H}_{\\infty}(Z) = k\\) and let \\(h:\\{0,1\\}^{n} \\to \\{0,1\\}^{k-d}\\) be a (family of) universal hash function, then we have\n\\[\\mathsf{SD}((h, Z, h(x)), (h, Z, U_{k-d})) \\leq 2^{-d/2}.\\]\nGoldreich-Levin Theorem: Let (\\(X\\), \\(Z\\)) be any r.v. with \\(H_{u}(X|Z) = k\\) then there exists efficient hash \\(h: \\{0,1\\}^{n}\\to \\{0,1\\}^{L = O(k)}\\) such that\n\\[\\mathsf{CD}((h, Z, h(x)), (h, Z, U_{L})) \\leq 2^{-\\Omega{k}}\\]\nNormally we have \\(k = \\omega{k}\\) (at least superpolynomial hardness), so the computational distance is negligible.\nPseudoentropy of regular OWF What is the UP of \\(X\\) given \\(f(X)\\) if \\(f\\) is a regular \\(\\epsilon\\) OWF with regularity \\(\\alpha = 2^{k}\\)\nThe min-entropy is clearly \\(k\\) bits, but computationally speaking, we can do better.\nClaim: \\(H_{u}(X|f(X)) = k + \\log{1/\\epsilon}\\), where\n\\[ \\Pr_{{X}}[A(f(X)) \\in f^{-1}(f(X))] \\le \\epsilon \\]\nAnd therefore\n\\[ \\Pr_{{X}}[A(f(X)) = X] \\le 2^{-k}\\epsilon \\]\nWe can understand it in this way. Let event \u0026ldquo;A succeeds\u0026rdquo; denotes the event that \\(A\\) successfully guesses the exact preimage. Then we have\n\\begin{align*} \\Pr[\\text{A succeeds}] \u0026amp;= \\Pr[\\text{A outputs coset}\\land\\text{A hits}] \\\\ \u0026amp;= \\Pr[\\text{A outputs coset}]\\cdot \\Pr[\\text{A hits}| \\text{A outputs coset}] \\\\ \u0026amp;= 2^{-k} \\cdot \\Pr[\\text{A outputs coset}]\\enspace, \\end{align*}\nwhere by \u0026ldquo;A outputs coset\u0026rdquo; I mean the event A\u0026rsquo;s output is in \\(f^{-1}(f(x))\\). The last equality holds since when A output something in that set, the probability it succeeds is exactly \\(2^{-k}\\).\nPRGs from Known Regular OWFs Proof given in Goldreich\u0026rsquo;s book. Very complex, uses three hashes.\nWe have an alternative 3-line proof.\nAssumption: \\(f\\) is \\(\\epsilon\\)-one-way and \\(2^{k}\\) regular\nHash \\(f(X)\\) to extract \\(n-k\\) bit (\\(h_{1}(f(X))\\)), since \\(\\mathbf{H}_{\\infty}(f(X)) = n-k\\) (note that we ignored entropy loss)\nHash \\(X\\) to extract \\(k\\) bits (\\(h_{2}(X)\\)), since \\(\\mathbf{H}_{\\infty}(X|f(X)) = k\\) (once again, entropy loss ignored.)\nThe key. Using chain rule \\(H_{u}(X|f(X)) = k + \\log(1/\\epsilon)\\) then\n\\[H_{u}(X|f(X), h_{2}(X)) \\ge \\log{1/\\epsilon},\\]\nNow extract \\(O(\\log(1/\\epsilon))\\) bits using hard-core function \\(h_{c}\\).\nIt is clear that the third step is crucial for gaining stretch.\nFinally, use a hybrid argument to prove combined distribution is pseudorandom. In particular, since it took me a while to see it clear, I might as well write down for possible future reference.\nProposition: (\\(h_{1}(f(X))\\), \\(h_{2}(X)\\), \\(h_{c}(X)\\), \\(h_{1}\\), \\(h_{2}\\), \\(h_{c}\\)) is pseudorandom.\nProof. Consider hybrid distribution \\[H_{1} := (h_{1}(f(X)), h_{2}(X), U_{L}, h_{1}, h_{2}, h_{c})\\]\nBy GL-theorem, we have\n\\begin{align*} \\mathsf{CD}(h_{c}(X)), U_{L} | f(X), h_{2}(X), h_{2}, h_{c}) \u0026amp;\\le 2^{-\\Omega(L)}\\\\ \u0026amp;\\le\\Omega(\\epsilon) \\end{align*}\nWhich means Hybrid 1 is indistinguishable to the real distribution.\nNow Consider hybrid distribution 2\n\\[H_{2} := (h_{1}(f(X)), U_{k}, U_{L}, h_{1}, h_{2}, h_{c}). \\]\nBy leftover hash lemma, we have\n\\begin{align*} \\mathsf{SD}(h_{2}(X), U_{k} | h_{2}, f(X)) \\leq 2^{-d/2} \\end{align*}\nFor some properly chosen \\(d\\) to be super logarithmic. This implies hybird 1 and hybrid 2 are indistinghishable.\nFinally, consider Hybrid distribution 3\n\\[H_{3}:= (h_{1}(U_{n-k}), U_{k}, U_{L}, h_{1}, h_{2}, h_{c})\\]\nBy leftover hash lemma, we have\n\\begin{align*} \\mathsf{SD}(h_{1}(f(X)), U_{n-k} | h_{1}) \\leq 2^{{-d/2}} \\end{align*}\nOnce again, for some properly chosen \\(d\\). This implies hybrid 2 and hybrid 3 are indistinguishable. Altogether, this concludes the proof.\nThe construction is optimum because it only calls \\(f\\) once and seed length is linear in \\(n\\).\nMulti-bit GL-Theorem is indeed worth investigating. From a facile result it seems that \\(h_{c}(x)\\) is \\(2^{m} (n\\epsilon)^{1/3}\\) close to \\(U_{m}\\).\nPRGs from unknown-regular OWFs The randomized iterate (CRYPTO 2006). The proof is again, too complex.\nLower Bounds (FOCS12) Any black-box construction of PRG must make \\(\\Omega(n/\\log n)\\) calls to the OWF to make PRG.\nPRG from unknown-regular OWFs Assumption: \\(f\\) is \\(\\epsilon\\) regular and \\(2^{k}\\) regular (but \\(k\\) is unknown).\nLet \\(Y\\) be the range of OWF, we define \\(\\bar{f}\\) that is \\(2^{n}\\)-regular.\n\\begin{align*} \\bar{f}: Y \\times \\{0,1\\}^{n} \u0026amp;\\to Y \\\\ \\bar{f}:(y,r) \u0026amp;\\mapsto f(y\\oplus r) \\end{align*}\nIf we call the vanilla construction for regular OWFs, then there is a problem.\nTo sample \\(Y\\) we need \\(n\\) bit, this makes the stretch negative.\nTo make it positive, we need to iterate it using hybrid argument.\nThis means we have to iterate \\(\\frac{n}{\\log{1/\\epsilon}}\\) times to get a positive stretch, which is tight (from FOCS 2012, BB constructions of PRG requires \\(\\Omega(n / \\log(1/\\epsilon))\\) OWF calls and \\(\\Omega(n / \\log n)\\) calls in general.)\nPseudorandom Function Security under CPA.\nAdversary has oracle access to the encryption algorithm.\nWe can achieve CPA security (Secret-Key) from PRFs. The definition of \\(\\prf\\) is a family of keyed functions that is indistinguishable from random function given oracle access.\nAn alternative definition is the distinguishing probability of any polynomial points is negligible.\nIs the two definition equivalent? Prof. Yu later changed this definition so that the query does not depend on previous query results. This is clearly weaker. But I think the \u0026ldquo;forall\u0026rdquo; type is equivalent. NOPE, you are trolled. In the non-adaptive defintion, the query is independent on the key choice. The weak PRF definition typically follows this syntax.\nWhy Pseudorandom Efficient and equivalent to random function.\nFrom PRF we immediately get a CPA-based encryption.\nThe GGM Construction of PRF Let \\(g\\) be a length-doubling PRG, then we seek to construct a PRF from this \\(g\\). Input \\(x\\) determines a path from root (the key) to leaf (the output).\n\\(g(x) = g_{1}(x) || g_{2}(x)\\)\nParallel repetitiion of the PRG is still a PRG from a standard hybrid argument.\nFirst Attempt: Shallow GGM Tree Consider a \\(l = O(\\log n)\\) depth tree. Then we can argue the stronger result that the range concatenated is pseudorandom. The proof is a hybird argument by replacing from layer 1 to layer \\(l\\) by uniform random. Since generating the whole tree takes only polynomial time and the width of any layer is at most polynomial, the proof follows by a standard hybrid argument.\nBut we need not to prove such a strong case. We can instead replace the oracle.\nThe General Case of GGM Theorem: If \\(g\\) is a (\\(t\\), \\(\\epsilon\\))-\\(\\prg\\) and \\(g\\) is computable in \\(t_{g}\\), then \\(F\\) is a (\\(t^{\\prime} = t/O(nt_{g})\\), \\(\\epsilon n t^{\\prime}\\))-\\(\\prf\\).\nWe then construct \\(n\\) hybrids where \\(H_{i}\\) is the previous \\(i\\) layers replaced by uniform random. Clearly \\(H_{0}\\) is the \\(F\\) distribution and \\(H_{n}\\) is uniformly random.\nThe \\(t^{\\prime}\\) term in the statment trolled me for a while, before I tried to prove it myself and I realized that it is a clever choice of parameter to enable a simpler result.\nIn particular, we need \\(O(t^{\\prime})\\) samples (\\(2n\\) pseudorandom / random bits), and simulation of the oracle takes \\(O(t^{\\prime} n t_{g}\\) overhead. Altogether, this implies \\(t^{\\prime} + O(t^{\\prime} t_{g} n)\\) time algorithm for \\(t^{\\prime}\\) samples. (Since for advantage, we have no trouble, it is skipped.) We now need to have \\(t^{\\prime} + O(t^{\\prime} t_{g} n) \u0026lt; t - t^{\\prime} t_{g}\\) to make use of the \\(t\\) bound. By setting \\(t^{\\prime} = t / O(n t_{g})\\) we can get this result.\nExercise: Domain Extension for PRFs Levin\u0026rsquo;s Trick: For any \\(l\\le n \\in \\mathbb{N}\\), let \\(R_{1}\\) be a random function distribution over \\(\\{0,1\\}^{l}\\to\\{0,1\\}^{n}\\) and \\(H\\) be a family of UHF from \\(n\\) to \\(l\\), then argue that \\(R_{1}(H_{{1}}(\\cdot))\\) is indistinguishable from \\(n\\) to \\(n\\) random function.\nProof (informal). Consider an adversary that makes at most \\(q\\) queries to the oracle, when non of the \\(q\\) queries collide, the output distribution is exactly the same in \\(R_{1}\\circ H_{1}\\) as in \\(R\\). So if we managed to argue this event happens with probability \\(1-\\epsilon\\) then the advantage between distinguishing these two oracles are at most \\(\\epsilon\\).\nConsider the event that collision do happen. We denote \\(\\text{Collide}_{i}\\) the event that the \\(i^{\\text{th}}\\) query becomes the first collision. It follows from union bound that\n\\[\\Pr[\\text{Collide}] \\le \\sum_{i}\\Pr[\\text{Collide}_{i}]\\]\nWhere the probability is over random choice of \\(R_{1}\\), \\(H_{1}\\), and the querying algorithm. The observation here is that when \\(\\text{Collide}_{i}\\) occurs, the first \\(i-1\\) oracle outputs are independently random. And thus the information of \\(H_{1}\\) has not increased from these outputs. Therefore,\n\\[\\text{Collide}_{i} \\le \\frac{i-1}{2^{l}}\\]\nFrom another union bound using the uniform hash property.\nAltogether, this implies\n\\[\\Pr[\\text{Collide}] \\le \\frac{q^{2}}{2^{l+1}},\\]\nWhich is arguably good enough when \\(l\\) is not too small (e.g. \\(1/2n\\)).\nBibliography\nI did some research for a more rigorous proof, and all references point to a paper by Levin in Combinatorica 1987: One way functions and pseudorandom generator. But it seems that from Nico\u0026rsquo;s paper in CRYPTO 2015 \u0026mdash; Efficient pseudorandom functions via on-the-fly adaption that this results can be improved when \\(l\\) is not big enough. The original paper is scanned and is in terrible readability. So I may only consider reading it after I confirmed that my aforementioned proof is incomplete.\nLecture 7 PRF PRF from PRG using GGM tree. Two proofs, the first one is a strong result, but with limitation. The second one relaxed the result, but is able to prove polynomial depth results.\nPseudorandom functions in almost constant depth from low-noise LPN First introduce the LPN problem.\nSearch LPN given a, \\(y = ax+e\\), find out \\(x\\) Decisional LPN distinguish \\((a, y)\\) with \\(a, U_{q}\\) The two versions are polynomially equivalent. Another fact. LPN and Hermite normal forms are equivalent.\nLPN \\(\\le\\) HLPN, we have a \\(n\\) loss in query complexity HLPN \\(\\le\\) LPN, add uniform secret to LPN sample. No loss whatsoever and noise can be arbitrary. In the following construction, we assume \\(x,e\\) are both Bernoulli.\nHardness of LPN Worst case hardness: decoding linear code Average-case hardness: BKW algorithm\nFor constant noise \\(\\mu\\) BKW: \\(t = q = 2^{O(n/\\log n)}\\). Vadim\u0026rsquo;s tradeoff: \\(t = 2^{O(n/\\log\\log n)}\\), \\(q = n^{1 + \\epsilon}\\). For \\(q = O(n)\\), the best algorithm is \\(t = 2^{{O(n)}}\\). For low noise LPN \\(\\mu = n^{-c}\\). The best algorithm has \\(t = poly(n,q)e^{n^{1-c}}\\). Related Works LPN to PRG, PRF, CCA PKE, etc.\nMain Results Polynomial-stretch PRG in \\(\\mathcal{AC}_{0} \\mod 2\\) PRF in \\(\\tilde{\\mathcal{AC}_{0}} \\mod 2\\) (depth is \\(\\omega(1)\\)) Infeasibility result: quasi-polynomial hard PRF in \\(\\mathcal{AC}_0\\) is impossible. Notions In this result, we consider randomized PRG, PRF.\nWe consider shared random matrix \\(A\\). This will incur a security loss from hybrid argument (the secret now is a matrix rather than a vector).\nRandomized PRF in this work is weak PRF.\nPRG We use an sampler/extractor to convert almost all entropy of input \\(w\\) into Bernoulli-like noise \\(x,e\\).\nAssume noise \\(\\mu = 2^{-i}\\) for \\(i\\in\\mathbb{N}\\). For \\(\\mu = n^{-c}\\) (\\(i = c\\log n\\)), Shannon entropy of \\(Ber_{\\mu}\\) \\(\\approx \\mu\\log(1/\\mu)\\).\nThis is very wastful for randomness. There are two solutions\n[Applebaum et al. 09], recycle randomness from \\(r\\). [Yu Zhang 16], first use a pairwise independent hash function to expand randomness, then use AND to sample noise. Theorem: Let \\(h_1, h_2, \\ldots, h_q\\) be 2-wise independent hash function, for any source \\(w\\) of collision entropy \\(\\lambda\\), and any constant \\(0 \u0026lt; \\delta \\le 1\\)\n\\[ \\mathsf{SD}((a, (e_1, \\ldots, e_q), (a, Ber_{\\mu}^q))) \u0026lt; \\delta. \\]\nAlternative Bernoulli noise sampler \u0026ndash; Bitwise OR, but can only use uniform random input.\nTheorem. Assume that the DLPN is (\\(q = O(n)\\), \\(t\\), \\(\\epsilon\\))-hard on input of size n\nPRF We assume there is a PRG with \\(n\\)-bit input and \\(n^2\\)-bit output. (i.e. a synthesizer ?)\nUse GGM construction of depth \\(d = \\omega(1)\\) to get a PRF of input size \\(\\omega(\\log n)\\) Domain extension from \\(\\{0,1\\}^{n}\\) to \\(\\{0,1\\}^{\\omega{\\log n}}\\) using generalized levin\u0026rsquo;s trick. Pseudorandom Permutation Figure 7: Definition of Pesuro-Random Permutation\nThis definition follows a common paradigm in cryptography: efficient approximation of ideal world from real world.\nFigure 8: Feistel Networks: from PRF to PRP\nThe feature here is that both the permutation and its inverse are efficiently computable. And it can be easily concatenated.\nThe Luby-Rackoff PRP from PRF: four round construction.\nProof sketch. Seems like we can use RO-like argument for first four hybrids, in the final hybrid, i.e. using random function to implement a random permutation. It seems like birthday attack is unavoidable in this case.\nWhat if we reduce the network to three rounds? This suffices for indistinguishability for only encryption oracle, rather than the evaluation oracle.\nWhat about two rounds? If we first do a hash function \\(h_1\\) at the beginning and hash the two round output \\(h_2\\) after the end, we can do a PRP from two round Feistel.\nConstructions of Block Ciphers Ideal vs. Reality\nIn theory One-way function (actually, we learned OWP, regular OWF, not any OWF) -\u0026gt; PRG -\u0026gt; PRF -\u0026gt; PRP\nIn practice Built from scratch: AES / DES\nA PRP can is a PRF up to a birthday bound A PRP is at first, a PRF. In practice, PRP is acquired easily from AES. But permutation is a class more \u0026ldquo;structured\u0026rdquo; than random functions. So there is a gap (luckily not too big) between PRF and PRP.\nLemma. A (\\(t\\), \\(\\epsilon\\), \\(q\\))-secure PRP on n-bits is a (\\(t\\), \\(\\epsilon + \\frac{O(q^2)}{2^n}\\), \\(q\\))-PRF.\nProof.\nAny (t, q)-Adv distinguishes PRP from RP with advantage \\(\\leq\\epsilon\\). Any (\\(\\infty\\), q)-Adv distinguishes RP from RF with advantage \\(O(q^{2}/2^{n})/\\). Mode of Operation Direct use of a block cipher is not recommended. Message are a multiple of the cipher block size in length. The solution is different mode of operations.\nECB (insecure) Cipher Block Chaining Cipher Feedback Output Feedback Counter (the difference from \\(r, \\prf_{k}( r) \\oplus x\\) is that CTR hash shorter ct, but is stateful) Pseudoentropy and Pseudorandomness Extraction Two types of Pseudoentropy.\nHILL pseudoentropy X has k bit HILL pentropy if it is indistinguishable in the non-uniform model from a k-bit unpredictable (unconditional) distribution. Metric-type pseudoentropy X has k bit Metrix type pseudoentropy if for every circuit D of size s there exists a distribution of at least k-bit min-entropy that is indistinghishable by \\(D\\) from \\(X\\). Lecture 8 Pseudoentropy and pseudorandomness extraction.\nPseudoentropy HILL and metric-type pesudoentropy.\nHILL pseudoentropy. We say \\(X\\) has HILL pseudoentropy \\(k\\) if there exists a distribution \\(Y\\) where \\(\\mathbf{H}_{\\infty}(Y) \\ge k\\) and \\(\\mathsf{CD}(X, Y) \\leq \\epsilon\\). Metric-type pseudoentropy. We say \\(X\\) has metric-type pseudoentropy \\(k\\) if for every circuit \\(D\\) of size \\(s\\) there exists a distribution \\(Y\\) with \\(\\mathbf{H}_{\\infty}(Y) \\ge k\\) and \\(\\delta^D(X, Y) \\le \\epsilon\\). Borak proved 2 implies 1 using von Neumman\u0026rsquo;s Min-Max theorem. The idea is to prove after exchanging the quantifiers, the result is to some extent, equivalent.\nPseudoentropy of PRG conditioned on leakage If \\(\\mathsf{PRG} : \\{0,1\\}^n \\to \\{0,1\\}^m\\) and \\(f : \\{0,1\\}^n \\to \\{0,1\\}^{\\lambda}\\)\nFigure 9: Peduroentropy of PRG\nWithout leakage, the pseudoentropy of PRG output is trivial. We want to prove similar result conditioned on arbitrary leakage.\nWhy do we use probability instead of plain assertion? The reason is that some leakage can be drastic. Using probability we can bypass this limitation. E.g. the leakage function \\(f\\) is the hamming weight of input. If we observed that \\(f(x) = 0\\), then it holds that \\(x = 0\\).\nFrom the previous lemma 7, we only have to prove equation (4), which is a seemingly weaker (and hopefully easier to prove) result.\nThis lecture is based on a FOCS 2008 paper: Leakage Resilient Cryptography 这是一篇经典论文，贡献是\n结论非常庞大，而且它试图通过理论的方法解决实际密码实现上的问题\n证明过程中的一个结论是 Dense Model Theorem, 它与Green-Tao定理存在着联系\nGreen-Tao: 质数包含所有长度的等差数列，即给定\\(\\ell\\)，存在差为 \\(\\ell\\)的素数等差数列\n我们使用集合上的Dense Model Theorem。\nProof overview.\nFigure 10: Simplified Proof\nFirst consider the complement of the event, what we want to prove is \u0026hellip;\nOne tricky part is that you can assume a 0-1 distinguisher can output one real number. This special type of distinguisher can be implied by standard distinguishers, by apprximating the probability \\(\\Pr[D=1]\\).\nAnyway, the proof showed that PRG is still secure under leakage. In particular, we have for a \\(\\mathsf{PRG}\\), there exists a high-entropy \\(Y\\) such that \\(\\mathsf{PRG}(X), f(X)\\) is indistinguishable from \\(Y, f(Y)\\). We can therefore use an extractor to extract randomness from \\(Y | f(Y)\\). This means that even for leaky source, we can extract randomness from PRG\u0026rsquo;s output using randomness extractor (e.g. universal hash function).\nNon-Uniform Key wPRF For a weak PRF, if we choose key to be slightly non-uniform, will the output still be pseudorandom?\nFigure 11: Non-uniform High-min-entropy Key in PRG Application\nIf you are interested, please refer to STOC 2008, EC 2009 (a simplified proof is presented in TCC 2013).\nExercises Existence of Independent Code Independent code: \\(k\\)-independent and \\(k = n\\) means that the code \\(C\\) is MDS code, which is trivial for \\(\\mathbb{F}_2\\), so typically we have \\(k \u0026lt; n\\).\nWe relex the condition to proving a good enough probability over the choice of \\(C\\).\nWe first expand the probability in to summation over \\(r\\), and then observe that for random \\(C\\), since \\(r\\) is pair-wise disjoint, the r.v. \\(Cr_1\\) and \\(Cr_2\\) are independent for any \\(r_1 \\ne r_2\\). Notice that altogether they are not independent (consider \\(r_3 = r_1 + r_2\\)). We can then use Chebyshev\u0026rsquo;s inequality to get the result.\nOne-Time MAC Universal hash function\nCollision Entropy and Min-Entropy Equivalence Use Markov inequality.\nPRG from LPN One trick \u0026mdash; flattening Shannon entropy. For \\(H(w) = a\\), we have \\(\\minentropy{w_1, w_2, \\ldots, w_n} \\approx na\\). The definition-based conditional min-entorpy is somewhat pessimistic. The flattneing trick can be userful here.\nLecture 9 Exercise Solutions PRG from LPN First of all standard LPN with \\(q = 2n\\) and \\(\\mu = \\frac{1}{4}\\) implies Hermite normal form LPN\u0026rsquo; where secret follows noise distribution \\(Ber_{\\mu}^n\\).\nSo we first sample a \\(4n\\)-bit random number, and then through bitwise-AND, get a \\(2n\\)-bit random Bernoulli noise. Conditioned on this output, we still have whp. \\(\\frac{3n}{2} - \\lambda\\) 2-bit pairs that have \\(\\log 3\\) entropy.\nProcedure:\nFirst sample \\(x, e\\) from \\(4n\\)-bit uniform randomness. Then output \\(A x + e\\), and use randomness extractor to extract \\(2n + \\lambda\\) bits. Search-LPN and Decision-LPN From Decision-LPN to Search-LPN: Compute \\(x\\) and accept iff. the hamming weight of \\(y - Ax\\) is small.\nIf input \\(A, y\\) follows LPN distribution, the algorithm will accept whp. If the input follows uniform distribution, then from the fact that\n\\[ \\Pr_{A, y} [ \\exists s, |y - As| \\le \\lambda ] \\le 2^{ -m + n + \\lambda \\log(m) }, \\]\nwe conclude that the probability the algorithm accept is bounded by the previous negligible probability.\nFrom Search-LPN to Decision-LPN: There are at least three very related methods.\nThe first one is the most \u0026ldquo;orthodox\u0026rdquo; one. Construct hybrid \\(H_0\\), \\(H_1\\), \\(\\ldots\\), \\(H_q\\). \\(H_0\\) is the LPN distribution, and \\(H_q\\) is the uniform distribution. Using GL theorem we can conclude from the one-wayness of LPN, changing \\(a_i^T x\\) to \\(U_1\\) is indistinguishable. So by hybrid argument we can conclude that \\(H_0\\) and \\(H_q\\) are indistinguishable.\nOr we can follow the second way: using the LWE-like solver, solving the secret bit-by-bit.\nFinally, we can use a very unorthodox method, without hybrid argument. Suppose there is a distinguisher that distinguishes LPN distribution and uniform distribution, then we can construct an algorithm that on input \\(A, Ax+e, r\\), output \\(r^T, x\\) with high probability. And from GL-theorem\u0026rsquo;s proof (the list decoding algorithm), this implies a solver for \\(x\\).\nHow to do that? First samples \\(u \\leftarrow \\{0,1\\}^q\\), and then let \\(\\bar{A} = A - u\\cdot r^T\\). Observe that\n\\begin{align} A x + e \u0026amp;= (\\bar{A} + u r^T) x + e \\\\ \u0026amp; = \\bar{A} x + e + u (r^T x)\\enspace. \\end{align}\nSo when \\(r^Tx = 0\\), \\(Ax + e\\) follows LPN distribution with \\(\\bar{A}\\) as public matrix, whereas when \\(r^T x = 1\\) output is random.\nAnd thus \\(\\bar{A}, y = Ax+e\\) follows\nLPN distribution when \\(r^T x = 0\\) Uniform distribution when \\(r^T x = 1\\) This implies an effective distinguisher for the GL-hardcore.\nDomain Extension Conditioned on no collision at \\(R_1\\), the two distributions are identical. So we only have to bound the probability of collision. And the probability is just a birthday attack bound. As a matter of details, I think the probability should be computed as\n\\[ \\Pr[\\neg \\text{Collision}] \\ge (1) (1 - \\frac{1}{2^l}) (1 - \\frac{2}{2^l})\\ldots (1 - \\frac{q-1}{2^l}) = 1 - O(\\frac{q^2}{2^{l+1}})\\enspace, \\]\nwhereas I am not sure how to formulate the \\(\\binom{q}{2}\\)-pair bound, since collision can occur at each level.\nOne tricky part is that after query, the hash function \\(h\\) can be made public. So the attack can be made a two-stage process. First the attacker is given oracle access to a PRF (\\(R^{\\prime} = R \\circ H\\)), and in the second stage, the attacker is given the transcript of the attack, along with the hash function. This is clearly a relaxation, but does not affect security.\nCRHF and UOWHF U(OW)HF is an one-way version of UHF. CRHF is considered to be the strongest primitive in symmetric cryptography, although no black-box construction based on OWF exists.\nCollision Resistance Hash Function CRHF is a family of Hash funcitons such that:\nEfficient polynomial computable sampling and evaluation algorithms Shrinking opposite to stretching Collision Resistant given random instance, any PPT adversary cannot find a collision \\[ \\Pr_{g\\leftarrow G; (x, x^{\\prime}) \\gets A(1^n, g)} [x\\ne x^{\\prime}\\land g(x) = g(x^{\\prime})] = \\mathsf{negl} \\]\nBirthday attack. Use \\(2^{\\frac{m}{2}}\\) time to find from \\(2^m\\)-output domain a collision with a constant probability (since the collision probability with random output among \\(2^m\\) and \\(q\\) queries is \\(\\Theta(\\frac{q^2}{2^m})\\)). This implies that any CRHF with output size \\(m\\) has security no more than \\(\\frac{m}{2}\\).\nPractical examples:\nMD5 output 128bits, broken SHA1 output 160bits, broken SHA256 output 256bits, unlikely to break Theoretically black-box construction of CRHF based on OWF is impossible.\nUniversal One-Way Hash Function UOWHF is a family of Hash funcitons such that:\nEfficient polynomial computable sampling and computing Shrinking opposite to stretching Target Collision Resistant given random instance, a target, any PPT adversary cannot find a collision. For any \\(x\\in \\{0,1\\}^n\\), \\[ \\Pr_{g\\leftarrow G; x^{\\prime}\\gets A(1^n, g,x))} [x\\ne x^{\\prime}\\land g(x) = g(x^{\\prime})] = \\mathsf{negl}. \\]\nTCR limits the form of collison (by setting a \u0026ldquo;target\u0026rdquo;), so it is a weaker version of CR.\nTCR is equivalent to another notion called TCR2. In this definition, the target \\(x\\) is chosen uniformly at random. That TCR implies TCR2 is trivial, while in the opposite direction, we can construct a TCR hash from a TCR2 hash, by adding \\(n\\)-bit to function description, and xoring \\(a\\) with input before every evaluation. That is, \\(g^{\\prime}(x) = g(x \\oplus a)\\).\nThe reduction is trivial. Suppose there exists a target \\(a\\) that allows an algorithm \\(A\\) finds collision with non-negligible probability, then we can first ask TCR2 challenger for a hash function \\(g\\) and target \\(x\\), then send to algorithm \\(A\\) \\(g_{x \\oplus a}\\) and \\(a\\). If such a collision \\(b\\) is found, it holds that \\(g(x) = g(x \\oplus a \\oplus b)\\).\nUOWHF is good enough for digital signatures, and it is implied from OWF. This concept, together with a reduction from OWP, was presented by Naor and Yung.\nUOWHF can be seen as dual to PRG.\nUOWHF from OWP Let \\(f: \\{0,1\\}^n \\to \\{0,1\\}^n\\) be any (\\(t\\), \\(\\epsilon\\))-one-way permutation, and \\(H\\) be a family of universal hash permutations over \\(\\{0,1\\}^n\\),\n\\[ H = \\{ h:\\{0,1\\}^n \\to \\{0,1\\}^{n} | h(y) := h\\cdot y, h\\ne {\\bf 0}, y\\in GF(2^n) \\}\\enspace, \\]\nlet \\(\\mathsf{trunc}\\) be the function that truncates the last bit of its \\(n\\)-bit input. Then we argue that\n\\[G := \\{ (\\mathsf{trunc} \\circ h \\circ f) | h\\in H \\}\\]\nis a family of (\\(t - n^{O(1)}\\), \\(\\epsilon\\)) UOWHF with 1bit shrinkage.\nProof We can construct an inversion algorithm for OWP based on Collision finder of TCR2. The key is that we can \u0026ldquo;program\u0026rdquo; the hash function in the middle to meet our need.\nGiven input \\(y\\), we first samples \\(x^{\\prime} \\leftarrow \\{0,1\\}^n\\). With probability \\(\\frac{1}{2^n}\\) we can success at this step (\\(f(x^{\\prime} = y\\)). If not, we continue by computing \\(h = (00\\ldots 01)\\cdot (y - x^{\\prime})^{-1}\\). Notice that this implies\n\\[ \\mathsf{trunc} \\circ h \\circ \\underbrace{f (x)}_{y} = \\mathsf{trunc} \\circ h \\circ f (x^{\\prime})\\enspace, \\]\nand since \\(x^{\\prime} \\) and \\(x\\) are iid, \\(h\\) is indeed random. If the inversion algorithm has probability \\(\\epsilon\\) when the input is \\(h, x^{\\prime}\\), then with the same probability we can find \\(x\\) since the hash function is \\(2\\)-regular. Altogether, we obtain a OWP inverter that succeed with at least \\(\\epsilon\\) probability.\nMerkle-Damgard Domain Extension for CRHFs and UOWHFs Let\n\\[G \\subseteq \\{ g: \\{0,1\\}^n \\to \\{0,1\\}^{n-s} \\} \\]\nfor each \\(g : (x_i,r_i) \\to x_{i+1}\\), where \\(x_i, x_{i+1} \\in \\{0,1\\}^{n-s}\\), \\(r_i \\in \\{0,1\\}^s\\), be a (\\(t\\), \\(\\epsilon\\))-secure CRHF, and for any \\(q \\in \\mathbb{N}\\) define \\(G^q \\subseteq \\{0,1\\}^{n + (q-1) s} \\to \\{0,1\\}^{n-s}, g\\in G\\) where\n\\[ g^q(x_{1}, r_1, r_2, \\ldots, r_q) = g(\\ldots g(g(x_1, r_1), r_2), \\ldots, r_q). \\]\nThen we have (\\(t - q t_g\\), \\(\\epsilon\\))-CRHF.\nProof From the \u0026ldquo;bigger\u0026rdquo; collision we can find a smaller collison at the \\(i^{th}\\) level such that \\(g(x_i, r_i) = g(x^{\\prime}_i, r^{\\prime}_i)\\) and \\((x_i, r_i) \\ne (x_i^{\\prime}, r_i^{\\prime})\\). And that contradicts the assumption that \\(g\\) is CRHF. The time loss is incurred at the checking step.\nMerkle-Damgard Domain Extension for UOWHFs.\nLet\n\\[ G \\subseteq \\{ g: \\{0,1\\}^n \\to \\{0,1\\}^{n-s} \\} \\]\nfor each \\(g : (x_i,r_i) \\to x_{i+1}\\), where \\(x_i, x_{i+1} \\in \\{0,1\\}^{n-s}\\), \\(r_i \\in \\{0,1\\}^s\\), be a (\\(t\\), \\(\\epsilon\\))-secure UOWHF, and for any \\(q \\in \\mathbb{N}\\) define \\(G^q \\subseteq \\{0,1\\}^{n + (q-1) s} \\to \\{0,1\\}^{n-s}\\), \\(g_{1}, g_2, \\ldots, g_q \\in G\\) where\n\\[ g^q(x_{1}, r_1, r_2, \\ldots, r_q) = g_q(\\ldots g_2(g_1(x_1, r_1), r_2), \\ldots, r_q)\\enspace. \\]\nThen we have (\\(t - q t_g\\), \\(q \\epsilon \\))-UOWHF.\nProof This proof is somewhat tricker than the previous proof, since we have to embed the target into it. Using the TCR (instead of TCR2) definition, we can settle with arguing existential property, but throughout the proof one must beware that the target \\(y\\) must be independent of the UOWHF function (this is probabilty the reason behind \\(q\\)-many independent hash functions in the definition).\nSuppose through contradiction, there exists an algorithm running in \\(t - qt_g\\)-time and a target \\(y = (x_1, r_1, \\ldots, r_q)\\) such that\n\\[ \\Pr_{g_1,g_2,\\ldots,g_q \\leftarrow G; y^{\\prime} \\gets A(y, g_1, \\ldots, g_q)} [y \\ne y^{\\prime} \\land g^q(y) = g^q(y^{\\prime})] \\ge q\\epsilon\\enspace, \\]\nWe can find a \\(t\\)-time algorithm \\(A^{\\prime}\\) and target \\((x_i^{\\star}, r_i^{\\star})\\) finds with at least \\(\\epsilon\\)-probability. First consider a random index \\(i^{\\star} \\leftarrow [q]\\), random hash functions \\(g_1, \\ldots, g_{i^{\\star} - 1} \\leftarrow G\\), and define \\(x_i^{\\star}, r_i^{\\star} = g^{i^{\\star} - 1} (x_1, r_1, \\ldots, r_{i^{\\star} - 1})\\). Now we let \\(g_{i^{\\star}} = g\\) which is the algorithm \\(A^{\\prime}\\)\u0026rsquo;s input, and sample the rest hash functions at random.\nBy the assumption, since our definition of \\(q\\) hash functions follows the uniform distribution over \\(G^q\\), with probability \\(q\\epsilon\\) the algorithm \\(A\\) will return a collison \\(y^{\\prime}\\). And since the index \\(i^{\\star}\\) is independent with \\(A\\)\u0026rsquo;s input, with probability at least \\(\\frac{1}{q}\\), the collision will occur at position \\(i^{\\star}\\). Id est, we can get \\(x_{i^{\\star}}^{\\prime}, r_{i^{\\star}}^{\\prime}\\) that constitutes a collision for the hash function \\(g\\). Formally, we have\n\\begin{align*} \u0026amp; \\Pr_{ i^{\\star} \\leftarrow [q]; g \\leftarrow G; (x^{\\prime}_{i^{\\star}}, r^{\\prime}_{i^{\\star}}) \\gets A(x_{i^{\\star}}, r_{i^{\\star}}) } [(x^{\\prime}_{i^{\\star}}, r^{\\prime}_{i^{\\star}}) \\neq (x_{i^{\\star}}, r_{i^{\\star}}) \\land g(x_{i^{\\star}}, r_{i^{\\star}}) = g(x^{\\prime}_{i^{\\star}}, r^{\\prime}_{i^{\\star}})] \\\\ \u0026amp; \\ge \\Pr_{\\vec{g} \\leftarrow G^q; y^{\\prime} \\leftarrow A^{\\prime}(\\vec{g})} [y \\ne y^{\\prime} \\land g^q(y) = g^q(y^{\\prime})] \\cdot \\Pr_{i^{\\star} \\leftarrow [q]} [i = i^{\\star}] \\\\ \u0026amp; \\ge q\\epsilon \\cdot \\frac{1}{q} \\\\ \u0026amp; = \\epsilon\\enspace. \\end{align*}\nFinally, since in the above argument, the target \\(x_{i^{\\star}}, r_{i^{\\star}}\\) only depends on \\(y\\) and random choice of \\(i^{\\star}\\) and \\(g_1, g_2, \\ldots, g_{i^{\\star} - 1}\\), we conclude by average argument there exists one specific target that has more than ε advantage.\nRemarks It seems that if we use only one hash function in the construction, the target throughout the argument will be dependent on the hash function itself, rendering the final averaing argument invalid. It is definitely an obstacle, whether or not its an artifact I currently have no idea.\nMerkle-Damgard Tree \u0026mdash; More Efficient Domain Extension If we have a length-halving function, then we can use an \u0026ldquo;inverse\u0026rdquo; GGM tree. One caveat is that this tree has depth \\(O(\\log n)\\) whereas GGM has linear depth.\nLecture 10 Continuing on hash functions CRHF is a very natural definition, but no black-box construction based on OWF of CRHF seems possible. UOWHF has a weaker definition, but still strong enough to support many applications, including:\nDigital signatures Cramer-Shoup PKE scheme Statistical hiding commitment It should be noted that both UOWHFs and CRHFs are families of functions, rather than a single one.\nWe have a simple, effective generic construction based on OWP and UHF. Quite like the complimentary to the OWP based stretch-1 PRG construction.\nDomain extension, in the inverse direction.\nIn the tree-like construction for UOWHF, one still have to use different functions in different layers. Though there has not been any proof against using the same hash function every layer, doing so would render the regular proof invalid, since we have to embed a target (either some target in the TCR definition or a random target in the TCR2 definition) into the challenge target, this target has to be independent with the instance \\(g\\).\nSpecifically, if we use the instance \\(g\\) in every layer of the challenge instance, there is a (seemingly) inherent correlation between \\(g\\) and the challenge target \\(t^{*}\\). On the other hand, if we use independent hashes every layer, we can guess one instance \\(i^{\\star}\\) and embed the input hash instance \\(g\\) into that layer. In this case, success happens when the output collision position coincides with our guess, and the collision target now will only depend on \\(y\\) and random choice independent of \\(g\\). An averaging argument can then be applied to argue the existence of some valid target.\nExtension to UOWHF (Almost) Optimal Constructions of UOWHFs from 1-to-1, Regular One way Functions and Beyond.\nAs Prof. Lai pointed out, in some decsipline, 1-to-1 means bijective. So to clearify the notation, the term \u0026ldquo;1-to-1\u0026rdquo; means injective in this lecture.\nCHRFs are UOWHFs, but OWFs imply UOWHFs but not CRHFs.\nSymmetric Crypto Hierarchy \u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;Many\u0026nbsp;Crypto\u0026nbsp;Applications\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp; \u0026nbsp;PRF\u0026nbsp;\u0026nbsp; \u0026nbsp;Digital\u0026nbsp;Signature\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp; \u0026nbsp;Stat\u0026nbsp;ZK\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp; \u0026nbsp;PRG\u0026nbsp;\u0026nbsp; \u0026nbsp;UOWHFs\u0026nbsp;[NY89,HHRVW10]\u0026nbsp; \u0026nbsp;Stat\u0026nbsp;Hiding\u0026nbsp;Com.\u0026nbsp; \u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;One\u0026nbsp;Way\u0026nbsp;Functions\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp;\u0026nbsp; Duality Between PRGs and UOWHFs From length-\\(n\\) OWF, we can have PRG with input length \\(\\tilde{O}(n^3)\\). Or UOWHF with output length \\(\\tilde{O}(n^7)\\).\nIt seems like the PRG line is already pushed to the limit. In an annecdote, Yu met with Zheng (a la [YZ12]) in a 2013 meeting, where Zheng informed him after this work with PRG, he decided to ditch theory and instead work in industry (Google).\nFigure 12: Overview of this work\nUniversal Hashing UHF from finite group multiplication and truncating.\nWell-known hashing properties:\nLeftover hash lemma For any \\(X\\in\\{0,1\\}^n\\) with \\(\\mathbf{H}_{\\infty}(X) \\ge m + d\\), conditioned on \\(h \\leftarrow H\\), \\(h(X)\\) is \\(2^{-\\frac{d}{2}}\\)-close to uniform. Injective hash lemma For any \\(X \\in \\{0,1\\}^n\\) with \\(H_0(X) \\le m - d\\), we have \\(\\Pr_{h\\leftarrow H, x\\leftarrow X}[ \\exists x^{\\prime} \\ne x: h(x) = h(x^{\\prime} ] \\le 2^{-\\Omega(d)}\\). This can be proved using a simple union bound on \\(x^{\\prime}\\). Original UOWHFs from OWP Assumption (\\(t\\), ε)-one-way permutation \\(f : \\{0,1\\}^n \\to \\{0,1\\}^n\\). We use a UHF family \\(H\\) and a truncating function \\(\\mathsf{trunc} : \\{0,1\\}^n \\to \\{0,1\\}^{n-s} \\).\nStatement \\(G : \\{ \\mathsf{trunc} \\circ h \\circ f : h \\in H\\}\\) is a family of (\\(t - n^{O(1)}\\), \\(2^s \\epsilon\\))-secure UOWHFs.\nProof We can adapt the proof for the original 1-bit shrinkage construction to this case. First we make a guess \\(x \\leftarrow \\{0,1\\}^n\\) and returns if the guess is correct. Or else, we guess \\(v = 0\\ldots0\\bar{v}, \\bar{v} \\leftarrow \\{0,1\\}^s\\) and compute \\(h = (y^{*} - f(x))^{-1} v\\). After that, we send \\(g = \\mathsf{trunc} \\circ h \\circ f\\) and \\(x\\) to \\(A\\) and receives its result \\(x^{\\prime}\\). Notice that we have \\( h \\cdot (f(x) - f(x^{\\prime}) \\ne 0\\). So if it happens that the choice of \\(v\\) makes this \\(x^{\\prime}\\) the preimage of \\(y^{*}\\) with probability \\(\\frac{1}{2^s - 1}\\).\nOriginal UOWHFs from 1-to-1 OWFs Assumption (\\(t\\), \\(\\epsilon\\))-1-to-1 OWF \\(f : \\{0,1\\}^n \\to \\{0,1\\}^l\\) ((\\(l \u0026gt; n\\))\nTools UHF \\(H_0\\), \\(\\ldots\\), \\(H_{l - n}\\), where \\(H_i : \\{ h_i : \\{0,1\\}^{l-i} \\to \\{0,1\\}^{l-i-1}\\}\\).\nStatement \\(G : \\{h_{l-n} \\circ \\ldots \\circ h_0 \\circ f\\}\\) is a family of (\\(t - n^{O(1)}\\), \\(\\epsilon\\))-UOWHFs.\nUse \\(l - n + 1\\) independent hash functions to shrink \\(f(x)\\) where \\(f : \\{0,1\\}^n \\to \\{0,1\\}^l\\) is a OWF. But the excessive use of hash function seems to be an artifact of its proof. But right now I have yet found out how to prove it.\nConstruction 1: UOWHFs from 1-to-1 OWFs Assumption (t, ε)-1-to-1 OWF \\(f: \\{0,1\\}^n \\to \\{0,1\\}^l\\) ( \\(l \u0026gt; n\\) ).\nTool Universal hash function \\(H = \\{ h: \\{0,1\\}^l \\to \\{0,1\\}^l\\} \\), Truncating function \\(\\mathsf{trunc} : \\{0,1\\}^l \\to \\{0,1\\}^{n-s}\\)\nStatement \\(G : \\{ \\mathsf{trunc} \\circ h \\circ f : h\\in H\\} \\) is a family of (\\(t - n^{O(1)}\\), \\(2^{s+1} \\epsilon\\))-UOWHFs.\nProof We can use an alternative definition of OWF, taking account of the fact that \\(f\\)\u0026rsquo;s range is sparse.\nConstruction 2 Skipped.\nCRHF from LPN Russell Impagliazzo\u0026rsquo;s Complexity Worlds Algorithmica \\(\\mathcal{P} = \\mathcal{NP}\\) (or \\(\\mathcal{NP} \\subseteq \\mathcal{BPP}\\)) Heuristica \\(\\mathcal{NP} \\ne \\mathcal{P}\\) but \\((\\mathcal{NP}, \\mathcal{U}) \\subseteq \\mathcal{AvgP}\\); \\(\\mathcal{NP} \\not\\subseteq \\mathcal{BPP}\\) but \\((\\mathcal{NP}, \\mathcal{U}) \\subseteq \\mathcal{HeurBPP}\\) Pessiland \\(\\mathcal{NP}, \\mathcal{PSamp} \\not\\subseteq \\mathcal{HeurBPP}\\), but \\(\\not\\exists \\mathsf{OWF}\\)) Minicrypt \\(\\exists\\) one way function ( 单向函数 ) but \\(\\not\\exists\\) public key crypto( 公钥密码) Cryptomania \\(\\exists\\) public key crypto ( 公钥密码 ) \u0026amp; multiparty computation 安全多方计算 Obfustopia \\(\\exists\\) fully homomorphic encryption ( 全同态加密) \u0026amp; obfuscation 混淆 \\(\\mathcal{NP}\\) vs. OWF \\(\\mathcal{NP}\\) problem: easy to verify. \\(\\mathcal{NP}\\)-hardness is defined via reduction. Its conjectured however, that \\mathcal{NP} is superpolynomially hard.\nLPN Problem It seems like that Learning with Error, Nearest Codeword Problem, Learning Parity with Noise are all related.\nWith smoothing lemma, we can prove the reduction from worst-case NCP to average-case LPN.\nOverview of the reduction\nConsider the a NCP instance \\(A, c = Ax + e\\), we want to randomize it by multiplying a matrix \\(B\\) and randomizing the secret accordingly. So we sample \\(x^{\\prime}\\) at random and comput \\(BA\\), and \\(Bc + BAx^{\\prime} = BA (x + x^{\\prime}) + B e\\). To ensure low noise, we have to make \\(B\\) sparse. The smoothing lemma states that for A that corresponds to balanced code, if \\(B \\gets Ber_{\\mu}^{q \\times m}\\) we have\n\\[ (BA, Be) \\approx_s (U^{q \\times n}, Ber_{\\mu}^q). \\]\nThere is however a simpler proof using Vazirani\u0026rsquo;s XOR lemma, that I have proof read but have yet finished. I have already read Vazirani\u0026rsquo;s XOR lemma, perhaps I should read it.\nHardness of NCP and LPN It seems that worst case NCP has time complexity \\(\\mathsf{poly}(n) \\cdot e^{\\mu n}\\). For average LPN, the BKW algorithm gives \\(2^{O(\\frac{n}{\\log n})}\\) complexity. So it seems that worst case NCP is indeed very hard.\nCryptographic Hashing from LPN Construct a intermediate problem \\(\\mathsf{bSVP}\\) that is the analogue to SIS problem. We then construct an Expand function that is\n1-to-1 output sparse 0-1 vector parallel We can then directly get a CRHF.\nExpand\nThe expand function is very easy. For \\(L\\cdot t\\) bit input, the function expand it to \\(2^L \\cdot t\\) bit output, by first partition the input into \\(t\\) \\(L\\)-bit blocks, translate each block into \u0026ldquo;one-hot\u0026rdquo; encoding, and then output. The output has exactly \\(t\\) ones, and by definition it is an injective map.\nLPN Implies bSVP Suppose we have a bSVP solver \\(O\\), we can construct a distringuisher \\(A^O(A, y)\\).\nWe can first find a solution \\(x\\) to \\(A^T\\), them determine which is the case by the bias of \\(y^Tx\\). If \\(y\\) is uniform, then \\(y^Tx\\) is also uniformly random. Otherwise, \\(y^Tx\\) has biased Bernoulli distribution from piling up lemma.\nThis reminds me of knapsack LPN problem.\nHardness T-hard (\\(n\\), \\(\\mu\\), \\(m\\))-LPN implies \\(\\sqrt{T}\\)-hard CRH \\(h_A\\), where \\(h_A (y) = A \\cdot \\mathsf{Expand}(y)\\), \\(t^2 \\le m \\le T = 2^{\\frac{\\mu t}{1 - 2\\mu}}\\).\nI wonder if Knapsack-LPN can be used to construct a CRHF and how this theorem is proved.\nOvercoming Weak Expectations Typical crypto setting \\(P\\): pick random secret key \\(R \\leftarrow \\{0,1\\}^m\\). But in practice, we can only guarantee that \\(R\\) has large entropy.\nThere are three options. (\\(X\\) is the weak source)\nClever Design \\(P\\) so that it can withstand weak randomness Modular Design key deriviation function \\(h : \\{0,1\\}^n \\to \\{0,1\\}^m\\) subject to \\(R = h(X)\\) is good for \\(P\\). The goal is to assume little-to-nothing about \\(P\\). Dumb Use \\(R = X\\) and hope for the best. Pedantic Viewpoint Fix \\(P\\) and any \u0026ldquo;legal\u0026rdquo; \\(A\\) Let \\(f( r)\\) be the advantage of \\(A\\) on key \\(r\\).\nUnpredictability apps: \\(f( r) \\in [0,1]\\) Indistinguishability apps: \\(f( r) \\in [-\\frac{1}{2}, \\frac{1}{2}]\\) In the ideal world, the advantage of \\(A\\) is \\(|E(f(U_m))| = |\\sum_r \\frac{1}{2^m} f( r)|\\) In the real world, the advantage of \\(A\\) is \\(|E(f( R))| = |\\sum_r p( r) \\cdot f( r) |\\) Simple Case For unpredictability application, we have any (\\(t\\), \\(\\epsilon\\))-secure \\(P\\) in the ideal model is also (\\(t\\), \\(\\ 2^d \\cdot epsilon\\))-secure in the \\(m-d\\)-real model.\nProof\n\\(E_r(p( r)\\cdot f( r)) \\le 2^m \\frac{1}{2^{m-d}} \\sum_r \\frac{1}{2^m} f( r) = 2^d E(f(U_m))\\).\nNotice that we used the fact \\(f( r)\\) is non-negative throughout the proof.\nIndistinguishablility Application The paper introduced a square security notation, but I have yet grasped it.\nLecture 11 From this lecture through the next three or four lectures, Prof. Liu will take on this lecture. 两节课讲一下现代密码学的主要原则，然后在之后讲IBE，ABE，FHE等内容，再讲一两个证明。\nOutline A brief introduction Principles of Modern Crypto framework of modern crypto mathematics of pkc PKE Digital signature Hash function Hybrid encryption and PKE A Brief Introduction to Crypto Crypto ≈ Cryptography + Cryptanalysis\nUsually cryptanalysis is very important in symmetric-key cryptography (e.g. Hash function, secret-key cryptography).\nThe Basis Goals of Cryptography Enabling parties to communicate over an open communiation channel in a secure (confidentiality, integrity) way. Cryptogrpahic primintives Secrecy / Confidentiality: SKE / PKE Integrity / Authenticity: MAC / PKE, using Hash Function (this primitive is keyless, isn\u0026rsquo;t there public coins?) Private Key Encryption Two parties share keys previously.\nMessage Authentication Code Only sender and receiver can compute and verify MAC.\nPublic Key Cryptography Modern provable security is (arguably) more biased towards PKC.\nIn pure symmetric crypto, people typically use a centralized online key distribution server to handle session key establishment requests. Whereas in public key setting, one can use certificates to do this.\nIn 1976, W. Diffie and M. Hellman purposed a paper \u0026ldquo;New Directions in Cryptography\u0026rdquo; to motivate simplifaction of key distribution and management in symmetric-key cryptography.\nDigital Signature Like MAC, but publicly verifiable.\nPublic Verifiability Transferability Non-repudiation Principles and Framework of Modern Cryptography Classic cryptography \u0026mdash; symmetric key encryption algorithms.\nClassical Cryptography Art Ad-hoc Modern Cryptography (Methodological) Science Components Syntax (what components should a system have) Security Models (what is the definition of security and what is the adversary\u0026rsquo;s ability) Provable Security (reduction) Private Key Encryption Syntax: three algorithms\n\\(KeyGen(1^n) \\to k\\) \\(Enc(k, m) \\to c\\) \\(Dec(k, c) \\to m\\) We can then define key space \\(\\mathcal{K}\\), messsage space \\(\\mathcal{m}\\) and correctness of private-key encryption.\nKey space for single-table substitution: \\(26!\\)\nKerckhoff\u0026rsquo;s Principle Security only depends on secrecy of key, rather than the algorithm. The rationale behind this principle is that changing keys is much easier than changing algorithms. So to be more complete, cryptographic designs should be made completely public.\nMoreover, it feels safer after witnessing every one around the globe failed to break a published cryptographic scheme.\nSo It appears there are indeed people who believe that algorithms should be kept secret (at least in the civilian application).\nBrute-Force At least the key space should be large enough to make exhaust-search attack infeasible. But note that this is not sufficient.\nPrinciples of Modern Cryptography Principle 1 Formal Definitions, provides what threats are in scope and what security guarantees are desired. Security guarantee and threat model.\nSecurity gurantee \u0026mdash; semantic security, not a bit of additional information is leaked Threat model \u0026mdash; Ciphertext-only attack, known-plaintext attack, chosen-plaintext attack, chosen-ciphertext attack. Lecture 12 现代密码学的原则 明确定义 包括正确性、安全性的定义(threat model, security guarantee) 精确的假设 由于需要使用计算安全性，而统计意义上的安全性很难得到 We are almost entirely talked away from using ad hoc assumptions. Though this principle has nothing to do with the content of assumptions. 安全性证明 定义与假设允许我们分析，安全保证能否在相应的模型下被假设蕴含，这就是安全性证明的功能 Provable Security and Real-World Security The art part of modern cryptography: rigorous approach leaves room for creativity in:\nDeveloping definitions suited to contemporary applications and environments (e.g. CCA, UC) Proposing new mathematical assumptions (e.g. Coppersmith, Shor) Designing new primitives (e.g. IBE a la Shamir, PKE a la Diffie and Hellman) Constructing novel schemes and proving them secure Attacking deployed cryptosystems Provable Security and Real-World Security A proof of security is always relative to the definition being considered and the assumptions being used.\nThe proof may be irrelevant if\nThe security guarantee does not match what is needed The threat model does not capture the adversary\u0026rsquo;s ture abilities The proof of security is meaningless if the assumption is refuted.\nFramework of Modern Cryptography Personal summary of Prof. Liu. Framework\nSymmetric Cryptography Encryption Message Authentication Code Asymmetric Cryptography Public Key Encryption Digital Signature IBE, ABE, FHE Blind Signature, Ring Signature Commitment, Zero-Knowledge Proof Hash function Research Directions in Asymmetric Cryptogrpahy 应用密码算法的业务系统 应用密码算法的协议 密码原语的定义：应用驱动、密码理论研究 密码原语方案设计：构造符合源于定义并在其模型下证明安全的方案 困难设计：困难问题的求解算法研究 Number Theory Cyclic Group\nPrimes Generating large primes \u0026mdash; a probablistic method. Sample a random large enough number, using a conjecture we can argue that with large probability we can actually get a prime number, if we repeat the process a small number of times. The primality test can be a coRP algorithm.\nDiscrete Logarithm Assumption We always work on finite groups. The groupgen algorithm generates algorithms for \u0026ldquo;translation\u0026rdquo; in \\(\\mathbb{G}\\). Theoretically, a GroupGen algorithm is related to the instance of DL, CDH, DDH instance, but in practice we can simply choose NIST recommended standard values.\nAn Example GenGroup Algorithm\nGenerate a uniform n-bit prime \\(q\\) Choose a \\(l\\)-bit prime \\(p\\) such that \\(q | (p - 1)\\) Choose a uniform \\(h \\leftarrow \\mathbb{Z}_p^{*}\\) Set \\(g = h^{\\frac{p - 1}{q}}\\) Output \\(g, q, p\\) Another GenGroup Algorithm\nOn subgroups of finite field On Elliptic Curves (cf. ECDSA) Inverse on a Generic Group Simply \\(h^{-1} = h^{q - 1}\\).\nPublic Key Cryptography CPA / CCA threat model and IND / SS security guarantee.\nTrick: if the fine-defined constraint, e.g. challenge ciphertext cannot be further queried, is not used, then the proof itself is most certainly useless.\nLecture 13 Some kind of code: 787228. Last lecture we have covered public key encryption. This lecture we will continue with digital signature.\nDigital Signature Patches need to be verified publicly.\nProperties:\nCorrectness. \\(\\mathsf{Verify} (pk, m, \\mathsf{Sign} (sk, m)) = 1\\) for every \\(m\\)\nSecurity (EUF).\nSecurity guarantee: non-forgeability Threat model: signing oracle, the advantage is just the success probability of forgery. Extension: strong unforgeability, which means challenge (\\(m\\), \\(\\sigma\\)) pair needs to be unique, rather than \\(m\\) has to be unique.\nExample DSA and *ECDSA both are included in the current Digital Signature Standard, issued by NIST.\nAlthough ECDSA is no longer the recommended DS standard, it is still considered more efficient and have at least the same security level as RSA signatures. In ECDSA, the group parameter can be shared, whereas in RSA the encryption modulus cannot be shared.\nSyntax: A group generation algorithm that generates the description of a cyclic group, its order and a generator. An example is to generate the prime-\\(q\\)-order subgroup of a larger multiplicative group \\(\\mathbb{Z}_p^{*}\\).\n\\(KeyGen(1^n) \\to (pk, sk)\\) The group parameter can be considered public. In practice, this algorithm can just sample a private order and output \\(pk = \\mbox{group}, g^x\\) and \\(sk = x\\).\nAlso, two functions \\(H: \\{0,1\\}^{*} \\to \\mathbb{Z}_q\\) and \\(F: \\mathbb{G} \\to \\mathbb{Z}_q\\) are included in the public key as auxiliary information.\n\\(\\mathsf{Sign}(sk, m) \\to c\\) First hash the message to \\(\\mu = H(m) \\), and then sample \\(k \\leftarrow \\mathbb{Z}_q\\). Then compute \\(r =F(g^k) \\), and \\(s = k^{-1} (\\mu + xr)\\). If \\(r = 0\\) or \\(s = 0\\), sample \\(k\\) again and repeat. Output \\(\\sigma = (r, s)\\). \\(\\verify(pk, m, \\sigma) \\to \\{0,1\\}\\) Output 1 iff. \\(r = F(g^{H(m) s^{-1}} y^{r s^{-1}})\\). Security: to prove the euf-cma security of DSA / ECDSA, the function \\(F, H\\) should be modelled as random oracle. \\(H\\) can sometimes be considered as a random oracle, \\(F\\) is completely not like a hash function. In DSA, \\(F\\) is just modulo \\(q\\); In ECDSA, \\(F\\) is the first coordinate modulo \\(q\\).\nHash Function Syntax: \\(H: \\{0,1\\}^n \\to \\{0,1\\}^{l(n)}\\).\nSecurity guarantee: collision-resistant.\nWeaker Security: second-preimage or target-collision resistance: given a uniform \\(x\\) it is infeasible to find \\(x^{\\prime}\\) such that \\(x\\) and \\(x^{\\prime}\\) collides.\nPreimage resistance: given a uniform target \\(y\\) it is infeasible to find \\(x\\) such that \\(y = H(x)\\).\nBirthday attack: an upper bound on the security of \\(l(n)\\)-long is \\(l(n) / 2\\).\nPopular Crypto Hashes:\nMD5 Broken SHA1 Nearly broken SHA2 OK SHA3 Secure but slow Hybrid Encryption Encapsulate a symmetric session key from public key encryption, and then use this session key to encrypt subsequent data.\nKEM / DEM are a new pair of primitives to capture / simplify hybrid encryption method.\nKey Encapsulation Method Syntax: there are three algorithms \\(KeyGen\\), \\(Encap\\), \\(Decap\\)\nThe CPA security is defined as follows. The challenge text is a ciphertext and a key. If \\(b = 0\\), the ciphertext is the encryption of the key; if \\(k = 1\\), the key and the ciphertext are independent. The adversary guesses the value \\(b\\).\nThe CCA security is defined by adding a decryption oracle.\nExample El Gamal-like KEM: actually I think it is more like DH-key exchange. Up on agreeing \\(g^{xy}\\), both sides hash this value to produce a key.\nLecture 14 Introduction to IBE\nStarting from motivation (i.e. application in real life), abstract the definition.\nFrom definition derive a construction and the security threat model.\nFrom security model and construction, derive a security proof.\nMotivation of Idenity-based Encryption Public key cryptogrpahy partly solved the key distribution nuisance in symmetric key cryptography, but PKI is still somewhat troublesome. So key distribution should not be considered completely solved in PKC.\nIntroduction to IBE Certification issuing is not free.\nAdi Shamir introduced IBE in 1984. The application scenario is one-time key distribution in a large system (e.g. bank and multinational corporation).\nOne generalization is that an arbitrary string can be used as the public key.\nThe concept of Identity-based Cryptography Introduced by A. Shamir in 1984 Identity-based Signature Scheme was proposed in 1987 The first usable identity-based encryption shcemes were purposed in 2001 from pairing and QR Correctness If the same \\(id\\) is used, decryption will ensure plaintext recovery.\nSecurity IND-ID-CCA: Define two oracles\n\\(OKeyGen(id) \\mapsto KeyGen(mpk, msk, id)\\) \\(ODec(id, ct) \\mapsto Dec(mpk, KeyGen(mpk, msk, id), ct)\\) And a number of restrictions:\nThe challenge identity must not be previously queried to \\(OKeyGen\\) After challenge phase, the adversary must not query \\(OKeyGen\\) with \\(id^{\\star}\\) or query \\(ODec\\) with \\(id^{\\star}, c^{\\star}\\). Construction Underlying Mathematics Bilinear Map Groups: Let \\(G\\) and \\(G_T\\) be two cyclic groups of order \\(p\\) and \\(q\\), then a map \\(e: G \\times G \\mapsto G_T\\) is a bilinear map if\nBilinear for all \\(u, v \\in G\\) and \\(a, b \\in \\mathbb{Z}\\) it holds that \\(e(u^a, v^b) = e(u, v)^{ab}\\). Non-degenerate \\(e (g, g) \\ne q_{G_T}\\). We say \\(G\\) is a bilinear group if the group operation in \\(G\\) can be computed efficiently and there exists a group \\(G_T\\) and an efficiently computable bilinear map \\(e: G \\times G \\to G_T\\) as above.\nWe let \\(GenGroup\\) a group generation algorithm that generates \\(G, G_T, p, q, e\\).\nBDH assumption: It is hard to compute \\(e(g, g)^{abc}\\) given random \\(g, g^a, g^b, g^c\\).\nOriginal Construciton The original construction satisfies IND-ID-CCA security in the RO model. Some considered selective IND-sID-CCA security in the standard model.\nA number of subsequent works improved the security.\nFurther Development The PKG can read any ciphertexts. This can introduce\nkey escrow problem The revocation of user secret keys Anonymous IBE (Homework) Hierarchical IBE Digital Signature ECDSA is the key algorithm to ensure Bitcoin\u0026rsquo;s functionality.\nIn Bitcoin, transaction is authenticated by ECDSA. A wallet is the database of pk / sk pairs. In Bitcoin and other cryptocurrency, it is a desireable thing to have deterministic wallets.\nAdvantages of Deterministic Wallet\nLow-maintenance wallets with easy backup and recovery (just backup the seed) Freshly generated cold addresses (cold means never been on the Internet) Trustless audit Hierarchical wallet allowing a treasurer to allocate funds to departments Though it should be noted that the treasurer use case and auditor use case cannot be used together.\nStealth address and determinstic wallet.\nLecture 15 Deterministic Wallet Cryptographically, not very sound.\nWallet vs. Stealth Address Wallet: managing the keys from the wallet owner.\nStealth address: to send money to a certain publicly visible master key in such a way that this key does not appear in the ledger at all, so that users\u0026rsquo; privacy gets more protection.\nStealth address can serve as wallet, as a matter of fact.\nMonero The Payer The public The Payee A = aG, B = bG \\((a,b)\\in\\mathbb{Z}_p^2\\) \\(r\\leftarrow \\mathbb{Z}_p\\) \\(R = rG\\) \\(s = H(aR) + b\\) \\(S = H(rA)G + B\\) For each transaction, the payer uses a different \\(r\\).\nProperties (intuitive)\nPrivacy Each coin receiving address is freshly generated, with random \\(r\\) Security Only the payee knows \\(b\\) Convenience The check needs to be run each for each transaction Enhanced Security and Convenience \\(b\\) can be stored in cold storage Can be used to implement trustless audit. Problem If one secret key is compromised, the master secret key may be compromised.\nRationale of the Problem Functionality\nUser has a Master Public Key Payer can compute a DVK from MPK without interaction User can examine from DVK if its the recepient Correctness Checking transaction and signature verification algorithms are both correct\nUnforgeability Three oracles: verification key adding oracle, signing key corruption oracle, and signing oracle.\nNotice that signing key corruption orecle, designed to take care of signing key corruption, is not considered in Monero. That is way Monero has the aforementioned problem.\nCommitment Schemes This part is presented by Prof. Yu.\nDefinitions Correctness Hiding Binding Two Types of Commitment Schemes Standard Statistically binding, computationally hiding Perfect Statistically hiding, computationally hiding Lecture 16 In this lecture we are talking about FHE.\nApplication Secure cloud computing. Securely deligate processing of data without giving away access to it.\nDefinition Homomorphism: We can apply some class of function \\(f\\) to \\(Enc(m)\\) to get \\(Enc(f(m))\\).\nFirst Attempt: RSA RSA satisfies multiplicative homomorphism. The \u0026ldquo;plain\u0026rdquo; RSA satisfies that after multiplying two ciphertexts, we get the ciphertext of multiplying two plaintexts.\nHomomorphism on Arbitrary Operation AND, XOR is Turing-complete.\nThe first breakthough is ascribed to Craig Gentry. ACM best doctoral paper.\nFigure 13: Development of Gentry\u0026rsquo;s Work as of 2020\nMechanism Behind HE What objects support addition and multiplication? polynomials, matrices, and integers.\nToday we use [GHDV09] as an example, which may seems a bit untidy, but still good enough to demonstrate the basic ideas of HE.\nThe construction of [GHDV09]:\nSecret Key large odd prime \\(p\\) Encrypt a bit \\(b\\) - Pick a random large multiple of \\(p\\), \\(q \\cdot p\\) - Pick a small \\(r\\) and let cipher text be \\(c=q\\cdot p+2r+b\\)\nDecrypt a ciphertext \\(c\\) first \\(\\mod p\\) then \\(\\mod 2\\) The noise is added to prevent GCD attacks in the IND-CPA game: GCD(\\(p \\cdot q_1\\), \\(p \\cdot q_2\\)) = \\(p\\). We rely on an \u0026ldquo;approximate-GCD\u0026rdquo; assumption.\nWhen we perform homomorphic multiplication, there will be a quadratic blow-up in noise. When the noise grows too big, and becomes bigger than \\(\\frac{p}{2}\\) then decryption security will be violated.\nNow we can do a lot of additions and some multiplications. We have a \u0026ldquo;somewhat\u0026rdquo; homomorphic scheme. Enough to perform some low-multiplicative-depth tasks, like database search, spam filtering, etc.\nThe last step is accomplished through bootstrapping.\nFrom Somewhat HE to Full HE Consider an \u0026ldquo;augmented decryption circuit\u0026rdquo;\nFirst decrypt \\(c_1\\) and \\(c_2\\) and them perform an NAND. We call this circuit \\(\\hat{C}\\). The first layer of circuit \\(\\hat{C}\\) has input \\(c_1\\) (resp. \\(c_2\\)) and \\(sk\\). If \\(\\hat{C}\\) is in the evaluatable range of SHE, then Gentry shows that this SHE scheme actually implies a FHE scheme.\nThe natural idea is that decryption will kill all noise, so we can use decryption circuit to reduce all noise. Only the secret key are encryption, since the ciphertext is already public. So the output only carries noise from encryption of secret key, which is fresh every time. To summarize, we thus have obtained a \u0026ldquo;refresh\u0026rdquo; operation.\nIssues Omitted The SWHE cannot correctly evaluate its decryption circuit, we have to \u0026ldquo;squash\u0026rdquo; this circuit by leaking some information of decryption key Is it safe to encrypt the key by itself? The circular security assumption still seems not proven to this day. In this example its self-loop. How to better control the noise accumulation? There are new scheme like GSW. Is it practical? NO. FHE from LWE LWE Parameters: modulus \\(q\\), dimension \\(n\\), number of samples \\(m\\) Secret: uniformly random vector \\(s \\in \\mathbb{Z}^n_q\\). Noise: \\(e\\) sampled from some distribution such that \\(|e| \\ll q\\) whp\nConstruction Public key \\(A, b = As + 2e\\), notice that here the multiple \\(2\\) is fine, since GCD(2, q) = 1, and we can reduce plain LWE to this version of \u0026ldquo;2LWE\u0026rdquo; by multiplying \\(2^{-1}\\) on both sides. Encryption Sample \\(t \\leftarrow \\{0,1\\}^m\\) and \\(c = t A, t b + m\\). Homomorphic Addition Adding two ciphertexts together, also, since the modulus is \\(q\\), the ciphertext will not expand every time.\nHomomorphic Multiplication If \\(|e_1| \\ll q\\) and \\(|e_2| \\ll q\\) then \\(m_1\\cdot m_2 = (2e_1 + m_1)(2e_2 + m_2) \\mod q \\mod 2\\).\nThen let \\(a^{\\prime} = t A\\), \\(e^{\\prime} te \\), we have\n\\begin{align*} m_1 \\cdot m_2 \u0026amp;= (2e_1 + m_1) (2e_2 + m_2) \\\\ \u0026amp;= (b_1 - s^T a_1) (b_2 - s^T a_2) \\end{align*}\nSo we have to provide quadratic terms of \\(s_i s_j\\) and 1-degree term \\(s_i\\) in encrypted form. But there is also a problem of coefficient of \\(Enc(s_i)\\), \\(Enc(s_i\\cdot s_j)\\) too big. We then apply the binary representation trick, i.e. publish encryption of \\(2^0s_i\\), \\(2^1s_i\\), \\(2^2 s_i\\), \\(\\ldots\\).\nIssues Omitted If we do not want to rely on circular security, we have to resort to limited multipliation depth, and the key length will be linear to the depth.\n[BV14] presented some better noise management tricks, using a \u0026ldquo;sequentialization\u0026rdquo; technique.\nSecure Computation In this chapter we discuss secure multiparty computation.\nFirst we construct an OT scheme based on PKE with obviously sampleable PKs. This property requires that\nA sampling algorithm can sample pk identically distributed to the pk in real \\(KeyGen\\) algorithm The sampled pk cannot have a decryption key. ","permalink":"http://localhost:1313/note/provsec/","summary":"\u003ch2 id=\"basic-information\"\u003eBASIC INFORMATION\u003c/h2\u003e\n\u003cp\u003eThis is the notes of the course \u0026ldquo;Provable Security\u0026rdquo;. The first few\ncourses will be taught online. While subsequent courses are still\nunsettled.\u003c/p\u003e\n\u003cp\u003eI took this course last year, and I am pretty confident about my grasp\nof basic concepts like universal hash function, GL theorem, basic PRG,\nPRF constructions, etc. But contents like CRHF and PRP are still\nrather alien to me, so in this course I will review the previous\ncontents and try to master the missing pieces.  Also it is desireable\nto incopreate the previous notes and complete the notes altogegher.\u003c/p\u003e","title":"可证明安全理论笔记"},{"content":"This is my notes of the 18-19-1 course ``Computational Complexity\u0026rsquo;'.\nLecture 1: Introduction Introduction This is the lecture note of Prof. Fu\u0026rsquo;s Computational Complexity (not to be confused with the Computational Complexity: Advanced Topics in the second semester). As Prof. Fu is not following strictly the structure of the book, I consider it necessary to take notes of the essential contents taught in the lectures, and subsequently organized them as a series.\nThe notes will be updated every week, sometimes twice a week. Some elaborations based on reading from the book may also be added here.\nAuxiliary Course Information Information about the teaching assistant:\nName 杨启哲 Phone Number 15901917102 Email Address mailto:spacepenguin9494@gmail.com Also homework will be handed down to us through email. I chose the school\u0026rsquo;s email address to communicate with him.\nAn Introduction to Computational Complexity There are some classical problems in computer science (or mathematics at large):\nDiophantine Problem (i.e. finding integer solutions to linear equations)\nMatching Problem\nVertex Cover Problem\nGraph Isomorphism Problem\nThere are most established results regarding the algorithmic solution to these problems. The Diophantine Problem is known to be undecidable \u0026ndash; there does not exist algorithm to solve this problem. For the Matching Problem, there is an algorithm that solves this problem in polynomial time. The Vertex Cover Problem is NP-Complete \u0026ndash; any polynomial algorithm that solves this problem would implies that \\(\\mathbf{P}=\\mathbf{NP}\\), which is highly unlikely. The Graph Isomorphism Problem is not known to be in \\(\\mathbf{P}\\), but it is surely in \\(\\mathbf{NP}\\).\nComplexity of computation is about classifying various problems in computer science and comparing such classes. Throughout the course, some main techniques in theoretical computer science would be explained, including:\nRecursion Theoretical Method\nAlgebraic Method\nCombinatorial Method\nProbabilistic Method\nTime Complexity Definition of Turing Machine First the definition of Turing Machine is introduced. Informally, we have a k-tape, unidirectional, input-read-only Turing Machine is represented by a tuple \\(\\mathbb{M}=(\\Gamma, Q, \\delta)\\), where \\(\\Gamma\\) is its finite alphabet, \\(Q\\) is its finite state sets, and \\(\\delta:Q\\times\\Gamma^{k}\\to Q \\times \\Gamma^{k-1}\\times \\{L,S,R\\}^{k}\\) is its transition function. It should be noted that without loss of generality we assume \\(q_\\text{start},q_\\text{halt}\\in Q\\) and \\(\\{{0,1,\\triangleleft,\\Box}\\}\\subset \\Gamma\\).\nIt is clear that the full configuration of a Turing Machine consists of its 1. state, 2. contents of working tapes, and 3. head position. (As we will see later, any Turing Machine \\(\\mathbb{M}\\) can be transformed into another Oblivious Turing Machine \\(\\mathbb{M}^\\prime\\) whose head movement is only dependent on its input length.)\nDefinition of Problems After defining the Turing Machine, we need to describe the set of problems suitable to the aforementioned definition, and the conditions a Turing Machine solves this problem. This gives rise to the definition of problems. A function \\(f:\\{0,1\\}^{*}\\to\\{0,1\\}^{*}\\) is called a problem, and a TM \\(\\mathbb{M}\\) computes/solves this problem if for every string \\(x\\) of finite length, whenever \\(x\\) is written on \\(\\mathbb{M}\\)\u0026rsquo;s input tape, \\(\\mathbb{M}\\) halts with \\(y=f(x)\\) written on its output tape. This can be written compactly as \\(\\mathbb{M}(x)=f(x)\\) for all \\(x\\in\\{0,1\\}^{*}\\).\nWe shall be focused on decisional problems \\(d:\\{0,1\\}^{*}\\to\\{0,1\\}d:\\{0,1\\}^{*}\\to\\{0,1\\}^{}\\) from now on. A language \\(L\\) is a set of finite strings. The term \u0026ldquo;\\(\\mathbb{M}\\) accepts \\(L\\)\u0026rdquo; means that for any string \\(x\\), \\[\\mathbb{M}(x)=1\\iff x\\in L\\]\nSome exercise on designing Turing Machines are provided. Actually there more elaborate exercises on Arora\u0026rsquo;s book. I will defer the solutions to these interesting problems to a compilation of solutions to exercises in Chapter 1 of Arora\u0026rsquo;s book.\nTime Constructible Functions Then the notion of time constructible functions is introduced. There are two definitions provided in this lecture. There are two definitions, where the second one implies the first one.\nSuppose \\(T:\\mathbb{N}\\to\\mathbb{N}\\) and \\(T\u0026gt;n\\), then\n\\(T\\) is time constructible if there exists a TM that computes the function \\(1^n\\mapsto \\llcorner{T(n)}\\lrcorner\\) in \\(O(T(n))\\) steps.\n\\(T\\) is time constructible if there exists a TM that halts at exactly \\(T(n)\\) steps.\nBy the fact that a counter that a counter TM that counts up to \\(n\\) runs in \\(O(n)\\) steps (this can be proved using a simple counting trick), one can confirm that the second definition implies the first one. From now on we will only consider time constructible functions, since if a function \\(T\\) is time constructible, we can hard-wire the TM in \\(T\\)\u0026rsquo;s definition into arbitrary TM \\(\\mathbb{M}\\), resulting a TM that will exactly halt in \\(O(T(n))\\) time. This technique is called hardwiring a clock to a Turing Machine.\nOblivious Turing Machine A Turing Machine is oblivious if its head position at step \\(i\\) only depends on its input length \\(|x|\\) and \\(i\\) itself. Actually, any TM can be transformed into an oblivious one, from the technique that transform arbitrary finite number of tapes into one read-write tape Turing Machine. This will nevertheless introduce a quadratic overhead.\nChurch-Turing Thesis Church-Turing Thesis states that every physically realizable computing device can be simulated by a Turing Machine. As there are (possibly) infinitely many models of computing devices that may rely on bizarre physical phenomenon, this is only a thesis so far, rather than a theorem. Note that there is a strong version of this thesis, stating that the overhead of such simulation is only polynomial in the length of input.\nUniversal Turing Machine The fact that Turing Machine is finite sparkles the idea that as a mathematical object, Turing Machine can be encoded, and furthermore written on the input tape of other Turing Machine. This led to the notation of Universal Turing Machine, which takes the description of some Turing Machine \\(\\mathbb{M}\\), its input \\(x\\), and outputs the result \\(\\mathbb{M}(x)\\) as \\(\\mathbb{M}\\) would.\nMore precisely, Prof. Fu presented a simple scheme to encode the transition function \\(\\delta\\) of a Turing Machine, that I will skip due to its triviality.\nThere are also two assumptions introduced regarding the encoding of Turing Machine:\nEvery TM is represented by infinitely many binary strings.\nEvery finite binary string (canonically) represents a TM.\nThe first assumption can be satisfied by sticking arbitrary \\(1\\)\u0026rsquo;s to the back of the encoding and regard them as the encodings of a same TM. While the second restriction can be satisfied by mapping all the invalid encodings to some dummy TM.\nEncoding of Turing Machine gives rise to the efficient enumeration of Turing Machine. By fixing an effective bijection between \\(\\{0,1\\}^{*}\\) and \\(\\mathbb{N}\\), we can enumerate all the Turing Machine by natural numbers.\nLecture 2: Time Complexity The main body of this lecture is devoted to the proof of the complexity of universal Turing Machine. The main idea behind the proof is a construction that minimize the movement of tapes by splitting the tape into sparse zones. The analysis of this algorithm is called amortized analysis and maybe of independent interest. Prof. Fu has taught us the essence of this proof, and I think it is most beneficial for me to work out the fine details by myself in this note.\nSimulation Overhead of Universal Turing Machine Suppose \\(L\\) is computed by an time \\(O(T(n))\\) TM for some time constructible \\(T\\). Then there is a universal TM that decides \\(L\\) in time \\(O(T(n)\\log(T(n)))\\). Where the constant hidden in the asymptotic expression is only dependent on the number of tapes, alphabet size, and the number of states of the simulated TM.\nAnother theorem and its corollary are also given in this lecture as exercises.\nDiagonalization and Universal Turing Machine Using the technique of diagonalization, one can prove that there exists some problems that is not decidable by any Turing Machine. Two of them are introduced in Arora\u0026rsquo;s book and in this lecture, they are\n\\(\\mathsf{UC}:=\\{x|\\mathbb{M}_x(x)\\text{ does not halt or outputs }1\\}\\),\n\\(\\mathsf{HALT}:=\\{\\langle \\alpha,x\\rangle|\\mathbb{M}_\\alpha(x)\\text{ halts within finite steps}\\}\\).\nWhile the first one is strongly related to the diagonalization technique, and second one is reducible to the first one.\nSpeedup Theorem In the last part of this lecture, the speedup theorem is introduced. There are two versions, and only the simple (and somewhat trivial) version is introduced. This basically translate to using a machine with bigger alphabet and bigger states to compress several steps in a TM into one in a bigger TM. This theorem is proposed by Hennie and Stearns in the context that omitting the constant factor is justifiable when defining the \\(\\mathbf{DTIME}(f(n))\\). I will omit the proof here.\nLecture 3: Time Complexity In this lecture the complexity class \\(\\mathbf{P}\\) is defined by computing the union of all the languages that is computable in polynomial time. Formally, Let \\(T:\\mathbb{N}\\to\\mathbb{N}\\) be a time function, and a language (problem) is in \\(\\mathbf{DTIME}(T)\\) if there exists some constant \\(c\u0026gt;0\\) and a Turing Machine \\(\\mathbb{M}\\) that decides \\(L\\) in time \\(c\\cdot T(n)\\).\nThe complexity class \\(\\mathbf{P}\\) is defined by the union of all polynomially computable languages (decisional problems), i.e. \\[\\mathbf{P}:= \\mathop{\\bigcup}_{c\\geq 1}\\mathbf{DTIME}(n^c)\\] Similarly, we have \\[\\mathbf{EXP}:= \\mathop{\\bigcup}_{c\\geq 1}\\mathbf{DTIME}(2^{n^c})\\]\nNondeterministic Turing Machine For pure theoretical interest, the Non-Deterministic Turing Machine (NDTM) is introduced. This model incorporates the notion of \u0026ldquo;guessing\u0026rdquo; into computation, and is not considered physically realizable.\nThe reason why a NDTM is considered capable of \u0026ldquo;guessing\u0026rdquo; is that it allows two transition functions, and therefore on every input, a tree of binary choices are made possible. Apart from that, a special state called accepting state is introduced, and some NDTM accepts on some input string means that there exists a path of binary choices such that the machine halts with the accepting state. Note that this also implies that it should be very hard to negate the result of some Non-Deterministic Turing Machine, since it takes exponential steps to determine its result (with no extra information). This trivial result is related to the fact that \\(\\mathbf{NP}\\neq\\mathbf{coNP}\\).\nThere are two points about NDTM in my notes on that lecture, they are:\nThat some Non-Deterministic Turing Machine runs in time \\(T(n)\\) means that every brunch of choices halts within \\(T(n)\\) steps.\nA string \\(x\\in\\{0,1\\}^{*}\\) is accepted by some NDTM \\(\\mathbb{N}\\) means that there exists a sequence of choice such that the machine \\(\\mathbb{N}\\) on input \\(x\\) halts with the accepting state (contrarily, \\(\\mathbb{N}\\) refuses \\(x\\) means that for every sequence of choice, the machine refuses this string). A language \\(L\\subset\\{0,1\\}^{*}\\) is accepted by a NDTM \\(\\mathbb{N}\\) means that \\(x\\in L \\iff \\mathbb{N}(x)=1\\).\nMany classic algorithmic problems have trivial solutions on a NDTM. For instance, let\u0026rsquo;s consider the traveling salesman\u0026rsquo;s problem. An NDTM can simply use the two transition functions to guess a binary string that corresponds to some canonical representation of a permutation of all the vertices on graph, and then verify that such vertices actually consist of a path, and such a path satisfies the distance requirement. If so, it enters accepting state, or else, it halts without accepting. Trivially, the language \\[L := \\{{\\langle{G,d}\\rangle|G\\text{ has a cycle of length less than }d}\\}\\] can be accepted by such a NDTM.\nClassifying Complexity by Nondeterministic Turing Machine Following the definition of \\(\\mathbf{DTIME}(T(n))\\), we can come up with \\(\\mathbf{NTIME}(T(n))\\). A language \\(L\\in\\mathbf{NTIME}(T(n))\\) if and only if when there exists some NDTM \\(\\mathbb{N}\\) that accepts \\(L\\) in time \\(T(n)\\).\nNaturally, we can define the complexity class that consists of all the problems that can be polynomial-time determined by Nondeterministic Turing Machine, i.e. \\(\\mathbf{NP}\\).\n\\[\\mathbf{NP}:= \\mathop{\\bigcup}_{c\\geq 1} \\mathbf{NTIME}(n^c)\\]\nSimilarly, extending polynomial to exponential leads to the definition of \\(\\mathbf{NEXP}\\).\n\\[\\mathbf{NEXP}:= \\mathop{\\bigcup}_{c\\geq 1} \\mathbf{NTIME}(2^{n^c})\\]\nThe slides state that there is surprisingly small number of result concerning the connection between the two versions of definitions of complexity classes, except for some trivial results. And I remember there is similar result in Arora\u0026rsquo;s book. The trivial result is that \\[\\mathbf{P}\\subseteq\\mathbf{NP}\\subseteq\\mathbf{EXP}\\subseteq\\mathbf{NEXP}.\\]\nUniversal Nondeterministic Turing Machine It turns out it is rather easy to design a universal Turing Machine when the \u0026ldquo;guessing\u0026rdquo; ability is at hand. Intuitively, this seems like the result of the loosely definition of a Nondeterministic TM accepting a string. By extending the running time of some NDTM linearly, the number of possible brunches increases exponentially. And perhaps that is why such a universal machine is so easy to design.\nBut first the notion of snapshot is introduced. A snapshot consists of the preimage of the transition function \\(\\delta\\). Recall that transition function has the form \\[\\delta:\\Gamma^k\\times Q \\mapsto \\Gamma^{k-1}\\times Q \\times\\{{L,S,R}\\}^{k}\\] And therefore, a snapshot for a \\(k\\) tape Turing Machine at step \\(i\\) is \\(\\langle{a_1,\\ldots,a_k,q}\\rangle\\in\\Gamma^{k}\\times Q\\), where \\(a_1,\\ldots,a_k\\) correspond to the \\(k\\) symbols under the read/write heads at step \\(i\\), and \\(q\\) is the state in the state register at that step.\nNote that compared to the configuration of a Turing Machine, a snapshot is much more compact. More importantly, a snapshot alone is able to determine the one-step computation process. This observation (computation on a Turing Machine is local) is important to the proof of Cook-Levin theorem.\nIn the lecture Prof. Fu presented a universal NDTM that takes three working tapes:\nTo guess a snapshot sequence;\nTo guess a choice sequence;\nTo verify the content of \\(k-1\\) working tapes is consistent with the computation process.\nBy the definition of NDTM, if some string \\(x\\) is accepted by a NDTM, it means that there is a choice sequence (and therefore a snapshot sequence) that leads the computation to a accepting state. Now, by the above definition, such a sequence surely occurs in the universal TM\u0026rsquo;s choice tree, which means that \\(x\\) is also accepted by this universal NDTM.\nAssuming that the Turing Machine to be simulated runs in time \\(T(n)\\)1 The simulation takes time at most \\(c\\cdot T(n)\\), where \\(c\\) is a constant only dependent on the machine being simulated (ergo a constant). A naive idea would be to represent the \\(k\\) tapes on the third tape of the universal machine, and verification of each working tape takes no more than \\(k\\cdot T(n)\\) steps.\nDeterministic Time Hierarchy Theorem The time hierarchy theorem states that by allowing more time to a (Deterministic) Turing Machine, the language it is capable of deciding strictly grows. This and the nondeterministic version of this theorem are both proved using the diagonalization technique, which is introduced in the third chapter of Arora\u0026rsquo;s book.\nIf \\(f\\) and \\(g\\) are time-constructible functions, and \\(f(n)\\log(f(n))=o(g(n))\\), then \\(\\mathbf{DTIME}(f(n))\\subsetneq\\mathbf{DTIME}(g(n))\\).\nDefine the Turing Machine \\(\\mathbb{M}\\) that runs in time \\(c\\cdot g(n)\\): On input \\(x\\), \\(\\mathbb{M}\\) computes \\(\\mathbb{U}(x,x)\\) clocked with \\(g(|x|)\\). If the simulation halts before the timer ends, \\(\\mathbb{M}\\) outputs the negated result; Else, it outputs \\(1\\).\nLet \\(L\\) be the language accepted by \\(\\mathbb{M}\\), then by definition \\(L\\in\\mathbf{DTIME}(g(n))\\). Suppose by contradiction, \\(\\mathbf{DTIME}(f(n))=\\mathbf{DTIME}(g(n))\\), we have \\(L\\in\\mathbf{DTIME}(f(n))\\). Let \\(\\mathbb{M}^\\prime\\) be the machine that computes \\(L\\) in \\(O(f(n))\\) time. Then since the simulation of \\(\\mathbb{M}\\prime\\) takes at most \\(c^\\prime\\cdot f(n)\\log(f(n))\\), we have that we can find a representation \\(\\llcorner{\\mathbb{M}^\\prime}\\lrcorner\\) large enough to be simulated by universal TM \\(\\mathbb{U}\\). Now consider \\(\\mathbb{M}(\\llcorner{\\mathbb{M}^\\prime}\\lrcorner,\\llcorner{\\mathbb{M}^\\prime}\\lrcorner)\\). By the definition of universal TM, this value is \\(\\mkern 1.5mu\\overline{\\mkern-1.5mu\\mathbb{M}^\\prime(\\llcorner{\\mathbb{M}^\\prime}\\lrcorner)\\mkern-1.5mu}\\mkern 1.5mu\\). However, since \\(\\mathbb{M}^\\prime\\) and \\(\\mathbb{M}\\) decide the same language, this value should also be \\(\\mathbb{M}^\\prime(\\llcorner{\\mathbb{M}^\\prime}\\lrcorner)\\), leading to a contradiction.\nLecture 4: Time Complexity In the previous lecture we have learned the deterministic Time Hierarchy theorem. By a simple observation that \\[n^c\\cdot2^{n^c}\\approx2^{n^c}\u0026lt;2^{2^{n^c}}\\] We can define a exponential hierarchy. That is, following the definition of \\(\\mathbf{EXP}\\), we can define \\[\\mathbf{2EXP}:=\\mathop{\\bigcup}_{c\\ge 1}2^{2^{n^c}}.\\]\nSimilarly, \\(\\mathbf{3EXP},\\mathbf{4EXP},\\ldots\\) can be defined. Finally, we define \\[\\mathbf{ELEMENTARY}:=\\mathbf{EXP}\\cup\\mathbf{2EXP}\\cup\\ldots.\\]\nAlthough the exact functionality of such definition is unclear for the time being, I am sure when the course proceeds, those will come natural to me.\nNondeterministic Time Hierarchy Theorem Before stating this theorem a brief history of this theorem is introduced. First of all, Cook proved in 1970 that \\(\\mathbf{NTIME}(r(n))\\subsetneq\\mathbf{NTIME}(r^\\prime(n))\\) if \\(1\\leq r(n) \u0026lt; r^\\prime(n)\\). I wrote in my notebook that this is a slightly weaker result compared to the one stated in the textbook1.\nThe theorem stated in the textbook and this lecture is as follows.\nIf \\(f\\) and \\(g\\) are time-constructible functions and \\(f(n+1)=o(g(n))\\), then \\(\\mathbf{NTIME}(f(n))\\subsetneq\\mathbf{NTIME}(g(n))\\).\nThe proof uses a technique called \u0026ldquo;lazy diagonalization\u0026rdquo;, which is necessary for the proof with nondeterministic Turing Machine. As discussed earlier, negating the output of a nondeterministic machine is not so easy, since all the brunches need to be computed. And therefore to negate only one output in an exponential number of machines makes the negation efficient (this actually means focusing the attention on problems of smaller scale). The proof is proposed by Zak.\nLike previous proofs using diagonalization, we need to define a Turing Machine and its deciding language such that it lies in the set \\(\\mathbf{NTIME}(g(n))\\setminus\\mathbf{NTIME}(f(n))\\)2. The machine we define has five working tapes3, and its accepting strings have the form \\(1^n\\). The function of its working tapes is as follows (we denote the machine as \\(\\mathbb{V}\\)):\nThe heads of the first working tape and the input tape moves right at full speed until the machine halts. The first tape writes \\(1\\) at the first cell and then writes string of the form \\(0^n1\\). Let \\(h_0,h_1,\\ldots\\) be the index of the \\(1\\)\u0026rsquo;s on the first working tape.\nThe second working tape enumerates NDTM \\(\\mathbb{L}_1,\\mathbb{L}_2,\\ldots\\) hardwired with a \\(g(n)\\) -timer. Upon generating \\(\\mathbb{L}_i\\), the machine computes universal NDTM on input \\((\\llcorner{\\mathbb{L}_i}\\lrcorner, 1^{h_{i-1}+1})\\). Notice that in this step, our machine is required to explore every brunch of the universal TM\u0026rsquo;s choice, And this step takes exponential (in the length of \\(h_{i-1}+1\\)) time. Upon acquiring the result, \\(\\mathbb{V}\\) writes \\(1\\) on location \\(h_i\\) of the first working tape (this gives the definition of \\(h_i\\)), and the result on the second working tape (right after the description of \\(\\mathbb{L}_{i}\\)).\nSuppose the input is of form \\(1^n\\) with \\(n\u0026gt;1\\). After the input is scanned, \\(\\mathbb{V}\\) distinguishes between the two cases:\nIf \\(n=h_i\\), accepts \\(1^n\\) if \\(\\mathbb{L}_{i}(1^{h_{i-1}+1})=0\\); refuses it otherwise.\nIf \\(h_i\u0026lt;n\u0026lt;h_{i+1}\\), \\(\\mathbb{V}\\) simulates \\(\\mathbb{L}_{i}(1^{n+1})\\) for \\(g(n)\\) steps and outputs the simulation result.\nLet \\(L\\) be the language decided by \\(\\mathbb{V}\\), and by its definition, \\(L\\in\\mathbf{NTIME}(g(n))\\). Suppose by contradiction, we have \\(L\\in\\mathbf{NTIME}(f(n))\\), then we consider the machine \\(\\mathbb{M}\\) that decides \\(L\\) and runs in time \\(c \\cdot f(n)\\). By simple padding, we can find a encoding of \\(\\mathbb{M}\\) that is of length \\(n^\\prime\\) long enough that \\(c\\cdot f(n^\\prime+1) \u0026lt; g(n^\\prime)\\). By the definition of \\(\\mathbb{V}\\), the positive integer set is partitioned into intervals of forms \\((h_{i-1},h_i]\\). Suppose \\(n\\in(h_{i-1},h_i]\\). Then we have \\[\\begin{aligned} \\mathbb{V}(1^{h_{i-1} + 1}) \u0026amp;= \\mathbb{L}_{i-1}(1^{{h_{i-1} + 2}})\\\\ \\mathbb{L}_{i-1}(1^{{h_{i-1} + 2}}) \u0026amp;= \\mathbb{V}(1^{{h_{i-1} + 2}}) \\\\ \u0026amp;\\hspace{.5em}\\vdots \\\\ \\mathbb{V}(1^{h_{i}-1}) \u0026amp;= \\mathbb{L}_{i-1}(1^{h_{i}})\\\\ \\mathbb{L}_{i-1}(1^{h_{i}}) \u0026amp;= \\mathbb{V}(1^{h_i})\\\\ \\mathbb{V}(1^{h_i}) \u0026amp;\\ne \\mathbb{V}(1^{h_{i-1} + 1}) \\end{aligned}\\] This concludes the proof, since by the assumption we have \\(\\mathbb{V}(1^{h_{i-1} + 1})\\ne \\mathbb{V}(1^{h_{i-1} + 1})\\).\nI think there are some interesting thought experiment about the above proof. What if we set the requirement of \\(g\\) even higher, say \\(f(n+c)=o(g(n))\\) for arbitrary constant \\(c\\)? Would this make the proof harder? Maybe the core question is that what is the connection between the difference in time function, and the language that lies in the interval.\nGap Theorem When we consider the opposite of time-constructible functions, some interesting result can occur. Gap theorem is one of such astonishing examples.\nSuppose \\(r(x)\u0026gt;x\\) is a total computable function. Then there exists some total computable function \\(b(x)\\) such that \\(\\mathbf{DTIME}(b(x))=\\mathbf{DTIME}(r(b(x)))\\).\nThe proof uses a smart pigeon-hole argument.\nDefine a sequence of numbers \\(k_0\u0026lt;k_1\u0026lt;k_2\u0026lt;\\ldots\u0026lt;k_x\\) by \\[\\begin{aligned} k_0 \u0026amp;= 0\\\\ k_{n+1} \u0026amp;= r(k_{n})+1. \\end{aligned}\\] Then the set \\([0,r(k_x)]\\) is partitioned in to \\(x+1\\) disjoint intervals.\nNow define a property \\(P(i,k)\\). This property is satisfied when for every \\(j\\leq i\\) and input \\(z\\) of length \\(i\\), we have \\(\\mathbb{M}_{j}(z)\\) either halts within \\(k\\) steps or does not halt in \\(r(k)\\) steps.\nConsider the number \\(n_i=\\sum_{j\\leq i}|\\Gamma_j|^i\\), which is the number of all inputs of size \\(i\\) to machine \\(\\mathbb{M}_0,\\ldots,\\mathbb{M}_i\\). And consider the aforementioned partition of set \\([0. r(k_{n_i})]\\). Every input corresponds to a running time, and by pigeon-hole argument, these \\(n_i\\) numbers cannot fill all \\(n_i +1\\) intervals. Meaning there is a minimal \\(j\\) such that \\(P(i,k_j)\\) is true. Let \\(b(i)\\) be such \\(k_j\\).\nNow that we defined the function \\(b(n)\\), lets consider \\(\\mathbf{DTIME}(r(b(n)))\\). Since by the definition of \\(b(n)\\), property \\(P(i,b(i))\\) is true for all \\(i\\), for every language in \\(\\mathbf{DTIME}(r(b(n)))\\), we can find \\(x\\) long enough that the Turing Machine that decide it has number \\(i\u0026lt;|x|\\). By the definition of \\(b(n)\\), this machine halts in \\(b(|x|)\\) steps. Meaning that \\(L\\in\\mathbf{DTIME}(b(n))\\).\nIt is also noted in the slides that by time hierarchy theorem, \\(b(n)\\) is not time-constructible. Actually I think assuming \\(b(n)\\) is time-constructible, this implies \\(b(n)\\cdot\\log(b(n))=\\Omega(r(b(n)))\\), I do not understand the further contradiction.\nLecture 5: NP Completeness Before the introduction of NP completeness (the Cook-Levin theorem), an alternative definition of \\(\\mathbf{NP}\\) is introduced. This definition capture the intuition that \\(\\mathbf{NP}\\) language are those that are easy to verify, i.e. having short proofs that can be verified efficiently. The following theorem states the equivalence between the two definitions.\n\\(L\\in\\mathbf{NP}\\) if and only if there is a polynomial \\(p\\) and a P-time verifier \\(\\mathbb{M}\\) such that \\(\\forall x \\in \\{0,1\\}^{*}\\), \\(x\\in L \\iff \\exists u\\in\\{0,1\\}^{p(|x|)} \\land \\mathbb{M}(x,u)=1\\).\nIf \\(x\\in L\\) and \\(u\\in\\{0,1\\}^{p(|x|)}\\) is such that \\(\\mathbb{M}(x,u)=1\\), then \\(u\\) is called a certificate or witness for \\(x\\), with respect to \\(\\mathbb{M}\\) and \\(L\\).\nThe theorem is actually trivial to prove. Assuming such certificate for some language \\(L\\) exists, then a NDTM can simply guess the certificate first (takes \\(p(|x|)\\) steps) and then simulate \\(\\mathbb{M}\\) (the verifier) to determine the result. In the other direction, the certificate for a string \\(x\\) can simply be the sequence of choices made by the NDTM. The verifier just apply the transition function according to the certificate, and accepts \\(x\\) iff. the accepting state is reached.\nThis certificate-based definition actually reveals the fact that \\(\\mathbf{NP}\\) problems are easy to verify (in polynomial-time), while \\(\\mathbf{P}\\) problems are easy to solve (in polynomial-time). Some examples of \\(\\mathbf{NP}\\) problems include:\nIndependent Set, Traveling Salesman, Subset Sum, 0/1 Programming, Hamiltonian Path (\\(\\mathbf{NP}\\) -complete)\nGraph Isomorphism, Factoring (unknown)\nLinear Programming, Primality (actually in \\(\\mathbf{P}\\))\nKarp Reduction Reduction allows us to compare the difficulty between two problems, even though both of the problem may lack concrete solutions. Karp Reduction is perhaps the simplest one (without additional properties). Suppose \\(L,L^\\prime\\) are two languages, we say \\(L\\) is Karp reducible to \\(L^\\prime\\) if there exists some polynomial time computable function \\(r\\) such that \\(x\\in L\\iff r(x)\\in L^\\prime\\).\nNote that the reduction function \\(r\\) actually maps \\(L\\) onto \\(L^\\prime\\) (i.e. a surjection), and that means computing \\(L^\\prime\\) is at least as hard as computing \\(L\\). We introduce two notions:\nWe say \\(L\\) is \\(\\mathbf{NP}\\) -hard if \\(\\forall L^\\prime \\in \\mathbf{NP}\\), \\(L^\\prime \\le_{K}L\\).\nWe say \\(L\\) is \\(\\mathbf{NP}\\) -complete if \\(L\\in\\mathbf{NP}\\) and \\(L\\) is \\(\\mathbf{NP}\\)-hard.\nFor this lecture and the next one, we answer the question \u0026ldquo;is there an example of \\(\\mathbf{NP}\\) -complete\u0026rdquo; problem? First of all, a natural idea may arise from the certificate-based definition of \\(\\mathbf{NP}\\) and universal Turing Machine. Consider the following language:\n\\[\\mathtt{TMSAT} := \\{{\\langle{\\alpha,x,1^n,1^t}\\rangle|\\exists u\\in\\{0,1\\}^{n}\\text{ s.t. } \\mathbb{M}_{\\alpha}(x,u) \\text{ outputs 1 in t stpes}}\\} \\]\nClearly any language in \\(\\mathbf{NP}\\) can be Karp reduced to \\(\\texttt{TMSAT}\\).\nComplementary of NP A language \\(L\\subseteq \\{0,1\\}^{*}\\) is in \\(\\mathbf{coNP}:=\\{{L|\\mkern 1.5mu\\overline{\\mkern-1.5muL\\mkern-1.5mu}\\mkern 1.5mu\\in\\mathbf{NP}}\\}\\), iff. there exists a polynomial \\(p\\) and a Turing Machine \\(\\mathbb{M}\\) such that \\(x\\in\\L\\iff \\forall u\\in\\{0,1\\}^{p(|x|)}\\), \\(\\mathbb{M}(x,u)=1\\).\nPadding Technique There is a theorem related to the polynomial hierarchy1.\nIf \\(\\mathbf{P}=\\mathbf{NP}\\), then \\(\\mathbf{EXP}=\\mathbf{NEXP}\\).\nWe only have to prove \\(\\mathbf{NEXP}\\subseteq\\mathbf{EXP}\\), since inclusion in the other direction is trivial. Suppose \\(L\\in\\mathbf{NEXP}\\), then \\(\\exists c\\geq 1\\) and Turing Machine \\(\\mathbb{M}\\) such that \\(x\\in L\\iff\\exists u\\in\\{0,1\\}^{2^{{|x|}^c}}\\), \\(\\mathbb{M}(x,u)=1\\).\nNow define the following language \\(L^\\prime:=\\{{x1^{2^{{|x|}^c}}|x\\in L}\\}\\). By definition, \\(L^\\prime\\in\\mathbf{NP}\\) (the input is long enough now). By assumption, \\(L^\\prime\\in P\\). \\(\\forall x\\in\\{0,1\\}^{*}\\), by padding \\(1^{2^{{|x|}^c}}\\) to the back of \\(x\\), and calls the polynomial time algorithm on the padded result, \\(x\\) can be computed in \\(1^{2^{{|x|}^{c^\\prime}}}\\) time for some constant \\(c^\\prime\\). This implies \\(\\mathbf{EXP}=\\mathbf{NEXP}\\).\nCook-Levin Theorem Cook-Levin theorem gives for the first time, a natural problem (\\(\\mathtt{3SAT}\\)) that is \\(\\mathbf{NP}\\) -complete. This embarks on many other \\(\\mathbf{NP}\\) -complete problems since these problems can be reduced to \\(\\text{\\texttt{3SAT}}\\). Before the proof of Cook-Levin Theorem, the preliminary knowledge of conjunctive normal form is introduced.\nConjunctive Normal Form A CNF formula has the form \\(\\land_{i}(\\lor_j{v_{ij}})\\), where \\(v_{ij}\\) is a literal (a variable or its negation) and \\({v_{ij}}\\) is a clause.\nA \\(k\\) -CNF is a CNF where all the clauses have at most \\(k\\) literals. A CNF is satisfiable if there exists an assignment of variables such that the value of the \\(CNF\\) is true.\n\\(\\mathtt{2CNF}\\in\\mathbf{P}\\)\nConsider a graph of \\(2m\\) nodes, where \\(m\\) is the number of variables in the CNF. Each pair of node represents the 0/1 assignment of a variable. A clause \\(x\\lor y\\) is interpreted as two edges: \\(\\bar{x}\\to y\\) and \\(\\bar{y}\\to x\\) (If \\(x=0\\) then \\(y=1\\) and vise versa). This CNF is not satisfiable if and only if there is a path on the graph from some \\(z\\) to \\(\\bar{z}\\).\n\\(\\text{\\texttt{SAT}}\\le_{K}\\text{\\texttt{3SAT}}\\)\nThis can be proved by padding dummy literal into the clause. E.g. Consider \\(v_1\\lor v_2\\lor \\ldots\\lor v_n\\), we can introduce \\(n-3\\) dummy variables \\(y_1,\\ldots,y_{n-3}\\), and the resulting clause is \\[(v_1\\lor v_2\\lor y_1)\\land(\\mkern 1.5mu\\overline{\\mkern-1.5muy_1\\mkern-1.5mu}\\mkern 1.5mu\\lor v_3\\lor y_2)\\land\\ldots\\land(\\mkern 1.5mu\\overline{\\mkern-1.5muy_{k-3}\\mkern-1.5mu}\\mkern 1.5mu\\lor v_{n-1}\\lor v_{n})\\] Notice that the previous CNF is satisfiable if and only if the latter one is. And therefore we have that the satisfiable property is inherited.\nLecture 6: Cook-Levin Theorem Some preliminary knowledge before the lecture is introduced. They are:\nThe Boolean formula \\(x=y\\) can be expressed in CNF form \\((\\bar{x}\\lor y)\\land(x\\lor \\bar{y})\\).\nAny Boolean function \\(f:\\{0,1\\}^{l}\\to\\{0,1\\}\\) can be represented by an equivalent \\(l\\) -variable CNF, whose size is at most \\(l\\cdot 2^{l}\\).\nThe second point is similar to the maximum solution concept in digital circuit. The conversion is quite simple. Consider the truth table of \\(f\\), of which some entry corresponds to \\(f=0\\). For each such entry, we convert it into a clause as follows: if some variable \\(x\\) in that entry is \\(0\\), then add \\(x\\) to the clause; else, add \\(\\bar{x}\\). In this way, we ensure this restriction is encoded. By taking the logical and of all the terms, the whole function can be encoded.\nThe rest of this lecture is dedicated to the proof of Cook-Levin theorem, i.e. \\(\\text{\\texttt{3SAT}}\\) is \\(\\mathbf{NP}\\) -complete. Formally, we need to prove two results:\n\\(\\text{\\texttt{3SAT}}\\in\\mathbf{NP}\\) (trivial)\n\\(\\forall L\\in\\mathbf{NP}, L\\le_{K}\\text{\\texttt{3SAT}}\\)\nThe first result is trivial to prove, using the certificate based definition of \\(\\mathbf{NP}\\). For the second result, remember that we proved \\(\\text{\\texttt{SAT}}\\le_{K}\\text{\\texttt{3SAT}}\\), this means that we only need to prove \\(L\\le_{K}\\text{\\texttt{SAT}}\\) because this with the transitivity of reduction implies the second result.\nSince we need to prove a result that is true to all the \\(\\mathbf{NP}\\) languages, there is no resource we can rely on other than its definition. In this proof we actually utilize the certificate-based definition and represent the computation process as a CNF formula. The formula is satisfiable iff. some certificate exists of polynomial length and makes the verifier outputs 1.\nA naive idea would be to consider the computation of the verifier (by which we denote \\(\\mathbb{M}\\)) as a \\(|x|+p(|x|)\\) -length Boolean function. But that would incur complexity trouble, since the resulting formula would have exponential size. The key idea behind this proof is that for each step of \\(\\mathbb{M}\\), the transition function only relies on the \\(k\\) symbols under the heads and the state information, which altogether can be encoded to a constant length. And the steps of transition is a polynomial, therefore the resulting CNF would be of polynomial length, and is satisfiable iff. there is a certificate that leads \\(\\mathbb{M}\\) outputs 1.\nI think the idea behind this proof is that a TM can not compute functions with too many high-degree variables. While a \\(l\\cdot 2^l\\) variable formula can achieve this, such exaggeration is not necessary, since computation on a TM is highly local.\nNow we present the proof sketch of Cook-Levin theorem.\nLet \\(L\\in\\mathbf{NP}\\) has verifier \\(\\mathbb{M}\\), with running time \\(T(n)\\), certificate length \\(p(n)\\) and its alphabet can be encoded into \\(c_1\\) bits. Without loss of generality, we can assume a snapshot of \\(\\mathbb{M}\\) can be encoded into \\(c_2\\) bits. Consider \\(x\\in L\\) and its verification process on \\(\\mathbb{M}\\). The computation can be represented by a sequence of snapshots \\(z_1,\\ldots,z_{T(|x|+p(|x|))}\\), where without loss of generality we let \\(z_1=\\langle{q_{start},\\triangleleft,\\Box,\\ldots,\\Box}\\rangle\\) and \\(z_{T(|x|+p(|x|))}=\\langle{q_{halt},\\triangleleft,1,\\Box,\\ldots,\\Box}\\rangle\\) to be constant. We also make the assumption that \\(\\mathbb{M}\\) is oblivious.\nSince \\(\\mathbb{M}\\) is deterministic, we only need to verify\nthe input is well-formed (of the form \\(xu|u\\in\\{0,1\\}^{p(|x|)}\\))\nthe snapshots are well formed (the first one and the last one are the constants as required and the rest according to the transition function).\nThe only tricky part is how to verify every snapshot satisfies the transition function. The observation here is that each snapshot is only dependent on\nits previous snapshot (contains the state)\nthe symbol on each tapes at that step.\nNote that by assumption, \\(\\mathbb{M}\\) is oblivious, meaning at the beginning of the reduction, we can first append \\(x\\) with \\(1^{p(|x|)}\\) to find out the head movement of \\(\\mathbb{M}\\), and then use this information to proceed with the reduction. Altogether, \\(z_i\\) only depends on \\(z_{i-1}\\), \\(y_{\\text{inputpos}(i)}\\), and \\(z_{\\text{prev}(i)}\\). And its total number of variables is a constant. Altogether, the reduction takes polynomial time and the resulting CNF has polynomial size. This concludes the proof of Cook-Levin theorem.\nSome properties of Cook-Levin theorem are that:\nthe reduction can be done in logspace;\nthe reduction is actually a Levin reduction (there exists a bijection between the certificates of the two languages);\nthe reduction is parsimonious (#(certificates for \\(x\\)) = #(certificates for \\(r(x)\\) in \\(\\text{\\texttt{SAT}}\\))).\nDecision versus Search The next theorem proves that if the decision version of some \\(\\mathbf{NP}\\) -complete language is solved, its witness can also be found in polynomial time.\nIf \\(\\mathbf{P}=\\mathbf{NP}\\), then there exists a P-time TM \\(\\mathbb{M}\\) that \\(\\forall L\\in\\mathbf{NP}\\) on input \\(x\\in L\\), it outputs a certificate \\(u\\in\\{0,1\\}^{p(|x|)}\\) for \\(x\\).\nThe proof is very easy, using the fact that the reduction to \\(\\text{\\texttt{SAT}}\\) is actually a Levin-reduction.\n\\(\\mathbf{coNP}\\) Completeness The complementary problem \\(\\texttt{TAUTOLOGY}\\) of \\(\\text{\\texttt{SAT}}\\) is actually a \\(\\mathbf{coNP}\\) complete problem. The following theorem states this fact.\n\\(\\texttt{TAUTOLOGY} := \\{{\\varphi| \\varphi(x)=1, \\forall x\\in\\{0,1\\}^{n}}\\}\\) is \\(\\mathbf{coNP}\\) complete.\nFirst we prove that \\(\\texttt{TAUTOLOGY}\\in\\mathbf{coNP}\\), which is trivial since its complementary problem is just \\(\\text{\\texttt{SAT}}\\). In other words, whether \\(x\\not\\in\\texttt{TAUTOLOGY}\\) can be determined by an NDTM in polynomial time.\nSecondly, consider any language \\(L\\in\\mathbf{coNP}\\). Since \\(\\mkern 1.5mu\\overline{\\mkern-1.5muL\\mkern-1.5mu}\\mkern 1.5mu\\in\\mathbf{NP}\\), we have that \\(\\mkern 1.5mu\\overline{\\mkern-1.5muL\\mkern-1.5mu}\\mkern 1.5mu\\le_{K}\\text{\\texttt{SAT}}\\), and \\(\\texttt{TAUTOLOGY}=\\mkern 1.5mu\\overline{\\mkern-1.5mu\\text{\\texttt{SAT}}\\mkern-1.5mu}\\mkern 1.5mu\\). By the definition of Karp reduction, the process is a reduction from \\(L\\) to \\(\\texttt{TAUTOLOGY}\\).\nLecture 7: Implications of Cook-Levin Theorem Efficiently Verifiable Theorems is NPC In this lecture the implications of Cook Levin theorem is discussed. In particular, consider the following language with respect to a familiar axiomatic system \\(A\\). \\[\\lang{THEOREM} = \\set{(\\phi,1^{|\\phi|^c})|\\phi\\text{ has a formal proof of length} \\le |\\phi|^c \\text{ in } A}\\]\nThis is the finite version of Hilbert\u0026rsquo;s Theorem and essentially Godel\u0026rsquo;s question. But it is easy to see that this language is \\NP-complete. The proof relies on\nIn most familiar axiomatic system, verification time is polynomial in proof length \\(\\SAT \\le_{K} \\lang{THEOREM}\\) since satisfying CNF has the assignment of variables as proof. So Godel essentially palpicitated (or raised actually ) the famous question of ¶ vs. \\NP.\nBerman-Hartmanis Conjecture The conjecture is \u0026ldquo;all NP-complete problems are polynomially isomorphic\u0026rdquo;. By \u0026ldquo;polynomially isomorphic\u0026rdquo;, we mean there is a efficient isomorphism \\(\\sigma\\) (and \\(\\sigma^{-1}\\)) between the two languages. (Efficiency means polynomial in the length of input).\nThe evidence to this conjecture is the following facts:\n\\(A \\le_{K}^{1} B\\) for all NPC languages \\(A\\) and \\(B\\) If \\(A \\le_{K}^{1} B\\) and \\(B\\le_{K}^{1} A\\), then \\(A\\cong_p B\\). By \\(\\le_{K}^{1}\\) we mean the karp reduction is injective. Another important implication is that Berman-Hartmanis Conjecture would implies \\(\\P\\ne\\NP\\), since for sake of contradiction, consider if \\(\\P = \\NP\\) then any language in \\(\\NP\\) is trivially NPC. Now consider the \u0026ldquo;density\u0026rdquo; of languages. We consider a language \\(\\lang{L}\\) sparse if \\[\\# L^{\\le n} = \\#\\set{x\\in\\set{0,1}^{\\le n} : x\\in \\lang{L}} = n^{O(1)}\\] and respectively, dense if \\[\\# L^{\\le n} = 2^{n^{O(1)}}.\\]\nClearly \\(\\SAT{}\\) is dense. By the assumption, a trivial language like \\(\\set{1^n : n\\in \\NN}\\) is also NPC. But a dense language cannot be isomorphic to a sparse languge, since the reduction function \\(\\sigma\\) maps a dense language \\(L^{n}\\) to \\(n^{O(1)}\\) length instance in a sparse language \\(L^\\prime\\). But the possible output number is polynomial in \\(n\\), while the number of preimage instances is super-polynomial. Clearly such a \\(\\sigma\\) does not exist.\nLadner\u0026rsquo;s Theorem Lecture 8: Limitations of Relativization I think Ladner\u0026rsquo;s theorem must have been proved in last lecture, but I cannot find it anywhere on my notebook. Anyway, this lecture discusses the famous Baker-Gill-Solovay Theorem which states that the famous \\(\\P\\) vs. \\(\\NP\\) problem is not possible to prove under relativation.\nOracle Turing Machine Oracle Turing Machine adds the query power to Turing machine. In particular, consider an oracle language \\(\\lang{O}\\) (any language suffices), a Turing machine is given an additional query tape and three more states \\(q_{\\text{query}}\\), \\(q_{\\text{yes}}\\), and \\(q_{\\text{no}}\\). When machine enters query state, the next state will be yes if the content \\(x\\) on the query tape belongs to language O, and state no otherwise.\nWe proceed to define complexity classes with respect to oracle machine. Define \\(\\P^{O}\\) and \\(\\NP^{O}\\) to be the set of languages that can be accepted by (respectively nondeterministic) polynomial time oracle machine. More generally, we can define \\(\\NP^{O[k]}\\) to be the set restricting at most \\(k\\) time access to the oracle query.\nWe can define \\(\\NP^{\\NP} := \\mathop{\\cup}_{\\lang{L}\\in\\NP} \\NP^{L}\\).\nSome facts on such classes:\n\\(\\overline{\\SAT{}} \\in \\P^{\\SAT{}}\\) \\(\\P^L = \\P\\) for all \\(L\\in\\P\\) \\(\\NP^{\\NP} = \\NP^{3\\SAT}\\) Cook Reduction A language \\(L\\) is cook-reducible to \\(L^\\prime\\) if there exists a polynomial time oracle turing machine \\(\\TM^{L^\\prime}\\) that decides \\(L\\). A fact is that \\[L \\le L^\\prime \\iff L \\le \\overline{L^\\prime},\\] since the query result specifically states yes or no.\nThe status quo of different flavors of reduction is that, in NP-problem related proofs, Karp reduction and Cook reduction are interchanageable, but there does not exist an equavalence proof between these two reductions.\nLowness A language \\(B\\) is low for \\(A\\) if \\(A = A^{B}\\). If a language is low for itself then we call this language \u0026ldquo;closed under complement\u0026rdquo;, provided it is powerful enough to negate boolean results.\nSome examples:\n\\(\\P\\) is low for itself \\(\\NP\\) is believed not to be low for itself \\(\\PSPACE\\) is low for itself \\(\\L\\) is low for itself \\(\\EXP\\) is not low for itself. This because exponential time turing machine can query exponentially long string, and therefore it should be in \\(2\\EXP\\). Note that \\(\\EXP = {\\coEXP}\\) Baker-Gill-Solovay Theorem The theorem can be stated as \u0026ldquo;there exists language \\(\\lang{A}\\), \\(\\lang{B}\\) such that \\(\\P^{\\lang{A}} = \\NP^{\\lang{A}}\\) and \\(\\P^{\\lang{B}} \\ne \\NP^{\\lang{B}}\\).\nProof of Baker-Gill-Solovay theorem.\nConstruction of language \\(A\\) is easy, just pick a language that is powerful enough like \\[A:=\\set{\\langle\\alpha, x, 1^n\\rangle | \\TM_\\alpha(x) \\text{ outputs 1 in } 2^n \\text{ steps.}}\\]. It is easy to see that \\(\\EXP \\subset \\P^A\\) and also since an exponential time deterministic Turing machine can simulate every non-determinstic step of a polynomial-time non-deterministic Turing machine, we have \\(\\NP^A \\subseteq \\EXP\\). Also so we have \\[\\EXP \\subseteq \\P^A \\subseteq \\NP^A \\subseteq \\EXP,\\] which means \\(\\P^A = \\NP^A\\).\nConstruction of language \\(B\\) uses diagonalization technique. We define the language \\(B\\) recursively. Consider a sequence of strictly increasing integers (resp. set) \\(n_i\\) and \\(B_i\\). Define \\(n_0 = 0\\) and \\(B_0 = \\phi\\), and recursively:\n\\(n_{i+1}\\) is larger than \\(n_i\\) and also larger than all the strings that have been queried during construction of \\(B_1\\), \\(\\ldots\\), \\(B_i\\) Run \\(\\TM_i^{B_i}(1^{n_{i+1}})\\) in \\(2^{n_{i+1}-1}\\) steps. If It does not halt within \\(2^{n_{i+1}-1}\\) steps, let \\(B_{i+1} = B_i\\); It accepts, let \\(B_{i+1} = B_i\\) It rejects, let \\(B_{i+1} = B_{i} \\cup \\set{s}\\) where \\(|s| = n_{i+1}\\) and \\(s\\) is not queried when execuring \\(\\TM_i^{B_i}(1^{n_{i+1}})\\) (this ensures correctness of definition). Define \\(B = \\mathop{\\cup}_{i\\in\\NN} B_i\\) and the unitary language \\(U_B := \\set{1^n | s:|s| = n\\land s\\in B}\\), we then claim that \\(U_B \\in \\NP^B\\) and \\(U_B \\not\\in \\P^B\\).\nFirst a NDTM can simply guess a string \\(s\\) of input length and query the oracle of its membership in \\(B\\), outputing whatever the oracle returns.\nFor a deterministic TM, suppose by contradiction \\(\\TM_i^{B}\\) computes \\(U_B\\) in polynomial time. Then choose \\(n_{i+1}\\) large enough that \\(\\TM_i^{B}\\) terminates within \\(2^{n_{i+1}-1}\\) steps. First of all, by the construction of \\(B\\setminus B_i\\), the only strings inside this set are longer than any query of \\(\\TM_i^{O}(1^{n_{i+1}})\\), and are therefore not queried by this machine, so we have \\(\\TM_i^{B}(1^{n_{i+1}}) = \\TM_i^{B_i}(1^{n_{i+1}})\\). So if\n\\(\\TM_i^{B}(1^{n_{i+1}}) = 1\\) \\(\\implies\\) \\(\\exists s\\in B: |s| = n_{i+1}\\) \\(\\implies\\) \\(\\TM_i^{B_i}(1^{n_{i+1}}) = 0\\) \\(\\implies\\) \\(\\TM_i^{B}(1^{n_{i+1}}) = 0\\) \\(\\TM_i^{B}(1^{n_{i+1}}) = 0\\) \\(\\implies\\) \\(\\not\\exists s\\in B: |s| = n_{i+1}\\) \\(\\implies\\) \\(\\TM_i^{B_i}(1^{n_{i+1}}) = 1\\) \\(\\lor\\) \\(\\TM_i^{B_i}(1^{n_{i+1}})\\) does not halt within \\(2^{n_{i+1}-1}\\) steps. So we have \\(U_B \\not\\in \\P^B\\), which concludes the proof.\nRelativization A proof of \\(A = B\\) or \\(A\\ne B\\) relativizes if it is also a proof for \\(A^O = B^O\\) or \\(A^O\\ne B^O\\). Proofs that only uses diagonlization fall into this category. Baker-Gill-Solovay theorem states that \\(\\P\\) vs. \\(\\NP\\) is not likely to have such a simple proof.\nSpace Complexity This lecture concludes the introduction of time-complexity. The next topic is space complexity. First space bounded computation is introduced. As usual, we need to define complexity classes with respect to space constraint.\nLet \\(S:\\NN \\to \\NN\\) and \\(L\\subseteq \\set{0,1}^*\\). We say \\(L\\in \\mathsf{SPACE}(S(n))\\) if \\(\\exists \\TM, \\forall x\\in\\set{0,1}^*\\) \\(M(x) = x\\in L\\) and never uses more than \\(S(|x|)\\) blank cells on its working tapes. Similarly we can define \\(\\mathsf{NSPACE}\\) with respect to NDTMs.\nConfiguration Here we introduce the notion of configuration that consists:\nState Working tape content Head position It is clear that with these information, we can deduce the next state from the transfer function. We here assume wlog there is a single initial configurate and only one accept configuration.\nConfiguration Graph We can therefore introduce a configuration graph that has \\(2^n\\) nodes where each node denotes a possible configuration of length \\(n\\). There is one initinal configuration, one accepting configuration, and one rejecting configuration. Two nodes are connected with a directed edge if one step computation transfers from the first configuration to the second.\nNotice that \\[|Q|\\times \\log(S(n))^k \\times S(n)^k = 2^{O(S(n))}\\]\nIn fact we can design a CNF \\(\\phi_{\\TM, x}\\) such that \\(\\phi_{\\TM,x}(C,C^\\prime) = 1\\) iff. \\(C\\to C^\\prime\\) is in the configuration graph of \\(\\TM(x)\\). Moreover, \\(\\phi\\) should have size at most \\(O(S(n))\\).\nPilot Lecture Testing whether Prof. Fu is intelligent enough to figure out how to remotely continue his lectures using Zoom.\nAgenda Expander Graph and Derandomization PATH is NL complete. UPATH is in Randomized Logspace. But we can derandomize this randomized algorithm to make it possible to run in a deterministic TM. Prof. Fu plans to use two weeks to finish this. The main techniques here are algebraic. A little combinatorics technique is still based on algebra.\nInteractive proof system. Though might be lengthy, IP will be introduced completely. Some might be skipped.\nPCP theorem (very complicated) 1/3 to 2/5 of the total time will be dedicated to this part.\nTwo chapters of the book is dedicated to this topic which corresponds to this part. The first chapter states the two forms of PCP theorem, but no proof. The latter chapter states the proof. This is considered by Prof. Fu very hard.\nPCP proof is a testament to the grasp of complexity theory. Very related to approximate algorithm.\nCryptography Easy for us cryptography students, he said. Mainly pseudorandomness, several equaivalent definitions.\nGrading Temporarily not settled. Most likely attendence rate, homework, and paper reading and sharing (presentation).\nLecture I Expander and Derandomization 这一章是去随机化的一个例子。\nSay we have a randomized algorithm, is there an equivalent determinstic algorithm? There are relatively very few examples in derandomization. This Chapter\u0026rsquo;s example is rather famous.\nSo far our proof (of derandomization) has been relying on assumptions extensively. Say \\(\\BPP\\) vs. \\(\\P\\) problem. Proving this equivalent is reduced to other questions not easier than \\(\\P \\ne \\NP\\) so derandomization is generally hard.\nBut for specific randomized algorihtm, such derandomization is possible, i.e. expander graph.\nSynopsis Basic Linear Algebra (also fix the symbols, etc.) Random Walk Expander Graph Explicit Construction of Expander Graph Reingold\u0026rsquo;s Theorem Basic Linear Algebra We use column vector.\nMatrix = Linear transformation: \\(Q^n\\to Q^m\\)\nLinearility \\(f(u+v) = f(u) + f(v)\\), \\(f(c\\cdot v) = cf(v)\\) \\(j^{th}\\) column is \\(A\\cdot e_j\\) Two views of matrix\nDynamic View as a linear transform Static View as a basis transform (Au = v, u is A\u0026rsquo;s representation of v) Or\nAlgebraically how to solve this \\[\\sum_i \\vec{a_i}\\cdot x_i = \\vec{b}\\] good for actually solving the problem (since algebra seems more \u0026ldquo;tangible\u0026rdquo; than other math). Also known as the column picture. Geometrically intersection of hyperplanes, intuition (also called the row picture) Equationally set of equations Inner product and Projection We use \\(u^T v\\) to denote inner product. we have \\(\\theta = \\arccos{u^T v}\\), as a measure of orthogonality.\nWe have the very important projection matrix \\(A (A^T A)^{-1} A^T\\). In terms of vectors, we have v\u0026rsquo;s project to u: \\[\\frac{u^T v}{\\norm{u}}\\cdot \\frac{u}{\\norm{u}}\\]\nOrthonormal basis basis + unit length + orthrogonal\nOrthogonal matrix\u0026rsquo;s columns forms a orthonormal basis.\nCauchy-Schwatz Inequality \\[u^T \\cdot v \\le \\norm{u}\\norm{v}\\]\nFix Point of Linear Transfrom \u0026ndash; Eigenvectors \\[Av = \\lambda v\\] Which means linear transfrom does not change direction. If eigenvector forms a basis, then linear transfrom is just \u0026ldquo;stretching\u0026rdquo; on each such directions.\nA basic fact in linear algebra is that if eigenvalues are distinct then the eigenvectors are linearly independent. Proof by induction.\nSuppose the eigenvector are \\(v_1\\), \\(\\ldots\\), \\(v_n\\) and eigenvalues are \\(\\lambda_1\\), \\(\\ldots\\), \\(\\lambda_n\\) respectively. If there exists \\(c_1\\), \\(\\ldots\\), \\(c_n\\) such that \\[ \\sum_i c_i v_i = 0\\] then we have by left multiplying \\(A\\) \\[ \\sum_i \\lambda_i c_i v_i = 0\\]\nThen by substracting the two equations, we have \\[ \\sum_{i=1}^{n-1} c_i (\\lambda_i - \\lambda_{n})v_i = 0\\]\nInductively, we have \\[ c_1 \\prod_{i=1}^{n-1} (\\lambda_1 - \\lambda_i) v_1 = 0\\]\nWhich means that \\(c_1 = 0\\). And then we can conclude that \\(c_2\\), \\(\\ldots\\), \\(c_n = 0\\), concluding the proof.\nLet the eigenvectors form a matrix \\(S\\) then we have \\[ AS = S\\Lambda,\\] and therefore for invertivle \\(S\\) we have \\[A = S\\Lambda S^{-1}\\]\nWe shall sort the eigenvalues by their absolute value as \\(\\lambda_1\\), \\(\\ldots\\), \\(\\lambda_n\\) in descending order.\n\\[\\abs{\\lambda_1}\\ge\\abs{\\lambda_2}\\ge\\ldots\\ge\\abs{\\lambda_n}\\]\nWe call \\(\\rho(A) = \\abs{\\lambda_1}\\) the spectral radius. (But since in later discussion we always have \\(\\lambda_1 = 1\\) this is not so important in this chapter.)\nSchur\u0026rsquo;s Lemma For each matrix \\(A\\) there exists unitary matrix \\(U\\) and triangular matrix \\(T\\) such that \\[T = U^T A U\\]\nThis lemma implies spectral theorem.\nTable of Property Juxtoposition Symmetric / Hermitian Orthogonal / Unitary\nProperties of Hermitian matrix:\n\\(x^T A x\\) is real since \\((x^T A x)^T = x^T A^T x = x^T A x\\)\nEigenvalues must be real since \\(Av = \\lambda v\\), \\(v^T Av = v^T \\lambda v\\) so \\(\\lambda \\in\\RR\\).\nEigenvectors of different eigenvalues are orthogonal. Say \\(A u = \\lambda u\\) and \\(A v = \\lambda^\\prime v\\) and \\(\\lambda \\ne \\lambda^\\prime\\).\nThen\n\\begin{align*} v^T A u \u0026amp;= v^t \\lambda u \\\\ (A^Tv)^T u \u0026amp;= \\lambda v^t u\\\\ (\\lambda^\\prime u)^T u \u0026amp;= \\lambda v^t u\\\\ (\\lambda - \\lambda^\\prime) (u^T v)\u0026amp;=0 \\end{align*}\nBy this fact Hermitian matrix with distinct eigenvalues can be diagonalized since \\[AU = U\\Lambda\\] \\[U^{T}AU = \\Lambda\\]\nSpectrual Decomposition: \\(A = \\sum_i \\lambda_i u_i u^T_i\\)\nWe skip SVD because this is not an AI course.\nRayleigh Quotient A is Hermitian and rayleigh quotient is defined as \\[R(A,x):= \\frac{x^T A x}{x^Tx} = \\frac{\\sum_i \\lambda_i\\norm{u_ix}^2}{\\sum_i \\norm{u_ix}^2}\\] where \\(x\\ne 0\\)\nAnd therefore this can be upperbounded by \\(\\lambda_1\\) and \\(\\lambda_i\\) if \\(x\\) is orthogonal to the subspace span by \\(u_1\\), \\(\\ldots\\), \\(u_{i-1}\\)\nNorm Norm is a map \\(\\FF^n\\to\\RR^{\\ge 0}\\) such that 3 properties are satisfied:\n\\(\\norm{v} = 0 \\implies v = 0\\) \\(\\norm{c\\cdot v} = c \\cdot \\norm{v}\\) \\(\\norm{u + v} \\le \\norm{u} + \\norm{v}\\) Matrix norm: the amplification ability of matrix\n\\(\\norm{A} = \\max_{v\\ne 0} \\frac{\\norm{Ax}}{\\norm{x}}\\)\nWe can use different norms in this equation / definition.\nRandom Walk Reviewing of last year\u0026rsquo;s lecture on random walk. From spectrum graph theory\u0026rsquo;s point of view.\nGraph is the central object in combinatorics. Moreover, graph has matrix representation. Undirected graph maps to symmetric adjecency matrix \u0026ndash; Neat.\nWe study undirected graph in this chapter. We allow self-loop and parallel edges in undirected graph.\nReachability matrix: if \\(j\\to i\\) is an edge we let \\(M_{ij} = 1\\).\nRandom Walk Matrix: normalize each column so that they add up to \\(\\mathbf 1\\). So they model uniformly choose a neighbor at random at node \\(j\\) for column \\(j\\). We usually use d-normal graph which means the number of neighbors are equal at every vertex.\nRandom walk: put a pebble randomly, and then randomly walk. So the distribution after k step random walk is \\[ A^k \\mathbf{p}\\] where \\(\\mathbf p\\) is the initial distribution.\nExample: n-layer digraph, each layer has d nodes. Layer 1 is only connected to layer 2, 2 to 3 and so on. Random walk on from one layer in this graph does not converge. Special case \u0026ndash; n = 2 -\u0026gt; bipartite graph.\nIntroduction to Spectrual Graph Theory For a undirectional d-regular graph \\(G\\) consider its random walk matrix \\(A\\).\nWe have \\(A\\one = \\one\\) since \\(A^T = A\\), each row is a distribution. So we acquired a trivial eigenvector, eigenvale pair. Consider the facts:\n1 is an eigenvalue of A and its associated eigenvector is the stationary distribution vector \\(\\one\\). In other words \\(A\\one = \\one\\).\nAll eigenvalues have absolute values \\(\\le 1\\). Suppose \\(v\\) is an eigenvector for \\(A\\), then let \\(v_i\\) be the component with largest absolute value (this is common to the following two facts). Consider \\(A_i^T v = \\lambda v_i\\). Since \\(A_i\\) only has \\(1/d\\) and \\(0\\) component, the \\(\\abs{A_i^T v}\\) is bounded by \\(v_i\\).\nG is disconnected if and only if 1 is an eigenvalue of multiplicity \\(\\ge 2\\). From left to right: uniform distribution over either of the two subgraphs.\nFrom right to left: Consider the component \\(v_i\\), we have any node connected with \\(i\\) must also have component equal to \\(v_i\\). Then by the two eigenvectors begin distinct, we can prove the graph is disconnected.\nIf G is connected, G is bipartite if and only if -1 is an eigenvalue of A. From left to right: all one in nodes in \\(G_1\\) and all negative one in nodes in \\(G_2\\).\nFrom right to left: consider \\(v_i\\). Any node connected to \\(v_i\\) must be \\(-v_i\\), and \\(-v_i\\) to \\(v_i\\). The graph is connected, so our analysis can be applied to any node on this graph. Therefore the graph must be bipartite.\nRate of Convergence For a regular graph \\(G\\) with random walk matrix \\(A\\), we define rate of convergence\n\\[\\lambda_G:= \\max_p{\\frac{\\norm{Ap-\\one}}{\\norm{p-\\one}}}= \\max_{v\\perp\\one}\\frac{\\norm{Av}}{\\norm{v}},\\] where \\(p\\) is a probability distribution.\nFrom left to right: trivial\nFrom right to left: \\(\\alpha v + \\one = p\\) where \\(p\\) is a probability distribution and \\(\\alpha\\) is small enough.\nBy definition \\(\\norm{Av}\\le \\lambda_G \\norm{v}\\) for all \\(v\\perp \\one\\).\nLecture II Rate of convergence: \\(\\lambda_G\\) the smaller, the faster random walk will converge to uniformly random distribution.\nLemma: \\(\\lambda_G = |\\lambda_2|\\)\nDefine \\(\\gamma_G = 1-\\lambda_G\\) spectral expansion\nLemma of \\(l\\) step random walk \\[\\frac{\\norm{A^l p - \\one}}{\\norm{p-\\one}} \\le \\lambda_G^l \\norm{p-\\one} \\le \\lambda_G^l\\]\nThe first inequality follows by the definition of rate of convergence. While the second one follows from:\n\\begin{align*} \\norm{p-\\one}^2 \u0026amp;= p^Tp -2p^T\\one + \\one^T\\one \\\\ \u0026amp;\\le 1 - 2/n + 1/n\\\\ \u0026amp;\\le 1 \\end{align*}\nNoticible Bound on Spectral Expansion IMPORTANT: technique \u0026ndash; make a path from u to v that relies on the bound.\nLemma: If \\(G\\) is an n-vertex, d-regular grpah with self loop at each node then \\(\\gamma_G \\ge 1/(12n^2)\\).\nProof: We only have to prove that \\(\\lambda_G^2 \\le 1 - 1/(6n^2)\\). By definition, let \\(u\\) be the normalized \\(v_2\\) eigenvector, and \\(v = Au\\). Then our object is equivalent to proving \\(\\norm{v}^2 \\le 1 - 1/(6n^2)\\)\nChange the form of \\(1 - \\norm{v}^2\\) a bit to get substraction terms.\n\\begin{align*} 1 - \\norm{v}^2 \u0026amp;= u^T u - 2 (Au)^T v + v^T v \\\\ \u0026amp;= \\sum_{i,j}(A_{i,j} (u_i\\cdot u_i - 2u_i\\cdot v_j + v_j\\cdot v_j)) \\\\ \u0026amp;= \\sum_{i,j}(A_{i,j} (u_i - v_j)^2) \\end{align*}\nNow comes the most important technique: we break lower bound this sum term by a path from some \\(i\\) to \\(j\\). First we argue for the biggest \\(u_i\\) and smallest \\(u_j\\) we must have \\(u_i - u_j \\ge 1/\\sqrt{n}\\) since \\(\\bf u\\) is normalized.\nConsider a shortest path \\(i (i_0)\\to i_1\\to \\ldots \\to i_k \\to j (i_{k+1})\\) in \\(G\\), we get by interpolating \\(v\\) terms\n\\begin{align*} 1/\\sqrt{n} \\le (u_i - u_j) \u0026amp;\\le \\sum_{j=0}^k |u_{i_k} - v_{i_k}| + |v_{i_k} - u_{i_{k+1}}| \\\\ \u0026amp;\\le \\sqrt{\\sum_{j=0}^k |u_{i_k} - v_{i_k}|^2 + |v_{i_k} - u_{i_{k+1}}|^2} \\cdot \\sqrt{2D} \\\\ \\end{align*}\nwhere \\(D\\) is the diameter of the graph. Here we use a technique of \u0026ldquo;first shift to v then shift to the next u\u0026rdquo; technique. In this way, since all difference terms corresponds to edges in \\(G\\), we have \\[\\sum_{i,j}(A_{i,j} (u_i - v_j)^2) \\ge \\frac{1}{2dDn}.\\]\nBy another bound on the diameter of graph: \\((d+1)D/3 \\le n\\) we get \\(D \\le 3n/(d+1)\\). This means \\(1 - \\norm{v}^2 \\ge \\frac{1}{6n^2}\\), which concludes the proof.\nAlgorithm from This Lemma Connectivity on graph (undirected).\nSince we have shown on such n-vertex, d-regular, self-loop graph, \\(\\gamma_G \\ge 1/(12n^2)\\), we have now starting from any point \\(s\\), the distribution after \\(l = 24n^2\\log n\\) steps satisfies that \\[\\norm{A^l p - \\one}\\le (1-\\frac{1}{12n^2})^{12n^2 \\cdot 2\\log n} \\le \\frac{1}{n^2}.\\]\nThen using the bound \\(\\norm{x}_{\\infty} \\le \\norm{x}_2\\) we get \\[\\Pr[(A^lp)_t=1] \\ge \\frac{1}{n}-\\frac{1}{n^2}\\ge \\frac{1}{2n}\\] for big enough \\(n\\). Therefore by repeating \\(2n^2\\) times, the failure probability is negligible (\\(1/2^n\\)).\nSo far we proved using this algorithm that \\(\\lang{UPATH} \\in \\RL\\), (and subsequently, in \\(\\NL\\)) but how can we show \\(\\lang{UPATH} \\in \\L\\) as well?\nExpander Graph Expander graphs, defined by Pinsker in 1973, are sparse and well connected. They behave approximately like complete graphs.\nSparsity should be understood in an asymptotic sense.\nSparsity can be defined by limiting the degree of every node.\nDefinitions Well-connectedness can be characterized in a number of manners.\nAlgebraically, expanders are graphs whose second largest eigenvalue is bounded away from 1 by a constant.\nCombinatorially, expanders are highly connected. Every set of vertices of an expander has a large boundary geometrically.\nProbabilistically, expanders are graphs in which a random walk converges to the stationary distribution quickly.\nPerhaps the one based on random walk serves as a starting point to understanding this definition the best. If random walk converges to uniform distribution is fast, then its well-connected. This corresponds to \\(\\lambda_G\\) is small enough according to our lemma.\nCombinartorially, this means an arbitrary set of nodes have many edges connected to outer nodes. (Inter connection is limited.)\nIn this chapter we prove the equivalence of the three definitions.\nAlgebraic Property We want to prove \\(\\lambda_G = O(1)\\). Note that the previous lemma is not good enough.\nSuppose \\(d \\in\\NN\\) and \\(\\lambda_G \\in(0, 1)\\) are constants.\nA d-regular graph G with n vertices is an \\((n, d, \\lambda)\\)-graph if \\(\\lambda_G\\le \\lambda\\).\n\\(\\set{G_n}_{n\\in\\NN}\\) is a \\((d,\\lambda)\\)-expander graph family if \\(G_n\\) is an \\((n,d,\\lambda)\\)-graph for all \\(n\\in\\NN\\).\nProbabilistic Property In an expander graph, random walk converges to uniform distribution in logarithmic time. \\[ \\norm{A^{2\\log_{1/\\lambda}{n}} p -\\one} \u0026lt; \\lambda^{2\\log_{1/\\lambda}{n}} = 1/n^2\\]\nNote that this means that after logarithmic steps, the probability that reaching any node from any node is positive. And this means that the diameter of an expander graph is logarithmic.\nCombinatorial Property Suppose \\(G = (V,E)\\) is an n-vertex, d-regular graph, and \\(S\\) be a set of vertices no more than \\(n/2\\).\nLet \\(\\bar{S}\\) be the complement of \\(S\\) Let \\(E(S,T)\\) be the subset of edges \\(i\\to j\\) s.t. \\(i\\in S\\), \\(j\\in T\\) Let \\(\\partial S = E(S, \\bar{S})\\) The expansion constant \\(h_G\\) of \\(G\\) is defined as: \\[ h_G = \\min_{|S|\\le n/2} \\frac{|\\partial S|}{|S|}\\]\nFor constant \\(\\rho \u0026gt; 0\\), an n-vertex, d-regular graph \\(G\\) is an \\(n,d,\\rho\\)-edge expander if \\(h_G / d \\ge \\rho\\)\nPerhaps \\(h_G / d \\in (0,1)\\) is a more natural definition. the bigger this value is, the better the graph is connected (well-connected).\nLecture III Expander Graph:\nAlgebraic Property Combinatorial Property Prabablistic Property We actually need a family of expander graphs. It is desireable to have their degree uniform and spectral gap the same (a constant strictly less than 1).\nExistence of Expander Theorem: Let \\(\\epsilon \u0026gt; 0\\). There exists \\(d = d(\\epsilon)\\) and \\(N\\in \\NN\\) such that for every \\(n \u0026gt; N\\) there exists an (\\(n\\), \\(d\\), \\(1/2 - \\epsilon\\))-edge expander.\nProof of this theorem is skipped. Using Probabilistic method seems to be the way to prove it.\nEquivalence Between Definitions Theorem. Let \\(G = (V, E)\\) be finite, connected, d-regular graph. Then \\[\\frac{\\gamma_{G}}{2}\\le \\frac{h_{G}}{d} \\le \\sqrt{2\\gamma_{G}}.\\] Very good thoerem proving the equivalence.\nFor sake of competence incompetence, let\u0026rsquo;s reproduce the proof here.\nProof. First we prove the first inequality. Consider the set \\(S\\) that has less than \\(n/2\\) vertices such that \\[h_{G} = \\frac{|\\partial{S}|}{|S|}.\\]\nNow consider the indicator vector \\(\\one_{S}\\), we construct a vector\n\\begin{equation*} x = |\\bar S| \\one_{S} + |S| \\one_{\\bar{S}} \\end{equation*}\nNotice that this vector is orthogonal to \\(v_{1} = \\one\\). This means that\n\\begin{align*} \\frac{x^{T} A x}{x^{T} x} \u0026amp;\\le \\lambda_{G} \\\\ \\frac{x^{T}x - x^{T} A x}{x^{T} x} \u0026amp; \\ge \\gamma_{G}. \\end{align*}\nNotice that\n\\begin{align*} x^{T} A x \u0026amp;= \\frac{1}{d}(|S|^{2}\\cdot E(S,S)- |S||\\bar{S}| \\cdot 2E(S,\\bar{S})+ |\\bar{S}|^{2} \\cdot E(\\bar{S},\\bar{S})) \\\\ \u0026amp;= \\frac{1}{d}(|\\bar{S}|^{2}(d|S|-|\\partial{S}|)-2|S||\\bar{S}||\\partial{S}|+ |\\bar{S}|^{2}(d|S|-|\\partial{S}|)) \\\\ \u0026amp;= \\frac{1}{d}(d|S||\\bar{S}|n - n^{2}|\\partial{S}|) \\\\ \u0026amp;= \\frac{1}{d}(d|S||\\bar{S}|n - n^{2} h_{G} |S|) \\end{align*}\nAnd\n\\begin{align*} x^{T}x \u0026amp;= |S||\\bar{S}|^{2} + |\\bar{S}||S|^{2} \\\\ \u0026amp;= n |S| |\\bar{S}| \\end{align*}\nAnd therefore we have\n\\begin{align*} \\gamma_{G} \u0026amp;\\le 1 - \\frac{x^{T} A x}{x^{T} x} \\\\ \u0026amp;= 1 - \\frac{n|S||\\bar{S}| - \\frac{h_{G}}{d} n^{2}|S| }{n |S| |\\bar{S}|} \\\\ \u0026amp;= \\frac{h_{G}}{d} \\frac{n}{\\bar{S}} \\\\ \u0026amp;\\le 2 \\frac{h_{G}}{d} \\end{align*}\nNow we prove the second part: \\(\\frac{h_{G}}{d} \\le \\sqrt{2\\gamma_{G}}\\)\nOnce again, we start by considering vectors that can connect spectrum to conbinatorial property of the graph. This time we consider the eigenvector \\(v\\) that correspond to \\(\\lambda_{G}\\). Let \\(v = u+w\\) where \\(u\\) (resp. \\(w\\)) only has positive (resp. negative) components of \\(v\\). Wlog we assume non-zero components of \\(u\\) is less than \\(n/2\\) and \\[u_{1} \\ge u_{2} \\ge \\ldots \\ge u_{n/2} = u_{n/2+1} = \\ldots u_{n}.\\]\nNow consider the term \\[\\sum_{i,j}A_{i,j}|u_{i}^{2} - u_{j}^{2}|,\\] We can use the property of \\(A\\) being symmetric and regular, and \\(u_{i} = 0\\) for \\(i\\ge n/2\\) to simplify the term as\n\\begin{align*} \\sum_{i,j}A_{i,j} (u_{i}^{2} - u_{j}^{2}) \u0026amp;=\\sum_{i\\le n/2}2/d\\sum_{j\\in\\partial{\\set{i}}} (u_{i}^{2} - u_{j}^{2}) \\\\ \u0026amp;=\\sum_{i\\le n/2}2/d\\sum_{j\\in\\partial{\\set{i}}} \\sum_{k=i}^{j-1} (u_{k}^{2} - u_{k+1}^{2}) \\\\ \u0026amp;=2/d \\sum_{k=1}^{n/2} \\partial{[k]} (u_{k}^{2} - u_{k+1}^{2}). \\end{align*}\nNow we can use the definition of \\(h_{G}\\) to relate this term with \\(h_{G}\\).\n\\begin{align*} \\sum_{i,j}A_{i,j} (u_{i}^{2} - u_{j}^{2}) \u0026amp;\\ge \\frac{2}{d} \\sum_{k=1}^{n/2} h_{G} k (u_{k}^{2} - u_{k+1}^{2})\\\\ \u0026amp;= \\frac{2h_{G}}{d} \\norm{u}^{2}. \\end{align*}\nUsing Cauchy-Schwatz Inequality, we have \\[\\sum_{i,j}A_{i,j}|u_{i}+u_{j}|^{2}\\cdot \\sum_{i,j}A_{i,j}|u_{i}-u_{j}|^{2} \\ge (\\sum_{i,j}A_{i,j}|u_{i}^{2} - u_{j}^{2}|)^{2}.\\]\nNow lets upper bound the left hand side. First\n\\begin{align*} \\sum_{i,j} A_{i,j} |u_{i} - u_{j}|^{2} \u0026amp;= \\sum_{i,j} A_{i,j} (u_{i}^{2} - 2u_{i}u_{j} + u_{j}^{2}) \\\\ \u0026amp;= 2\\norm{u}^{2} - 2u^{T}Au. \\end{align*}\nAnd\n\\begin{align*} u^{T} A u \u0026amp;\\ge u^{T} A u + u^{T} A w\\\\ \u0026amp;= u^{T}Av\\\\ \u0026amp;= u^{T}\\lambda v\\\\ \u0026amp;= \\lambda \\norm{u}^{2}. \\end{align*}\nSo we get\n\\begin{align*} \\sum_{i,j} A_{i,j} |u_{i} - u_{j}|^{2} \u0026amp;\\le 2(1-\\lambda_{G})\\norm{u}^{2} \\\\ \u0026amp;= 2 \\gamma_{G} \\norm{u}^{2}. \\end{align*}\nFor the other part \\(\\sum_{i,j} A_{i,j} |u_{i} + u_{j}|^{2} \\) We can simply upperbound it to \\(4\\norm{u}^{2}\\).\nAltogether these implies\n\\begin{align*} (2 \\gamma_{G} \\norm{u}^{2}) \\cdot (4\\norm{u}^{2}) \u0026amp;\\ge (\\frac{2h_{G}}{d} \\norm{u}^{2})^{2}\\\\ \\sqrt{2\\gamma_{G}} \u0026amp;\\ge \\frac{h_{G}}{d}. \\end{align*}\nThis completes the proof.\nConvergence in Entropy Recall the definition of Renyi entropy: \\[H_{\\alpha}(X) := \\frac{1}{1-\\alpha}\\log\\sum_{x}\\Pr[X=x]^{\\alpha}.\\]\nWe argue that in an expander graph, one-step random walk does not decresae collision entropy.\nThe proof is rather simple, following the normal directional decomposition formula. Consider one-step random walk from an initial distribution \\(p\\) on a (\\(n\\), \\(d\\), \\(\\lambda\\))-expander graph. Decompose \\(p\\) into \\(p = \\one + w\\) where \\(w\\) is orthogonal to \\(\\one\\). Then\n\\begin{align*} \\norm{Ap} \u0026amp;= \\norm{A(\\one + w)}\\\\ \u0026amp;= \\norm{\\one} + \\norm{Aw} \\\\ \u0026amp;\\le \\norm{\\one} + \\norm{\\lambda w} \\\\ \u0026amp;\\le \\norm{\\one} + \\norm{w} \\\\ \u0026amp;= \\norm{p} \\end{align*}\nAnd that means that \\(H_{2}(Ap) \\ge H_{2}(p)\\) meaning collision is more unlikely after one-step random walk.\nExpander Mixing Lemma Very famous result. Roughly speaking, it means that in an expander graph, vertex density can be estimated using edge density.\nLet \\(G=(V,E)\\) be an (\\(n\\), \\(d\\), \\(\\lambda\\))-expander graph. Let \\(S\\), \\(T\\) \\(\\subseteq\\) \\(V\\) be two vertex sets. We have \\[\\abs{ \\abs{E(S,T)} - \\frac{d}{n}|S||T| } \u0026lt; \\lambda d \\sqrt{|S||T|}.\\] In particular, it implies \\[\\abs{ \\frac{\\abs{E(S,T)}}{n^{2}} - \\frac{|S|}{n}\\frac{|T|}{n} } \u0026lt; \\lambda.\\]\nProof. We once again uses spectral property of the graph to prove this result. Let \\(\\one_{S}\\), \\(\\one_{T}\\) be the indicator vectors.\nConsider the eigen decomposition of \\(\\one_{S}\\) (resp. \\(\\one_{T}\\)) as \\(\\sum_{i} \\alpha_{i} v_{i}\\) (resp. \\(\\beta_{i}\\)). We have \\(\\alpha_{1} = \\frac{|S|}{\\sqrt{n}}\\) (resp. \\(\\beta_{i} = \\frac{|T|}{\\sqrt{n}}\\)).\nConsider\n\\begin{align*} E(S,T)/d \u0026amp;= \\one_{S}^{T} A \\one_{T} \\\\ \u0026amp;= \\sum_{i}\\lambda_{i}\\alpha_{i}\\beta_{i}\\\\ \u0026amp;= \\frac{|S||T|}{n} + \\sum_{i=2}\\lambda_{i}\\alpha_{i}\\beta_{i}\\\\ \\end{align*}\nSo we have\n\\begin{align*} E(S,T) - \\frac{d}{n}|S||T| \u0026amp;= \\sum_{i=2}\\lambda_{i}\\alpha_{i}\\beta_{i} \\\\ |E(S,T) - \\frac{d}{n}|S||T|| \u0026amp;\\le \\sum_{i=1}\\lambda |\\alpha_{i}||\\beta_{i}| \\\\ \u0026amp;\\le \\lambda \\norm{\\alpha}\\norm{\\beta}\\\\ \u0026amp;= \\lambda \\norm{\\one_{S}}\\norm{\\one_{T}} \\\\ \u0026amp;= \\lambda \\sqrt{|S||T|} \\end{align*}\nApplication of Expander Graph Error reduction in randomized algorithm.\nFrom \\(t(n)r(n)\\) to \\(r(n) + O(t(n))\\approx r(n) + dt(n)\\).\nThe key observation is that a t-step random walk in an expander graph looks like t vertices sampled uniformly and independently.\nConsider an (\\(2^{r(n)}\\), \\(d\\), \\(\\lambda\\))-expander graph. The intuition is to replace random choice on vertice with one-step random walk on this graph.\n\\(K_{n}\\) is perfect from the viewpoint of random walk. Because one step random walk directly yields independent uniform distribution over all vertices.\nLet \\(J_{n} = [\\one,\\one,\\ldots,\\one]\\) be the random walk matrix for \\(K_{n}\\) with self loops.\nDecomposition for Random Walk on Expander Lemma. Suppose G is an (\\(n\\), \\(d\\), \\(\\lambda\\))-expander and A is its random walk matrix. Then \\(A = \\gamma J_{n} + \\lambda E\\) for some E such that \\(\\norm{E} \\le 1\\).\nProof. Let \\(E = \\frac{1}{\\lambda} (A - \\gamma J_{n})\\), consider \\(v\\) be any vector. Let \\(\\alpha = \\sum_{i}v_{i}\\), then we can decompose \\(v = \\alpha \\one + w\\) where \\(w\\perp \\one\\).\n\\begin{align*} Ev \u0026amp;= E(\\alpha \\one + w) \\\\ \u0026amp;= \\frac{1}{\\lambda}(A - \\gamma J_{n})(\\alpha \\one + w) \\\\ \u0026amp;= \\frac{1}{\\lambda}(\\alpha \\one + Aw - \\gamma \\alpha \\one) \\\\ \u0026amp;= \\alpha \\one + \\frac{1}{lambda} Aw \\end{align*}\nObserve that \\(w\\) is perpendicular to \\(\\one\\), this implies\n\\begin{align*} \\norm{Ev} \u0026amp;\\le \\norm{\\alpha \\one + \\frac{1}{\\lambda} \\lambda w } \\\\ \u0026amp;= \\norm{v} \\end{align*}\nThis completes the proof.\nLecture IV In this lecture we continue on thoerems on expander graph and started on explicit construction of expander graph.\nExpander Random Walk Theorem \\(B\\) is a strict subset of \\([n]\\). B can be understood as a bad random number set. This theorem states that using random walk as random source, the probability of \\(k\\) repetition all fails has a exponentially decreasing upper bound.\nTheorem. Let \\(G = (V,E)\\) be an (\\(n\\), \\(d\\), \\(\\lambda\\))-expander graph, and let \\(B\\subsetneq [n]\\) be a set of vertices. Let \\(|S| = \\beta n\\), \\(\\beta \\in (0,1)\\). Let \\(X_{1}\\) be a random variable denoting the uniform distribution on \\([n]\\) and let \\(X_{k}\\) be a random variable denoting a \\(k-1\\) step random walk from \\(X_{1}\\). Then\n\\begin{equation*} \\ \\Pr[\\mathop{\\land}_{i=1}^k X_k\\in B] \\le (\\lambda + \\gamma \\sqrt{\\beta})^{k-1}. \\end{equation*}\nProof. We use \\(B_i\\) to denote the event that after \\(i-1\\) steps of random walk, the result is in \\(B\\). Define distribution vector \\(p_i\\) as\n\\begin{equation*} \\ p_i := \\frac{BA}{\\Pr[B_i|B_{i-1}\\ldots B_{1}]}\\frac{BA}{\\Pr[B_{i-1}|B_{i-2}\\ldots B_1]} \\ldots \\frac{B\\one}{\\Pr[B_1]}, \\end{equation*}\nWhere \\(B\\) is the diagonal matrix with \\(\\beta n\\) entries. \\(p_i\\) means the distribution of \\(i\\) step random walks conditioned on \\(B_1B_2\\ldots B_i\\).\nWe therefore get\n\\begin{equation*} \\ \\Pr[B_1B_2\\ldots B_k] p_i = (BA)^{k-1} B\\one \\end{equation*}\nFrom the relation between l1 norm and l2 norm we can get\n\\begin{align*} \\ \\Pr[B_1B_2\\ldots B_k] \u0026amp;= \\norm{\\Pr[B_1B_2\\ldots B_k] p_k}_1 \\\\ \u0026amp;= \\norm{(BA)^{k-1} B\\one}_1 \\\\ \u0026amp;\\le \\sqrt{n} \\norm{(BA)^{k-1} B\\one}. \\end{align*}\nUsing the decomposition lemma from last lecture, we have \\(A = \\gamma J_n + \\lambda E\\) for some \\(\\norm{E} \u0026lt; 1\\). So we have\n\\begin{align*} \\ \\norm{BA} \u0026amp;= \\norm{B (\\gamma J_n + \\lambda E)} \\\\ \u0026amp;= \\norm{\\gamma B J_n + \\lambda BE} \\\\ \u0026amp;\\le \\gamma\\norm{B J_n} + \\lambda \\norm{BE}. \\end{align*}\nNow consider \\(\\norm{v}=1\\). Let \\(\\alpha = \\sum_{i} v_i\\), then we have \\(v = \\alpha \\one + w\\) where \\(w \\perp \\one\\).\n\\begin{align*} \\ \\norm{B J_n v} \u0026amp;= \\norm{B J_n \\alpha\\one} \\\\ \u0026amp;= \\alpha \\norm{B \\one}\\\\ \u0026amp;= \\alpha \\frac{\\sqrt{\\beta}}{\\sqrt{n}} \\\\ \u0026amp;\\le \\sqrt{\\beta} \\end{align*}\nAnd by multiplicative property of matrix norm, we have\n\\begin{align*} \\ \\norm{BE} \u0026amp;\\le \\norm{B} \\norm{E} \\\\ \u0026amp;\\le 1 \\end{align*}\nSo together we get \\(\\norm{BA} \\le (\\gamma \\sqrt{\\beta} + \\lambda)\\). Since \\(\\norm{B\\one} = \\sqrt{\\frac{\\beta}{n}} \\le \\frac{1}{\\sqrt{n}}\\), we get\n\\begin{equation*} \\ \\Pr[B_1B_2\\ldots B_k] \\le \\frac{1}{\\sqrt{n}} (\\sqrt{\\beta}\\gamma + \\lambda)^{k-1}. \\end{equation*}\nAnd that completes the proof.\nActually the proof can be modified a bit to facilitate better understanding of the error reduction procedure of \\(\\BPP\\). In particular, subsequent \\(B_i\\) and \\(B_{i+1}\\) does not need to be adjacent. Consider the event that \\(B_1\\), \\(B_3\\), \\(B_4\\), \\(\\ldots\\), \\(B_{k+1}\\) happens. We can modify the equation by applying two step random walk after \\(B \\one\\). From the fact that \\(\\norm{A}\\le 1\\), we can still use the same upper bound.\nRandomness-Saving Error Reduction The above theorem almost directly corresponds to error reduction procedure for randomized algorithms. In particular, we can save the random bits from \\(O(k\\cdot r(n))\\) to \\(O(r(n) + kO(\\log d)\\), where \\(d\\) is the degree of some appropriate expander graph and \\(k\\) is the time of repeatition.\nRP Recall that a randomized TM for \\(L\\in\\RP\\) never error when accepting and has error probability at most \\(1/3\\) when rejecting. So the standard error reduction procedure is to repeat the algorithm \\(k\\) times on independent randomness to get \\(1/3^k\\) error probability, and it takes \\(k\\cdot r(n)\\) random bits.\nUsing expander graph, we can do much better. Let \\(n = |x|\\) and \\(G_n\\) be an (\\(2^{r(n)}\\), d, \\(\\lambda\\))-expander graph. Using the previous theorem, we can first use \\(r(n)\\) random bits to sample a uniform distribution over all vertices (whose bit-representation is every possible random choice of the TM on \\(n\\)-bit input), and subsequently use \\(k\\log(d)\\) bits to do k-step random walk. Let \\(B :|B|\\le 1/3 2^{r(n)}\\) be the set of randomness on which \\(M\\) fails, then the probability of all k trials fail is at most \\((\\sqrt{\\beta} (1 - \\lambda) + \\lambda)^{k-1} \\le (\\frac{\\gamma+1}{2})^{k-1}\\), which is also exponentially small.\nBPP The case for \\(\\BPP\\) is more tricky since the turing machine can error with at most \\(1/3\\) probability at whatever output. The standard practice in this case is do majority voting on repeatition results. In the stardard case when independent randomness is used we use Chernoff bound to bound fail probability. Using expander graph, however, we need to modify the previous theorem (in a trivial way) to facilitate non-adjacent failure.\nConsider \\(n = |x|\\) and a \\((2^{r(n)}, d, \\lambda)\\)-expander graph. We can once again do \\(k\\) step random walk on this graph using \\(r(n) + k \\log(d)\\) random bits. The catch here is this procedure fails when \\(\\frac{k+1}{2}\\) trials fail, which by inspecting the previous proof more carefully, is at most \\((\\sqrt{\\beta}\\gamma + \\lambda)^{k+1/2}\\). We then use a union bound to include all possible cases of failure, which is \\(\\binom{k}{k+1/2}+\\binom{k}{k+3/2}+\\ldots + \\binom{k}{k} \u0026lt; 2^{k}\\), making the failure probability at most\n\\begin{equation*} 2^k \\cdot (\\sqrt{\\beta}\\gamma + \\lambda)^{k/2} = (2 \\cdot \\sqrt{\\sqrt{\\beta}\\gamma + \\lambda})^k, \\end{equation*}\nwhich can be made exponentially small by choosing appropriate \\(\\beta\\) (recall \\(\\beta\\) is tunable through stardard error reduction procedure).\nExplicit Construction of Expander Graph Family Typically we model vertices on expander graph as random choice, which makes its number exponentially large on polynomial time machines. So the algorithm to construct this graph may not always be efficient. We just a program that on input the graph index, vertice node index, and its neighbor index, output the neighbor\u0026rsquo;s node index.\nIn particular, to quote Prof. Fu\u0026rsquo;s slides:\nIn some applications expander graphs are small. An expander family \\(\\set{G_{n}}_{n\\in\\NN}\\) is mildly explicit if there is a P-time algorithm that outputs the random walk matrix of \\(G_n\\) whenever the input is \\(1^n\\). In some other applications expander graphs are large. An expander family \\(\\set{G_{n}}_{n\\in\\NN}\\) is strongly explicit if there is a P-time algorithm that on input \\(n, v, i\\) outputs the index of the i-th neighbor of v. Graph Products We will use several graph products to explicitly construct expander graph.\nPath Product\nThe path product of \\(G, G^{\\prime}\\) is another graph defined by \\(A^{\\prime}A\\) where \\(A, A^{\\prime}\\) are the respective random walk matrices. Its degree is \\(dd^{\\prime}\\). Its spectral gap is at most \\(\\lambda \\lambda^{\\prime}\\), and equality is achieved when the eigenvectors corresponding to spectral gap are parallel. In particular, we have \\(\\lambda_{G^n} = \\lambda_{G_n}^n\\).\nPath product can increase graph connectivity, but at a cost of higher degree.\nTensor Product\nThe tensor product of \\(G, G^{\\prime}\\), denoted \\(G \\otimes G^{\\prime}\\) is a graph (\\(V\\times V^{\\prime}, E \\times E^{\\prime}\\)). In particular, it means that vertices in \\(G \\otimes G^{\\prime}\\) is (u, v) where \\(u\\in V\\) and \\(u^{\\prime} \\in G^{\\prime}\\), and \\((u,v) \\to (w,z)\\) is an edge if \\((u,w) \\in E\\) and \\((v,z) \\in E^{\\prime}\\). In terms of matrix, we can write the resulting graph\u0026rsquo;s random walk matrix as\n\\begin{equation*} A_{G\\otimes G^{\\prime}} = \\begin{bmatrix} a_{1,1} A^{\\prime} \u0026amp; a_{1,2} A^{\\prime} \u0026amp; \\ldots \u0026amp; a_{1,n} A^{\\prime} \\\\ a_{2,1} A^{\\prime} \u0026amp; a_{2,2} A^{\\prime} \u0026amp; \\ldots \u0026amp; a_{2,n} A^{\\prime} \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\ a_{n,1} A^{\\prime} \u0026amp; a_{n,2} A^{\\prime} \u0026amp; \\ldots \u0026amp; a_{n,n} A^{\\prime} \\\\ \\end{bmatrix} \\end{equation*}\nThere are a few points to note:\nThere is no restriction on the dimension or degree of the graph From graph\u0026rsquo;s point of view, shifting order produce isomorphic graphs The resulting graph has \\(nn^{\\prime}\\) nodes and \\(d d^{\\prime}\\)-degree. Since \\[(A\\otimes A^{\\prime})\\cdot (v \\otimes v^{\\prime}) = Av \\otimes A^{\\prime} v^{\\prime}\\], and the eigenvectors of \\(A \\otimes A^{\\prime}\\) has the form \\(v_1 \\otimes v_2\\) where \\(v_1\\) (resp. \\(v_2\\)) is the eigenvector for \\(A\\) (resp. \\(A^{\\prime}\\)). So it follows that \\(\\lambda_{G\\otimes G^{\\prime}} = \\max{\\lambda, \\lambda^{\\prime}}\\).\nRotation Map\nIn this type of operation, we describe the connectivity details of a random walk matrix \\(A\\) by a \\(nd\\times nd\\) adjacency matrix. Vertice \\((u,i)\\) is connected to \\((v,j)\\) iff. v is u\u0026rsquo;s ith neighbor and u is v\u0026rsquo;s jth neighbor. This matrix is denoted as \\(\\hat A\\).\nZig-Zag Product\nConsider two graphs \\(G\\) of \\(n\\) vertices and \\(D\\) regularity, and \\(H\\) of \\(D\\) vertices and \\(d\\) regularity. The zig-zag product of G and H, denoted by \\(G \\circ H\\) is defined by\n\\begin{equation*} G \\circ H := (I_n \\otimes B) \\hat{A} (I_n \\otimes B). \\end{equation*}\nThe intuition here is that we combine three step of walk (from the path product). First do a random walk on \\(H\\) (the tensor product is with a graph with only self-loop on which random walk does nothing), then from the vertex labelling in \\(H\\) in this step, we can determine an edge in \\(G\\) through the rotation matrix, and finally one more step on \\(H\\). Using the parallel walk view of tensor product might be helpful here.\n\u0026lt;asset/zig-zag.eps\u0026gt;\nThere is a lemma regarding zig-zag product.\nLemma. \\((I_n \\otimes J_D) \\hat{A} (I_n \\otimes J_D) = A \\otimes J_D\\)\nFrom the random walk intuition, left hand side corresponds to first one step random walk on \\(J_D\\) and then rotation map on \\(A\\) and finally one more step on \\(J_D\\). Since one step random walk on \\(J_D\\) essentially randomly chooses a neighbor in \\(A\\), and any steps of random walk on \\(J_D\\) is equivalent to one step random walk on \\(J_D\\), this is equivalent to independently random walk on \\(A\\) and \\(J_D\\) for one step.\nIn detail, \\((I_n \\otimes J_D) \\hat{A} (I_n \\otimes J_D)_{(u,i),(v,j)} = \\frac{1}{D}\\frac{1}{D}\\) for \\(\\hat{A}_{(u,i),(v,j)} = 1\\) and that is the same with \\(A \\otimes J_D\\).\nLecture V Continuing on the explicit construction of expander graph. It is not until almost a week later before I finally settle down to organize these unsolicitated notes. Prof. Fu used a somewhat simpler construction in the proof of Reingold theorem. I will stick to his version in this note.\nReview on Expander Graph Two types of explicit graphs: strongly explicit (neighbor is efficiently computable), mildly explicit (whole graph is efficiently constructable)\nFor a random algorithm that uses \\(r(n)\\) bits, we need a graph with \\(2^r\\) nodes.\n\\(r = O (\\log n)\\) we can compute the graph directly (explicit or mildly explicit)\n\\(r = \\omega (\\log n)\\) (e.g. \\(r = \\poly (n) \\)) we cannot compute the graph directly since it is too big. But for random walk, we only need to randomly choose a neighbor. The syntax is \\((n, v, i) \\mapsto u\\) where \\(u\\) is the ith neighbor of \\(v\\) in \\(G_n\\). In our setting, v\u0026rsquo;s encoding is polynomial length, \\(i \u0026lt; d\\) is a constant, and n\u0026rsquo;s binary representation is polynomial. So compared to the graph\u0026rsquo;s size, this input is log-length.\nSo the algorithm we want is polylog in the size of the graph, which is why this is called strong.\nGraph Products Review Path Product: \\(\\lambda_{G^k} = \\lambda_G^k\\) Tensor Product: important in linear algebra and quantum computation. \\(\\lambda_{G \\otimes G^{\\prime} = \\max(\\lambda_G, \\lambda_{G^{\\prime}})}\\). Rotation Matrix: the rotation matrix \\(\\hat A\\) is an adjacent matrix \\(nD \\times nD\\). \\(\\hat{A}_{(v,j), (u,i)} = 1\\) iff. v is u\u0026rsquo;s ith neighbor and u is v\u0026rsquo;s jth neighbor. The good thing about rotation matrix is that this map is deterministic and invertible. This property will be useful in the construction of expander. (It enables backtracking.) Zig-Zag Product: Zig-Zag product of G and H is defined by \\((I_n \\zigz B) \\hat{A} (I_n \\zigz B)\\). More on Zig-Zag Product Lemma. \\(\\lambda_{G \\zigz H} \\le \\lambda_G + 2\\lambda_H\\) and \\(\\gamma_{G \\zigz H} \\ge \\gamma_G \\gamma_H^2\\).\nUses Decomposition lemma, triangle inequality on matrix norm and properties on the specturm of tensor product.\nProof (informal). Let \\(M\\) (resp. \\(A\\), \\(B\\)) be the random walk matrix of \\(G \\zigz H\\) (resp. \\(G\\), \\(H\\)), then by definition we have \\(M = (I_n \\otimes B) \\hat{A} (I_n \\otimes B)\\). Using decomposition lemma to decompose \\(B = \\gamma_H J_D + \\lambda_H E\\) for some \\(\\norm{E} \u0026lt; 1\\), we can expand the term into\n\\begin{align*} M \u0026amp;= (\\gamma_H I_n \\otimes J_D + \\lambda_H I_n \\otimes E) \\hat{A} (\\gamma_H I_n \\otimes J_D + \\lambda_H I_n \\otimes E) \\\\ \u0026amp;= \\gamma_H^2 A \\otimes J_D + \\text{rest}. \\end{align*}\nWe thus get \\(\\lambda_M \\le \\gamma_H^2 \\lambda_G + (1 - \\gamma_H^2)\\). This implies that \\(\\gamma_{G \\zigz H} \\ge \\gamma_G \\gamma_H^2\\), proving the second part of the thoerem. For the first part, we further relex the inequality, to \\(\\lambda_M \\le (1 - \\lambda_H)^2 \\lambda_G + 1 - (1 - \\lambda_H)^2 \\le \\lambda_G + 2\\lambda_H\\), completing the proof.\nComment on Zig-Zag Product:\nTypically \\(D \\gg d\\), \\(d\\) is the degree of the resulting expander graph. In Arora\u0026rsquo;s book, it is noted that this kind of graph operation (also replacement product) is used mainly to drastically reduce graph degree without deteriating connectivity too much. A t-step random walk thus uses \\(t \\log d\\) rather than \\(t \\log D\\) random bits. If \\(\\lambda_G\\), \\(\\lambda_H\\) are too big, there is a different bound in the 2000 RVW paper. O. Reingold, S. Vadhan, and A. Wigderson. Entropy Waves, the Zig-Zag Graph Product, and New Constant Degree Expanders and Extractors. FOCS, 2000. Expander Construction I Idea: use path product and zig-zag product to produce an expander graph family.\nSize Degree Expansion Path \u0026ndash; up UP Tensor up up down ZigZag up DOWN down What we want is constant degree. Maybe we can use path product to get good expansion and zig-zag product to bring back degree.\nLet \\(H\\) be a (\\(D^4\\), \\(D\\), \\(1/8\\))-grpah constructed by brute force (maybe proved to exist using probabilistic method, where we will find a appropriate constant \\(D\\)). Define\n\\begin{align*} G_1 \u0026amp;= H^2 \\\\ G_{k+1} \u0026amp;= G_k^2 \\zigz H \\end{align*}\nFact. \\(G_k\\) is a (\\(D^{4k}\\), \\(D^2\\), \\(1/2\\))-graph\nProof. Inductively, using previous lemmas, we get that \\(\\lambda_{G_{k+1}} \\le \\frac{1}{4} + 2 \\frac{1}{8} = \\frac{1}{2}\\). For the base case, it follows trivially that \\(\\lambda_{H^2} \u0026lt; \\frac{1}{2}\\).\nThe problem is how to interpolate between \\(D^4, D^8, \\ldots\\) ? It seems there is a facile solution.\nThe solution is indeed very cheesy, if you would allow me to use such language. Notice how our construction constructed, for some constant \\(c\\), expander graphs with nodes \\(c^1, c^2, c^3, \\ldots\\). So for an input \\(n^{\\prime}\\), we can find such a \\(n = c^i\\) for some power \\(i\\) that \\(\\frac{n}{c} \u0026lt; n^{\\prime} \u0026lt; n\\). Now if we contract \\(k\\) \\(e\\)-large vertice sets that are disjoint, we can actually show that resulting graph will have edge-expansion factor \\(\\rho\\) reduced at most to \\(\\frac{\\rho}{2e}\\) (a very loose bound) and degree increased to \\(d e\\) where \\(d\\) is the original regularity. This means by fixing a proper \\(e\\) we can interpolate between the graphs we caonstructed to get a bona fide expander family.\nThe time it takes to random walk on construction 1 is poly in graph size, so it is not strongly explicit. The space requirement is polylog, though.\nTo get such result, we can analyze the construction of such graph. To access a neighbor in \\(G_k\\), one needs to perform two walks in \\(G_{k-1}\\) and two (the slides showed one but I think in zig-zag product you need to walk two steps in \\(H\\)) walks in \\(H\\), meaning that \\(t_k = 2 t_{k-1} + O(1)\\). Unfolding the recursive expression, we get that \\(t_k = 2^{O(k)} = \\poly(|G_k|\\), meaning this graph is only mildly explicit.\nReplacement Product Consider the graph \\(G, H\\) as in zig-zag product, we define replacement product between \\(G, H\\) by\n\\begin{equation*} M = \\frac{1}{2} \\hat{A} + \\frac{1}{2} (I_n \\otimes B). \\end{equation*}\nThe intuition behind replacement product is very simple: if random walk on \\(G\\) is too expensive, we can use a smaller expander graph to generate edge label for it. So at each step of random walk in \\(G \\repl H\\), with \\(1/2\\) prob. we take one step random walk in \\(H\\), or else, using the vertice label inside the \\(H\\) \u0026ldquo;cloud\u0026rdquo; as edge lebel in \\(G\\) to do a rotation map. We shall show some not-so-bad algebraic properties of spectral gap.\nAlgebraic Properties Lemma. \\(\\gamma_{G \\repl H} \\ge \\frac{\\gamma_G \\gamma_H^2}{24}\\)\nProof (informal). We use a little trick here. First notice from basic inequality \\( (1+x)^n \u0026gt; 1+nx\\) it suffices to prove \\(\\lambda_{(G \\repl H)^3 \\le 1 - \\frac{\\gamma_G \\gamma_H^2}{8} }\\). This can be proved by decomposing \\(H\\), since \\(\\lambda_{(G \\repl H)^3} \\le \\frac{\\gamma_H^2}{8} (1 - \\gamma_G) + (1 - \\frac{\\gamma_H^2}{8}) = 1 = \\frac{\\gamma_G \\gamma_H^2}{8}\\). Completing our proof.\nExpander Construction II There exists a strongly explicit (\\(4\\), \\(\\lambda\\))-expander family for \\(\\lambda\u0026lt;1\\).\nThe construction is as follows. Let \\(H\\) be a (\\((2d)^{100}\\), \\(d\\), \\(0.01\\))-expander graph, \\(G_1\\) be a (\\((2d)^{100}\\), \\(2d\\), \\(0.5\\))-expander graph, and \\(G_2\\) be a (\\((2d)^{200}\\), \\(2d\\), \\(0.5\\))-expander graph. We then define for \\(k \u0026gt; 2\\),\n\\begin{equation*} G_k = (G_{\\ceil{\\frac{k-1}{2}}} \\otimes G_{\\floor{\\frac{k-1}{2}}})^{50} \\repl H. \\end{equation*}\nIt is easy to show through induction that \\(G_k\\) is a expander graph.\nFact. \\(G_k\\) is a (\\((2k)^{100k}\\), \\(2d\\), \\(0.98\\))-expander graph.\nAnother good property is that every induction reduces the problem size by half. This means that the time to do one-step walk in \\(G_k\\) is \\(t_k = \\poly(k) = \\polylog (|G_k|)\\). This means construction II is actually strongly explicit.\nProf. Fu commented that the \u0026ldquo;strongness\u0026rdquo; is achieved by a much much faster (double exponential in \\(\\log k\\)) growth in graph size, introduced by the tensor product.\nReingold\u0026rsquo;s Theorem Fun fact about the German language: Rain + Gold = Reingold\nTheorem. \\(\\lang{UPATH} \\in \\L\\)\nWhat we know already is that \\(\\lang{UPATH} \\in \\RL\\). The theorem does derandomization.\nConnectivity in expander graph can be done in logspace since\nthe diameter is log in its size for a regular graph, we only need to store graph label in the DFS stack, whose length is \\(O(\\log n)\\). (I think backtracking can be cheesed by traversing from the starting point all over again since all history is stored in the stack). This is the starting point of Reingold\u0026rsquo;s idea.\nBut the input is arbitrary. We must first convert the input graph in logspace, to an expander graph. The converted graph (of which we call \\(G^{\\prime}\\)) is poly-sized and therefore cannot be stored on working tape at once.\nWe use Construction I in Reingold\u0026rsquo;s algorithm. But conversion of \\(G\\) and construction of \\(G^{\\prime}\\) must be done \u0026ldquo;on-the-fly\u0026rdquo;.\nThe algorithm must come in different versions, since I find the one during the lecture essentially used construction I, whereas in Arora\u0026rsquo;s book, the algorithm used construction II. Nevertheless, the ideas should be similar. In this note, I will stick to Prof. Fu\u0026rsquo;s algorithm. We start by choosing an appropriate constant \\(D\\) and find a (\\(D^4\\), \\(D\\), \\(\\frac{1}{4}\\))-expander graph. We set a counter to \\(10 \\log n\\) where \\(n\\) is the input length, and enumerate all random walks in \\(G_k\\) from \\(s_k\\) to \\(t_k\\). \\(G_k\\) is constructed inductively like in construction I except in the base case we let \\(G_0\\) be the \u0026ldquo;regulated\u0026rdquo; input graph. The vertice convertion from \\(G_{k-1}\\) to \\(G_k\\) is done by putting arbitarty \\(i\\in[D^{4}]\\) (say all zero) paddings at back, since vertices in \\(G_k\\) has the form \\((u, i)\\) where \\(u \\in G_{k-1}\\) and \\(i \\in [D^4]\\). Since \\(H\\) is connected, \\(s\\) and \\(t\\) are connected iff. \\(s_k\\) and \\(t_k\\) do.\nThe number \\(10 \\log n\\) is chosen since the original spectral expansion \\(\\gamma\\) is at least \\(\\frac{1}{12n^2}\\). By each induction step, we can increase \\(\\gamma\\) by at least \\(\\frac{5}{4}\\). This means by \\(O(\\log n)\\) steps, every connected component in \\(G\\) would be an expander. Up to now, we can use the connectivity algorithm for expander graph to get output. (I did not verify this number personally, but you can essentially choose a large enough constant to ensure that.)\nOne tricky part is to show the algorithm indeed use logspace. To do one step walk in \\(G_k\\), we need to perform first one-step walk on \\(H\\), rotation map in \\(G_{k-1}\\), and finally another walk in \\(H\\). Since the recursion depth in \\(O(\\log n)\\), a trivial recursive algorithm uses logspace to perform a rotation map in \\(G_{10 \\log n}\\). This roughly concludes the proof. (One convinent feature about this construction is that during DFS, when backtracking is needed, we can actually derive the previous node \\(u\\) from current node \\(v\\) and the edge label \\(w\\) in the stack, since the mapping of rotation map is symmetrical.)\nOn RL vs. L The problem \\(\\RL = \\L\\) is open, the best we know is that \\(\\RL \\subseteq \\L^{3/2}\\). This result relies on pseudorandom generator, which sounds like a bit messy.\nLecture VI Interactive Proof System. Still a lot of math involved, but we might not plunge right in as in previous chapter.\nSome Zero-Knowledge related topics might not be covered in this semester, due to time limit.\nSome glimpse of interactive proof.\nDefinition of \\(\\NP\\) based on certificates: certificates are proofs. OTM: Oracle\u0026rsquo;s output is the proof Cook Reduction: \\(A \\le B\\), where \\(B\\) is the prover PH: OTM-based definition So computer science folks think this paradigm of prover / verifier is very useful. Interactive proof finds important application in crypto and approximation algorithms. PCP theorem\u0026rsquo;s proof also uses interactive proof.\nOn a philosophical view: a proof is created to be (efficiently) verified.\nIt was not until 1985 that the idea of computation through interaction was formally studied by two groups.\nLaszlo Babai, with a complexity theoretical motivation; Shafi Goldwasser, Silvio Micali and Charles Rackoff (who later plunged into political business, missing the Turing award), with a cryptographic Syntax:\nProver try to convince verifier some assertion is true. Verifier Probabilistic turing machine, try to find the truth value of this assertion. They communicate through dialogue.\nSynopsis MIP = NEXP might not be covered. All other topics will be covered. Note that a recent result showed that \\(\\class{MIP}^{*} = \\class{RE}\\).\nBasic Principle Verifier\u0026rsquo;s job must be easy (i.e. time complexity is polynomial). Prover\u0026rsquo;s power can be unbounded, but the answer must be short. Since the verifier\u0026rsquo;s query also counts as one step, it cannot ask too many questions.\nDeterministic Verifier Note that one query, one answer count as two rounds. \\(\\class{dIP}\\)\nWe say that a language \\(L\\) has a k-round deterministic proof system if there is a TM \\(V\\) that on input \\(x, a_1, \\ldots, a_k\\) runs in \\(poly(|x|)\\) time, and can have a \\(k |x|\\)-round interaction with any TM \\(P\\) such that the following statements are valid\nCompleteness \\(x \\in L \\implies \\exists P: \\set{0,1}^{*} \\to \\set{0,1}^{*} \\), \\(out_V(P,V) = 1\\), Soundness \\(x \\not\\in L \\implies \\forall P: \\set{0,1}^{*} \\to \\set{0,1}^{*}\\), \\(out_V(P,V) = 0\\). The class \\(\\class{dIP}\\) captures all such languages for deterministic verifiers. Unfortunately, we have the following fact.\nFact. \\(\\class{dIP} = \\NP\\)\nSo we will only be interested in probablistic verifiers. 如果是确定性的算法，那么问的问题都是傻问题；如果投硬币，才可能问聪明的问题\nInteractive Proof with Private Coins The STOC 1985 Paper: The Knowledge Complexity of Interactive Proofs has been rejected three times before finally accepted.\nPrivate Coin \u0026ndash; an Introduction Marla has one red sock and one green sock.\nHow can he convince Arthur, who is color blind, of the fact that the socks are of different color?\nArthur writes \u0026ldquo;1\u0026rdquo; and \u0026ldquo;2\u0026rdquo; on two socks. First let Marla sees the order, and then he secretly shuffles the socks with probability \\(1/2\\). If Marla has advantage in telling whether they have been shuffled, Arthur can be convinced whether the two socks are of the same color.\nPrivate Coins Model Verifier geneates an \\(l\\)-bits random number \\(r\\sample\\set{0,1}^l\\). The verifier knows \\(r\\) but the prover cannot see \\(r\\).\n\\begin{align*} a_1 = f(x,r), \u0026amp;a_3 = f(x, r, a_1, a_2), \\ldots \\\\ a_2 = g(x, a_1), \u0026amp;a_4 = g(x, a_1, a_2, a_3), \\ldots \\end{align*}\nBoth the interaction and the output can be viewed as random variable over \\(r\\).\n\\(\\IP\\) \u0026mdash; Interactive Proofs with Private Coins We can formulate \\(\\IP[k(n)]\\) as interactive proof with \\(k(|x|)\\) rounds.\nSuppose \\(k\\) is a polynomial. A language \\(L\\) is in \\(\\IP[k(n)]\\) if there\u0026rsquo;s a P-time PTM \\(V\\) that can have a \\(k(|x|)\\)-round interaction with any TM \\(P\\) and renders valid the following.\nCompleteness \\(x \\in L \\implies \\exists P: \\set{0,1}^{*} \\to \\set{0,1}^{*} \\), \\(\\Pr_r[out_V(P,V) = 1] \\ge 2/3\\), Soundness \\(x \\not\\in L \\implies \\forall P: \\set{0,1}^{*} \\to \\set{0,1}^{*}\\), \\(\\Pr_r[out_V(P,V) = 0] \\le 1/3\\). The class \\(\\IP\\) is defined by \\(\\cup_{c\\ge 1} \\IP[n^c]\\)\nOn a closer look, we may find that the prover is a \\(\\BPP\\) machine, whereas the verifier can be a \\(\\BPP\\) machine.\nFact. We may assume prover in the definition of \\(\\IP\\) is in \\(\\PSPACE\\).\nThe optimal prover may enumerate over\nThe random choice of verifer Possible answers whose total length is polynomial. It can use counting to find out which answer is optimal (in the sense that it produces the most convincing answer).\nCorollary. In \\(\\IP\\)\u0026rsquo;s definition, we can only consider the optimal prover.\nCorollary. \\(\\IP \\subseteq \\PSPACE\\), the converse direction will be covered later in this chapter (i.e. the celebrated PCP theorem).\nRobustness of Definition Using standard repetition technique, one can reduce error probability to \\(2^{1n^s}\\). In the case of \\(\\IP\\) (unbounded prover) parallel and sequential repetition are the same.\nFact. Allowing prover to use a private coin does not change \\(\\IP\\), since we can find a deterministic prover from a probablistic prover.\nPerfect Completeness \\(\\IP\\) with perfect completeness = \\(\\IP\\) \\(\\IP\\) with perfect soundness = \\(\\NP\\) Proof of 1. any problem in \\(\\IP\\) can be karp reduced to \\(\\lang{TQBF}\\) which has a sumcheck IP protocol that has perfect completeness.\nProof of 2. We can view the random string and answers to \\(V\\) as certificate. Since soundness is perfect, this fits the definition of \\(\\NP\\).\nGraph Non-Isomorphism \\(\\lang{GI}\\) is not known to be in \\(\\P\\). The best algorithm is \\(2^{\\polylog(n)}\\). \\(G_0\\) and \\(G_1\\) are isomorphic iff. there exists \\(\\pi\\) such that \\(\\pi(G_0 = G_1\\).\nProtocol for GNI:\nV: choose \\(r\\sample\\set{0,1}\\), and generate a random permutation graph \\(H\\) of \\(G_r\\). Send \\(H\\) to \\(P\\). P: identify the origin of \\(H\\) and reply with the answer. V: accept iff. the answer is correct. Completeness is perfect, soundness error is \\(1/2\\).\nQuadratic Non-Residuosity \\(\\lang{QR} = \\set{(a,p): \\exists b, b^2 = a \\pmod{p}}\\)\n\\(\\lang{QNR}\\) is not known to be in \\(\\NP\\) or not.\nProtocol for QNR:\nV: pick \\(r \u0026lt; p\\) and \\(i \\in \\set{0,1}\\) randomly. If \\(i = 0\\) then send \\(r^2 \\mod p\\) to P, else send \\(a r^2 \\mod p\\) to P. P: identify which is the case and answer with \\(i^{\\prime}\\). V: accept iff. \\(i = i^{\\prime}\\). Completeness is perfect, soundness error is \\(1/2\\).\nSummary One of the greatest achievements in complexity theory is that \\(\\IP = \\PSPACE\\).\nLecture VII We continue on interactive proof system with private coins, and start working on interactive proof system with public coins.\nInteractive Proof System for Permanent Recall that permanent is \\(\\#\\P\\)-complete.\nWe design an interactive proof system for perm(A) using arithmetic method\nRecall the formula for permanent\n\\begin{equation*} \\func{perm}(A) = \\sum_i a_{1,i} \\func{perm}(A_{1,i}) \\end{equation*}\nwhere \\(A_{1,i}\\) is the \\((n-1)\\times (n-1)\\) submatrix from deleting the first row and \\(i\\)th column from \\(A\\). This potentially allows us to reduce the problem of size \\(n\\) to that of size \\(n-1\\).\nThe idea behind this protocol is much reminiscent to the semi-honest to malicious transition in the BGW protocol (or the other direction). Notice that we can encode the matrices compactly: Using Vandermont matrix and Gaussian elimination, we can get a \\((n-1)\\times (n-1)\\)-matrix of \\((n-1)\\)-degree polynomials \\(D_A(x)\\) such that \\(D_A(i) = A_{1,i}\\) for \\(i \\in [n]\\). The permanent for \\(D_A\\) is a polynomial of degree at most \\(2(n-1)\\), which is very compact. The prover can send it as a proof. Though the prover can cheat by setting the target number \\(t\\) and the polynomial \\(p\\) to be such that\n\\begin{equation*} \\sum_i A_{1,i} p(i) = t \\end{equation*}\nThe number root of \\(p - \\func{perm}(D_A)\\) will be at most \\(2n - 2\\), and the verifier can choose a random number from a large enough field \\(\\ZZ_{q}\\), and then let the prover prove that \\(\\func{perm}(D_A(q)) = p(q)\\), which with high enough probability, is false. And thus we can use a union bound to show that an unfaithful prover\u0026rsquo;s success probability is small even when we are reduced to the base case, where the verifier can verify himself anyway.\nSo by choosing the modulus \\(q \\ge n^4\\), we have\n\\begin{equation*} \\sum_{i = 1}^{n-1} \\frac{i^2}{q} \\le \\frac{n^3}{q} \\le \\frac{1}{n} \\le \\frac{1}{3}. \\end{equation*}\nAnd that concludes the proof system, since completeness is perfect.\nInteractive Proof System with Public Coins The idea of public coin proof system is brought up fairly earily. In Papadimitriou\u0026rsquo;s 1983 paper, he said \u0026ldquo;We can formulate a decision problem under uncertainty as a new sort of game, in which one opponent is `disinterested\u0026rsquo; and plays at random, while the other tries to pick a strategy which maximizes the probability of winning \u0026mdash; a `game against Nature\u0026rsquo;.\u0026rdquo;\nHis paper included a set of ATM-like defintions.\nBut it is Babai that formalized the concept in the way as we known of today.\nPublic coin can be viewed as a special case of private coin. In private coin, the problem the verifier asks is a function of the private coin. In public coin, the coin is included in the message (or considered public). What the verifier does is essentially just coin-tossing (since the prover can simulate whatever the verifier does). Only after the final round will the verifier decides accept or reject from the previous interaction.\nNotions (in public coin interactive proof system):\nArther verifier (or nature), the one who toss coins Merlin prover According to definition, we have for polynomial \\(k : \\NN \\to \\NN\\)\n\\begin{equation*} \\AM[k(n)] \\subseteq \\IP[k(n)]. \\end{equation*}\nNotations \\(\\MA\\), \\(\\MA\\), \\(\\class{AMA}\\), \\(\\ldots\\) But as the collapse theorem shows, it suffices to consider only \\(\\AM\\) and \\(\\MA\\).\nCollapse Theorem If \\(k(n) \\ge 2\\), we have\n\\begin{equation*} \\AM[k(n) + 1] = \\AM[k(n)]. \\end{equation*}\nWe shall prove the special case when \\(k(n)\\) is a constant.\nLemma. \\(\\MA \\subseteq \\AM\\)\nSuppose \\(L \\in \\MA\\). This means \\(\\forall x \\in L\\), \\(\\exists V\\) such that\n\\begin{equation*} x \\in L \\iff \\exists a \\forall q V(x, q, a) = 1. \\end{equation*}\n(Recall that from Goldwasser-Sisper theorem, we may assume completeness is perfect). Then we can get\n\\begin{equation*} x \\in L \\implies \\forall q \\exists a V(x, q, a) = 1. \\end{equation*}\nNow we need to prove the converse direction to complete the proof. Suppose we have \\(\\forall q \\exists a V(x,q,a) = 1\\), recall that we may assume wlog error probability is less than \\(\\frac{1}{2^n}\\). Then for \\(q \\in \\set{0,1}^{m}\\) and \\(a \\in \\set{0,1}^n\\), we have there exists an \\(a\\) such that \\(V\\) accepts with probability greater than \\(\\frac{2^{m-n}}{2^m} = 2^{-n}\\), and that means \\(x\\in L\\).\nOr we can use the method provided on the slides, showing by relaxing by a factor \\(2^{|a|}\\) from union bound, we are still able to achieve \\(1/3\\) error probability.\nSo by definition, we have \\(\\AM \\subseteq \\class{MAM} \\subseteq \\class{AMM} \\subseteq \\AM\\), indicating \\(\\class{MAM} = \\AM\\), and similarly \\(\\AM = \\class{AMA}\\).\nNotice that our proof only showed that \u0026ldquo;collapsing\u0026rdquo; holds when \\(k\\) is a constant. Actually it also holds when \\(k\\) is a function of \\(n\\).\nBabai and Moran showed in 1988 that \\(\\AM[k(n)] = \\AM[k(n)/2]\\) for \\(k(n) \u0026gt; 2\\).\nPerfect Completeness \\(\\AM\\) has perfect completeness.\nProof. Goldwasser-Sipser Theorem + Shamir Theorem. Though they are skipped in this lecture, we will learn how to prove this result in later lectures.\nCorollary. \\(\\AM \\subseteq \\Pi_2^p\\)\nThis is a natural result from the perfect completeness of \\(\\AM\\). Since\n\\begin{align*} x \\in L \u0026amp;\\implies \\forall q \\exists a V(x,a,q) = 1 \\\\ x \\not\\in L \u0026amp;\\implies \\exists q \\forall a V(x,a,q) = 0. \\end{align*}\nWe thus have\n\\begin{equation*} x \\in L \\iff \\forall q \\exists a V(x,a,q) = 1, \\end{equation*}\nwhich is a \\(\\Pi^p_2\\) type definition.\nTheorem. If \\(\\coNP \\subseteq \\AM\\), then \\(\\PH = \\AM\\)\nProof (informal). From \\(\\NP \\subseteq \\MA^+ = \\MA\\) and the assumption \\(\\coNP \\subseteq \\AM\\), we get \\(\\PH \\subseteq \\AM\\) by induction.\nAs for the details, I think I have come up with two different (but similar) routes to this thoerem.\nProof 1. Consider a \\(\\Sigma_2\\SAT\\) formula \\(\\Psi\\) such that\n\\begin{equation*} \\Psi \\iff \\exists u_1 \\forall u_2 \\phi(u_1, u_2). \\end{equation*}\nFrom the assumption \\(\\coNP \\subseteq \\AM\\) we have the \\(\\coNP\\) formula \\(g(u_1) = \\forall u_2 \\phi(u_1, u_2)\\) is equivalent to \\(\\Pr_q [\\exists a, V(g(u_1), q, a) = 1] \\ge \\frac{2}{3}\\). Then using error reduction and union bound, we have \\(\\Pr_q [\\exists u_1, a, V(g(u_1), q, a) = 1] \\ge \\frac{2}{3}\\), which implies that \\(\\Sigma_2 \\subseteq \\AM\\). Similar to \\(\\BPP\\), \\(\\AM\\) is closed under complement, and that implies that \\(\\Pi_2 \\subseteq \\AM\\), which further implies \\(\\Pi_2 = \\Sigma_2 = \\AM\\). The theorem thus follows.\nProof 2. We use induction in this proof. Assuming \\(\\Sigma_i \\subseteq \\AM\\), we show that \\(\\Sigma_{i+1} \\subseteq \\AM\\).\nConsider the OTM-based defintion: \\(\\Sigma_{i+1} = \\NP^{\\Sigma_i \\SAT}\\). From the induction assumption, we can replace every oracle call by a two round interaction with some prover. We may also let the prover send at the very beginning a certificate, so that the verifier accepts iff. N accepts. So \\(\\Sigma_{i+1} \\in \\AM\\).\nAs for the base case, consider in the previous proof we showed that \\(\\Sigma_2 \\subseteq \\AM\\). This concludes the proof.\nCorollary. If \\(\\lang{GI}\\) is \\(\\NP\\)-complete, then \\(\\PH = \\AM\\).\nProof (informal). If \\(\\lang{GI}\\) is \\(\\NP\\)-complete, then \\(\\lang{GNI}\\) is \\(\\coNP\\)-complete. We will show that \\(\\lang{GNI}\\in\\AM\\), hence \\(\\coNP \\subseteq \\AM\\). Together with the previous theorem, this means the polynomial hierarchy collapses to \\(\\AM\\).\nFrom \\(\\NP \\subseteq \\MA \\subseteq \\AM\\) we can interpret as \\(\\AM\\) and \\(\\MA\\) are randomized analogues of \\(\\NP\\).\nIn \\(\\AM\\) the randomness is announced first In \\(\\MA\\) the randomness comes afterwards Set Lower Bound Protocol In this section we show that for a set \\(S\\) that\nmembership can be efficiently certified size is either \\(\\ge K\\) or \\(\\le \\frac{K}{2}\\) for some constant \\(K\\) we can construct a public-coin proof system that accepts when set is big and rejects with good possibility when set is small. The system uses pairwise independent hash function and the probabilistic method as techniques.\nPairwise Independent Hash Function Let \\(H_{n,k}\\) be a collection of hash functions from \\(\\set{0,1}^n\\) to \\(\\set{0,1}^k\\). We call this collection pairwise independent if\nFor each \\(x \\in \\set{0,1}^n\\) and each \\(y \\in \\set{0,1}^k\\), \\begin{equation*} \\Pr_{h\\sample H_{n,k}}[h(x) = y] = \\frac{1}{2^k} \\end{equation*}\nFor all \\(x, x^{\\prime}\\) with \\(x \\ne x^{\\prime}\\) and for all \\(y, y^{\\prime}\\), \\begin{equation*} \\Pr_{h\\sample H_{n,k}}[h(x) = y \\land h(x^{\\prime}) = y^{\\prime}] = \\frac{1}{2^{2k}}. \\end{equation*}\nEfficient Construction of Hash Function We can use finite-field operation to cut down output length.\nIn particular, we can constuct PIHF \\(H_{n,n}\\) from \\(GF(2^n)\\) by simply picking two field elements and letting \\(h_{a,b} = ax + b\\). If what we want is \\(H_{n,k}\\) with \\(n \u0026gt; k\\), we can cut the output by \\(n-k\\) bits; otherwise, we start with \\(H_{k, k}\\) and pad zeros to the input. It is trivial to show that the pairwise independence property still holds.\nApplication of PIHF Sipser used these functions to prove \\(\\BPP \\in \\Pi_4 \\cap \\Sigma_4\\). (Although I recall that we can actually prover \\(\\BPP \\in \\Pi_2 \\cap \\Sigma_2\\) using this method.) Stockmeyer applied them to set lower bound for the first time. Babai exploited them in the study of Arthur-Merlin protocol. Set Lower Bound Protocol Suppose \\(S\\) is a set whose membership can be certified. The certificate is checked by the verifier.\nThe set lower bound protocol is a public bound protocol. For a set \\(S\\) and a constant \\(K\\). If\n\\(|S| \\ge K\\), verifier will accept with high probability, \\(|S| \\le \\frac{K}{2}\\), verifier will reject with high probability. Motivation Assuming \\(S\\subseteq \\set{0,1}^m\\), \\(2^{k-2} \\le K \\le 2^{k-1}\\), we argue that for a set of \\(\\kappa = O(k)\\) hash functions, the mapped space \\(h_1(S) \\cup \\ldots h_{\\kappa}(S)\\) is able to cover the whole space \\(\\set{0,1}^k\\) if \\(|S| \\ge K\\).\nConsider any \\(y \\in \\set{0,1}^k\\), we have \\(\\Pr_h[h(x) = y] = \\frac{1}{2^k}\\). So\n\\begin{equation*} \\Pr_h[y \\in h(S)] \\ge \\sum_{x\\in S} \\Pr_h[y = h(x)] - \\sum_{x, x^{\\prime} \\in S} \\Pr[y = h(x) \\land y = h(x^{\\prime})] \\ge \\frac{K}{2^k} - \\frac{K^2}{2^{2k}} \\ge \\frac{1}{10}. \\end{equation*}\nSo by setting \\(\\kappa \u0026gt; \\frac{k}{\\log(10/9)}\\) we can get that\n\\begin{equation*} \\Pr_{h_1,\\ldots,h_{\\kappa}}[\\exists y y\\not\\in h_1(S) \\cup h_2(S) \\cup \\ldots \\cup h_{\\kappa}(S)] \u0026lt; 1. \\end{equation*}\nAnd that means there exists a set of hash functions such that the whole space is covered.\nOn the other hand, if \\(|S| \\le \\frac{K}{2\\kappa}\\), then\n\\begin{equation*} \\sum_{i=1}^{\\kappa} |h_i(S)| \\le 2^{k-2}. \\end{equation*}\nThe Protocol We first transform the problem into \\(S^l \\ge K^l\\) or \\(S^l \\le \\frac{K^l}{2^l}\\) for some proper \\(l = O(\\log k)\\) to fit the previous result, and then\nMerlin first sends a group of hash functions \\(h_1\\), \\(h_2\\), \\(\\ldots\\), \\(h_{\\kappa}\\) to Arthur Arthur randomly picks \\(y \\sample \\set{0,1}^k\\) and sends to Merlin Merlin sends back (\\(i\\), \\(x\\), \\(\\pi\\)) such that \\(h_i(x) = y\\) and \\(\\pi\\) proves \\(x\\in S\\). After that, Arthur accepts iff. the test passes.\nProof of \\(\\lang{GNI} \\in \\AM\\) Observe that the set \\(\\set{(H, \\pi)}\\) where \\(H\\) is isomorphic to \\(G_0\\) or \\(G_1\\) is a membership-verifiable set. Then we can apply the previous set lower bound protocol to show \\(\\lang{GNI} \\in \\AM\\).\nBoppana-Hastad-Zachos Theorem Thoerem. If \\(\\lang{GI}\\) is \\(\\NP\\)-complete, then \\(\\Sigma_2 = \\Pi_2\\).\nProof. We can use the previous theorem, since \\(\\lang{GI}\\) is \\(\\NP\\)-complete implies that \\(\\lang{GNI}\\) is \\(\\coNP\\)-complete, and thus \\(\\coNP \\subseteq \\AM\\).\nLecture VIII We discuss public coin versus private coin in this lecture. It is possible that \\(\\IP\\) and \\(\\AM\\) are not so different. Id est, random questions are good questions.\nGoldwasser-Sipser Theorem Thoerem. \\(\\IP[k(n) \\subseteq \\AM[k(n) + 2]\\)\nThis implies for constant round protocol, private coin is essentially public coin.\nThe proof is somewhat complicated. But its kernel is set lower bound protocol. We thus skip this proof.\nTogether with Babai theorem, we have for all constant round interaction proof is included in \\(\\AM\\).\nPublic-Coin versus Private-Coin We shall see from \\(\\IP =\\PSPACE\\) that \\(\\AM = \\IP\\) is unlikely.\nProgramme Checking Checking a program is not testing or verification. Checking is to check what is the probability that the program is correct for some input.\nTo quote words from Blum and Kannan: \u0026ldquo;Checking is concerned with the simpler task of verifying that a given program returns a correct answer on a given input rather than on all inputs. Checking is not as good as verification, but it is easier to do. It is important to note that unlike testing and verification, checking is done each time a program is run.\u0026rdquo;\nAs Prof. Fu mentioned, in this lecture and the same lecture last year, as interesting as program checking sounds, it is somewhat not favoured in the complexity literature, and existing papers on this subject is not too abundant. It is nevertheless a good exercise to show how can we use interactive proof.\nDefinition of Programme Checking A checker for a task T is a P-time probabilistic OTM C that, given a claimed program P for T and an input x, the following statements are valid:\nIf \\(\\forall y, P(y) = T(y)\\), then \\(\\Pr[C^P(x) \\text{ accepts } P(x)] \\ge \\frac{2}{3}\\). If \\(P(x) \\ne T(x)\\), then \\(\\Pr[C^P(x) \\text{ rejects } P(x)] \u0026lt; \\frac{1}{3}\\). The checker C may apply P to a number of randomly chosen inputs before making a decision. So even if \\(P(x) = T(x)\\), the checker may still reject \\(P(x)\\).\nChecker for Graph Non-Isomorphism If \\(P(G_0, G_1)\\) is a program for \\(\\lang{GNI}\\) such that if \\(G_0 \\not\\cong G_1\\) it returns \u0026ldquo;yes\u0026rdquo;, and otherwise it returns \u0026ldquo;no\u0026rdquo;, we can design a checker for this program in the following manner.\nOn input \\(G_0, G_1\\), our checker \\(C^P\\) works as follows:\nQuery \\(P(G_0, G_1\\) If it returns \u0026ldquo;yes\u0026rdquo;, then ask \\(\\P\\) to provide a \\(\\AM\\) proof that prove such statement. If it returns \u0026ldquo;no\u0026rdquo;, we verify its answer in this way. Choose a vertex \\(v_1^0 \\in G_0\\) and \\(v_1^1 \\in G_1\\), and replace \\(v_1^0\\) and \\(v_1^1\\) with \\(K_{n+1}\\) at each two graphs. Then checker then query \\(P\\) on the replaced, \\(2n\\) vertice graphs. If the answer is \u0026ldquo;no\u0026rdquo;, then delete \\(v_1^0\\) and \\(v_1^1\\) and repeat this process to find the next mapping in the reduced graph. If the answer is \u0026ldquo;yes\u0026rdquo;, then try again on \\(v_2^1\\), \\(v_3^1\\), and so on, until the permutation is found. Otherwise, \\(P\\) rejects. It is clear that completeness is perfect, and from the soundness of \\(\\lang{GNI}\\)\u0026rsquo;s AM proof, the error probability can be made \\(2^{-k}\\) by \\(k\\)-time repetition.\nAt this point, the slide page 80 points out that \u0026ldquo;if \\(L\\) has an interactive proof system where the prover can be efficiently implemented using \\(L\\) as an oracle, then \\(L\\) has a checker.\u0026rdquo; If the query result is \\(x\\in L\\), then we can ask the program to prove this statement. However, in the converse case, i.e. \\(x \\not\\in L\\), I have absolute no idea how to ensure \u0026lsquo;soundness\u0026rsquo;. Maybe this slide is skipped for the complexity of its proof.\nThere is a theorem that states \\(\\lang{GI}\\), \\(\\#\\SAT_D\\), and \\(\\lang{TQBF}\\) have checkers.\nChecker for Linear Function Linear function has the nice property that the problem on any input \\(x\\) can be reduced to solving the problem on a sequence of random inputs. We call this property random self-reducibility.\nLipton Theorem Theorem. There is a randomized algorithm that, given an oracle that computes the permanent on \\(1 - \\frac{1}{3n}\\) fraction of the \\(n \\times n\\) matrices on \\(GF(p)\\), can compute the permanents of all matrices on \\(GF(p)\\) correctly with high probability.\nThe idea is once again reduce the problem on one instance to that on other instances. Let\n\\begin{equation*} B(x) = A + xR \\end{equation*}\nwhere \\(R\\) is a random matrix. When \\(x \\ne 0\\) the matrix \\(B\\) is uniformly random, so we can actually query the oracle on \\(n+1\\) distinct, non-zero field elements, to get \\(n+1\\) evaluations, and finally by interpolation, get the evaluation on \\(x = 0\\). The key observation (somewhat reminiscent to arithmetization method) is that the permanent of \\(B(x)\\) is a \\(n\\)-degree polynomial.\nUsing union bound, we get the error probability is at most \\(\\frac{1}{3}\\), which is already good enough.\nAt last, the slide claim that Lipton\u0026rsquo;s algorithm implies a checker for the permanent problem. I have confused myself here a bit. In previous examples, we have used interactive proof system where checker acts as verifier (Arthur) and program acts like prover (Merlin). Permanent has an Interactive Proof system, why bother to use a checker algorithm when we can just ask the program to provide a proof?\n\\(\\IP = \\PSPACE\\) In this chapter, we state and prove the celebrated result \\(\\IP = \\PSPACE\\). Notice that from \\(\\IP \\subseteq \\PSPACE\\) and \\(\\lang{TQBF}\\) being a \\(\\PSPACE\\)-complete problem, all we have to prove is that \\(\\lang{TQBF}\\) has an interactive proof system.\nWe start by showing a slightly weaker version, namely, \\(\\#\\bar{\\SAT}_D \\in \\IP\\).\nArithmetization We can \u0026ldquo;upscale\u0026rdquo; a Boolean formula using arithmetization. Namely, for a 3CNF formula \\(\\phi = \\phi_1 \\land \\phi_2 \\land \\ldots \\land \\phi_m\\) with \\(n\\) literals, we can use the following law to convert this formula into a \\(n\\)-variate, at most \\(3m\\)-degree polynomial over \\(GF(q)\\) by recursively apply the following laws:\n\\(x_i \\to X_i\\) \\(\\neg \\phi \\to 1 - \\Phi\\) \\(\\phi_1 \\land \\phi_2 \\to \\Phi_1 \\cdot \\Phi_2\\) Using De-Morgan\u0026rsquo;s law we can also handel disjunction. The transformation above satisfies that\n\\begin{equation*} \\Phi(b_1, b_2, \\ldots, b_n) = \\phi(b_1, b_2, \\ldots, b_n). \\end{equation*}\nAnd therefore for the counting property, it holds that\n\\begin{equation*} \\sum_{b_1 = 0}^1\\sum_{b_2 = 0}^1 \\ldots \\sum_{b_n = 0}^1 \\Phi(b_1, b_2, \\ldots, b_n) = \\sum_{b_1 = 0}^1\\sum_{b_2 = 0}^1 \\ldots \\sum_{b_n = 0}^1 \\phi(b_1, b_2, \\ldots, b_n). \\end{equation*}\nLet \\(p_{\\phi}(X_1, X_2, \\ldots, X_n) = \\prod_{j=1}^m p_{\\phi_j}(X_1, X_2, \\ldots, X_n)\\) be the arithmetization of \\(\\phi\\). Although the transformation can be done in polynomial time, opening up the brackets would take exponential time (since the expression size is exponential).\nSumcheck Protocol Suppose \\(g(X_1, X_2, \\ldots, X_n)\\) is an \\(d\\)-degree polynomial, \\(K\\) is an integer. We want to prove that\n\\begin{equation*} \\sum_{X_1 = 0}^1 \\sum_{X_2 = 0}^1 \\ldots \\sum_{X_n = 0}^1 g(X_1, X_2, \\ldots, X_n) = K. \\end{equation*}\nWe do so by using the permanent proof like methods. The prover can send to the verifier a polynomial \\(h(X_1)\\) that is supposed to be \\(\\sum_{X_2 = 0}^1 \\ldots \\sum_{X_n = 0}^1 g(X_1, X_2, \\ldots, X_n)\\). Notice that \\(h(x_{1})\\) is compact. After this, the verifier\naborts if \\(h(0) + h(1) \\ne K\\) picks a random field element \\(q\\) and asks the prover to prove \\begin{equation*} \\sum_{X_2 = 0}^1 \\ldots \\sum_{X_n = 0}^1 g(q, X_2, \\ldots, X_n) = h(q). \\end{equation*}\nIn the base case when \\(n = 1\\), the prover simply computes \\(g(0) + g(1)\\), compares it to \\(K\\) and set the result accordingly.\nFact. The above protocol has\nperfect completeness, Soundness error \\(\\le 1 - (1 - \\frac{d}{p})^d\\). The completeness is straightforward. For soundness, observe that in the base case, the prover has perfect soundness. For \\(n\\)-variable formula, consider the case when \\(K\\ne\\sum_{X_1, X_2, \\ldots, X_n g(X_1, X_2, \\ldots, X_n)}\\). The verifier will\nalways reject if \\(h(X)\\) is correct choose a \\(q\\) that satisfies \\(h(q) \\ne \\sum_{X_2,\\ldots,X_n}g(q, X_2, \\ldots, X_n)\\) since there are at most \\(d\\) roots of \\(h(q) - \\sum_{X_2,\\ldots,X_n}g(q, X_2, \\ldots, X_n)\\). from the induction assumption, the probability that verifier rejects is greater than \\((1 - \\frac{d}{q}) (1 - \\frac{d}{q})^{n-1} = (1- \\frac{d}{q})^n\\). Using sumcheck protocol, we can prove \\(\\#\\SAT_D \\in \\IP\\).\nArithmetization for \\(\\lang{TQBF}\\) Recall our goal is to prove \\(\\TQBF \\in \\IP\\). So it is natural to consider how to extend the sumcheck protocol to quantified formulas. One possible way is to replace every existential quantifiers with summation and every forall quantifiers with multipliation. The obvious problem here is that with multiplication, the degree will grow exponentially fast. When the degree is too high, sumcheck will not work.\nFortunately, we have a linearization technique.\nLecture IV We start by picking up the leftovers in the Interactive proof chapter, then start with PCP theorem chapter. I actually find in this lecture that in an interactive proof system, the prover\u0026rsquo;s ability can be unbounded, although \\(\\PSPACE\\) would suffice. That is, in the definition of \\(\\IP\\), there is no restriction on prover\u0026rsquo;s ability, meaning they can be non-uniform or unbounded.\nInteractive Proof System Arithmetization: from boolean formula to arithmetic formula. The variables at value \\(\\set{0,1}\\) is the same. The advantage of such method is bigger field for better verificaiton process.\nThe sumcheck protocol for \\(\\class{TQBF}\\) is actually a modification over the simplified interactive interactive proof system for \\(\\#\\SAT_D\\). The improvement here is that since there are existential and universal quantifiers, we need some tools to bring down the arithmetic polynomial degree. The idea is to use linearization. Since we are only interested in the truth value of the \\(\\class{TQBF}\\) formula \\(\\psi\\), we can limit the equality to \\(0, 1\\). This allows us to use the following arithmetization operators:\n\\(\\exists_{x_i} p \\to 1 - (1 - p_0)(1 - p_1)\\) \\(\\forall_{x_i} p \\to p_0 p_1\\) \\(L_{x_i} p \\to x_i p_1 + (1 - x_i) p_0\\) Together with usual tools for converting \\(x_1 \\land x_2\\) to \\(X_1 \\cdot X_2\\) and \\(\\neg x_1\\) to \\(1 - X_1\\), we can maintain the following invariant (very informal):\nAfter existential or universal operator, the formula is true iff. the polynomial equals to one After linearization operation, the new polynomial is equal to the previous polynomial on \\(0,1\\). So the prover and verifier both convert the formula\n\\begin{equation*} \\psi = \\exists x_1 \\forall x_2 \\exists \\ldots \\exists x_n \\phi(x_1, x_2, \\ldots, x_n) \\end{equation*}\nto formula over some finite field \\(\\FF\\):\n\\begin{align*} p_{\\psi} = \u0026amp;\\exists_{X_1}L_{X_1} \\\\ \u0026amp; \\forall_{X_2} L_{X_1} L_{X_2} \\\\ \u0026amp; \\vdots \\\\ \u0026amp; \\forall_{X_{n-1}} L_{X_1} L_{X_2} \\ldots L_{X_{n-1}} \\\\ \u0026amp; \\exists_{X_n} L_{X_1} L_{X_2} \\ldots L_{X_n} \\\\ \u0026amp; p_{\\phi}(X_1,X_2,\\ldots, X_n). \\end{align*}\nThe prover and verifier proceeds in \\(n^2\\) rounds. In the first round, the prover sends a polynomial \\(s_1(X_1)\\) to the verifier, who then verifies that \\(1 - (1 - s(0))(1 - s(1)) = 1\\), and rejects otherwise. Then the verifier samples \\(r_1 \\sample \\FF\\) and asks the prover to prove the linearization operation is performed correctly.\nThis is done by letting the prover to send another polynomial \\(s_2(X_1)\\) that is meant to be the \u0026ldquo;openup\u0026rdquo; of the expression from right to left, up to \\(\\forall_{X_2}\\). Perhaps this process is better understood when interpreting the operations as operators. The prover sends another polynomial that is \\(p_{\\phi}\\) processed up to the \\(\\forall_{X_2}\\) operator, which will now be a univariate polynomial of degree at most \\(d\\). The verifier then verifies that \\(r_1\\cdot s_2(1) + (1 - r_1) \\cdot s_2(0) = s_1(r_1)\\). After this, the verifier chooses \\(r_3\\sample \\FF\\).\nNotice that in order to prove the operator \\(\\forall_{X_2}\\) is computed correctly, the \u0026ldquo;preimage\u0026rdquo; polynomial is now a bivariate polynomial (in \\(X_1\\) and \\(X_2\\)). But this is not a problem, since what we want to prove is that this process produces a polynomial in \\(X_1\\) that evaluates to \\(s_2(r_3\\) when \\(X_1 = r_3\\). So the verifier sends to the prover the polynomial partially assigned with \\(X_1 = r_3\\). The prover then verifies the polynomial \\(s_3\\) satisfies that \\(s_3(0)\\cdot s_3(1) = s_2(r_3\\). If this is indeed the case, the prover proceeds to sample \\(r_4 \\sample \\FF\\) and asks the prover to prove operator \\(L_{X_1}\\) is computed correctly. Note that this step will incur a new assignment to \\(X_1\\).\nSo The process proceeds inductively as such. In the final step, the prover can verify that without any operators, the polynomial-sized polynomial evaluates indeed to the target value defined by previous interactions. In this step, the verifier has perfect soundness and completeness.\nCompleteness is perfect. For soundness, using a union bound on the event that in some interaction step, the verifier chooses a random field element such that the false polynomial equals to the true polynomial, we conclude that soundness error is at most \\(\\frac{O(n^2 d)}{q}\\). Thus by setting \\(q\\) large enough, we can get small soundness error.\nPCP Theorem [PCP Theorem is] the most important result in complexity theory since Cook\u0026rsquo;s Theorem.\nProof Approaches There are mainly two proofs of PCP theorem.\n1992 Algebraic approach 2006 Combinatorial approach (also the one this book) Views Two ways to view PCP theorem:\nIt is a result about locally testable proof systems. Thus further specifying interactive proof. It is a result about hardness of approximation. Synopsis Approximation Algorithm Two Views of PCP Theorem Equivalence of the Two Views Inapproximability Efficient Conversion of NP Certificate to PCP Proof Proof of PCP Theorem Historical Remark Approximation Algorithms Ever since the discovery of PCP theorem, there has been a surge in the proof of inapproxibility of optimization algorithms.\nWe can characterize the performance of approximation algorithm in the following way. Suppose \\(A\\) is an approximation algorithm for a maximum function \\(f\\), then we \\(A\\) is a \\(\\rho\\)-apprximation (\\(\\rho:\\NN \\to (0,1)\\)) for \\(f\\) if it satisfies for all \\(x\\),\n\\begin{equation*} \\frac{A(x)}{f(x)} \\le \\rho(|x|). \\end{equation*}\nSimilarly, we can define \\(\\rho\\)-approximation for a minimum function \\(g\\) as\n\\begin{equation*} \\frac{g(x)}{A(x)} \\le \\rho(|x|). \\end{equation*}\nThere are some classifications of problems with respect to the approximation feasibility.\nFully Polynomial Time Approxmiation Scheme (FPTAS) A good example is the subset-sum problem. There is a dynamic programming algorithm that runs in exponential time, but for any \\(\\epsilon\\), we have an \\((1 - \\epsilon)\\)-approximation algorithm that runs in \\(O((1 - \\frac{1}{\\epsilon}) \\cdot n^2)\\) time. It is called \u0026ldquo;fully\u0026rdquo; approximatable probably because the inverse of approximation factor only appears as a multiplicative factor.\nPolynomial Time Approximation Scheme (PTAS) Knapsack problem has a similar dynamic programming algorithm (although not good enough). For any \\(\\epsilon\\), one can design a \\((1 - \\epsilon)\\)-approximation scheme that runs in time \\(O((1 - \\frac{1}{\\epsilon}) n^{\\frac{1}{\\epsilon}}\\).\nWe say that KnapSack has a PTAS.\nMax-3SAT A simple algorithm for Max-3SAT can achieve \\(\\frac{1}{2}\\) approximation factor. Simply choose every variable assignment that has better satisfying clauses in each step. We will get in the end at least half of all the satisfying clauses. So a greedy algorithm achieves approximation factor \\(\\frac{1}{2}\\). We say that \\(\\lang{Max-3SAT} \\in \\class{APX}\\).\nThere is some definition that \\( \\class{FPTAS} \\subseteq \\class{PTAS} \\subseteq \\class{APX} \\subseteq \\class{OPT} \\). And under assumption that \\(\\P\\ne\\NP\\) the containments are strict.\nMax-IS and Min-VC By definition, in a \\(m\\) vertex graph, \\(\\lang{Min-VC}\\) + \\(\\lang{Max-IS}\\) = m.\nA simple approximation algorithm for \\(lang{Min-VC}\\) is to pick a remaining edge, include its two vertices, and extend to cover all adjacent edges, and repeat. Its apprxomiation factor is \\(\\frac{1}{2}\\).\nWe will see evidence that refutes the following questions\nIs \\(\\lang{Min-VC}\\) in \\(\\class{PTAS}\\)? Is \\(\\lang{Max-IS}\\) in \\(\\class{APX}\\)? Two Views \\(\\class{MIP} = \\class{NEXP}\\) can be viewed as \u0026ldquo;nondeterminism can be traded with interaction and randomness\u0026rdquo;.\nSuppose \\(L \\in \\NP\\) and \\(x\\) is an input string. The prover provides a proof of polynomial length, the verifier simply samples a random location and then asks the value on that location.\nIn PCP\u0026rsquo;s language, restict query syntax and randomness resources. More specifically, for a language \\(L\\) and \\(q, r : \\NN \\to \\NN\\), we say that \\(L\\) has an (\\(q(n)\\), \\(r(n)\\))-PCP verifier if a \\(\\P\\)-time verifier \\(V\\) exists such that\nEfficiency The verifier is given access to a proof \\(\\pi\\) of length \\(\\le q(n) 2^{r(n)}\\), may toss at most \\(r(n)\\) coins and make at most \\(q(n)\\) non-adaptive queries. Altogether, it runs in polynomial time. Completeness If \\(x\\in L\\), then \\(\\exists \\pi:, \\Pr_r[V^{\\pi}(x) = 1] = 1\\). Soundness If \\(x \\not\\in L\\), then \\(\\forall \\pi, \\Pr_r[V^{\\pi}(x) = 1] \\le \\frac{1}{2}\\). In this definition, there are several points to note.\nIt suffices to consider proof length \\(\\le q 2^r\\).\nThis is simply due to at most this much locations may be queried.\n\\(\\class{PCP}(q, r) \\subseteq \\class{NTIME}(q 2^{O( r)})\\)\nThis is due to we can first guess a proof and then simulate the interaction by counting all accepting \\(r\\)\u0026rsquo;s and make a choice from counting results.\nThere are some results, some are trivial, some are not so trivial and will be proved in this chapter\n\\(\\PCP(0, \\log) = \\P\\) \\(\\PCP(0, \\poly) = \\NP\\) \\(\\PCP(\\log, \\poly) = \\NP\\) \\(\\PCP(\\poly, \\poly) = \\NEXP\\) \\(\\PCP(\\log, \\log) = \\NP\\) \\(\\PCP(\\log, \\log) = \\NP\\) The PCP Theorem When people say the PCP theorem, they are refering to \\(\\PCP(\\log, 1) = \\NP\\).\nIn order to make us familiar with the syntax of PCP proofs (and also to stress that they are in sharp contrast to NP certificates), a simple example is given to show that \\(\\lang{GNI} \\in \\PCP(\\poly, 1)\\). I think this protocol is just a modification of the previous private coin interactive proof system for \\(\\lang{GNI}\\) adapted to the PCP syntax.\nLecture X In this lecture, we learn the other form of PCP theorem \u0026mdash; the hardness of approximation. In addition, we prove the equivalence between the two forms.\nThe PCP is Optimal This statement is kindof like the hierarchy theorem, in the sense that if we choose \\(r = o(\\log(n))\\) and \\(q = o(\\log(n))\\), then \\(\\PCP \\) will collapse to (actually be a strict subset of) \\(\\NP\\). On the other hand, we have the result that \\(\\PCP(\\poly, 1) = \\NEXP\\). So our result is somewhat tight in this sense.\nFirst let\u0026rsquo;s prove that if \\(\\NP \\subseteq \\PCP(o(\\log), o(\\log))\\), then \\(\\P = \\NP\\). Suppose this is indeed the case, on input some \\(x\\), the verifier can enumerate over all possible random coins and query answers to find out whether \\(x\\in L\\) (for some predetermined \\(L\\)) or not. The total time it takes will be polynomial.\nThe other result is not proved during the lecture.\nHardness of Approximation \\begin{theorem}[The PCP theorem (hardness of approximation)] There \\(\\exists \\rho \u0026lt; 1\\) such that for every \\(L \\in \\NP\\) there is a P-time computable function \\(f : L \\to 3\\SAT\\) such that \\begin{align*} x\\in L \u0026amp;\\implies \\func{val}(f(x)) = 1 \\\\ x\\not\\in L \u0026amp; \\implies \\func{val}(f(x)) \u0026lt; \\rho. \\end{align*} \\end{theorem}\nNotice that \\(\\rho\\) is a constant strictly less than one. So we can let \\(L = 3\\SAT\\) and do \u0026ldquo;local error amplification\u0026rdquo; through this method. Even if in the original formula \\(x\\), only one clause is unsatisfiable, the converted formula \\(f(x)\\) will have at least \\((1 - \\rho)\\) portion unsatisfiable.\nThe syntax of this theorem resembles much of CL theorem. But on a closer inspection of the proof of CL theorem, one will see that for input \\(x \\not\\in L\\), it can be the case that \\(\\func{val} = \\frac{m-1}{m}\\) (we adhere to all the computation process, only changing the output from \\(0\\) to \\(1\\)). So this theorem cannot be proved using CL theorem alone.\nTo notice that this flavor of PCP theorem implies the hardness of approximation, we can view the mapping function \\(f\\) in the theorem as a reduction from any language \\(L\\in \\NP\\) to a promise version of \\(\\text{Max-3SAT}\\). If we have a P-time algorithm that gives a ρ-approximation of Max-3SAT, then we can effectively determine any \\(L\\in\\NP\\), indicating \\(\\P = \\NP\\).\nAnother way to phrase this theorem is that ρ-approximaiton algorithm for Max-3SAT is \\NP-hard.\nEquivalence of Two Forms We have to prove the equivalence of the two forms. In order to do this, we introduce a third form, which is a generalization of the hardness of approximation form.\nqCSP Problem \u0026mdash; a generalization to 3SAT If \\(q\\) is a natural number, then a qCSP instance \\(\\phi\\) with \\(n\\) variables is a collection of constraints \\(\\phi_1, \\ldots, \\phi_m : \\set{0,1}^n \\to \\set{0,1}\\) such that for each \\(i \\in [m]\\) the function \\(\\phi_i\\) depends on \\(q\\) of its input locations.\nWe call \\(q\\) the arity of \\(\\phi\\), and \\(m\\) the size of \\(\\phi\\).\nAn assignment \\(u \\in \\set{0,1}^n\\) satisfies a constraint \\(\\phi_i\\) if \\(\\phi_i(u) = 1\\) Let\n\\begin{equation*} \\func{val}(\\phi) = \\max_u \\{ \\frac{\\sum_{i=1}^m\\phi_i(u)}{m}\\}. \\end{equation*}\nWe say that \\(\\phi\\) is satisfiable if \\(\\func{val}(\\phi) = 1\\).\nqCSP is a generalization of 3SAT.\nFrom this definition we can make a couple of observations:\nWe may suppose \\( n \\le qm \\) since abundant literals can be deleted Every formula \\(\\phi\\) can be described using \\(O(m q 2^q \\log (n) \\) bits The simple greedy algorithm for Max-3SAT can be generalized to Max-qCSP and the approximation factor is \\(\\frac{1}{2^q}\\). While the first two observations are very obvious, I have yet find even how to generalize this algorithm. Maybe I will find this solution tomorrow.\nGapCSP Suppose \\(q \\in \\NN\\) and \\(\\rho \\le 1\\), we let ρ-GAPqCSP be the problem that determines a qCSP instance φ whether\nsatisfies that \\(\\func{val}(\\phi) = 1\\) or \\(\\func{val}(\\phi) \u0026lt; \\rho\\). We may say that ρ-GAPqCAP is \\NP-hard if for every \\(L \\in \\NP\\) there exists a P-time function \\(f\\) that satisfies\n\\begin{align*} x \\in L \u0026amp;\\implies \\func{val}(f(x)) = 1, \\\\ x \\not\\in L \u0026amp;\\implies \\func{val}(f(x)) \u0026lt; \\rho. \\end{align*}\nThe intermediate form of PCP theorem states that there exists some \\(\\rho \\in (0,1)\\) such that ρ-GAPqCSP is \\NP-hard. Notice that the second formulation directly implies this one.\nEquivalence Proof First we prove \u0026ldquo;suppose \\(\\NP = \\PCP(\\log, 1)\\)\u0026rdquo;, there exists some \\(\\rho\\) such that ρ-GAPqCSP is \\NP-hard.\nObserve that we can \u0026ldquo;unwrap\u0026rdquo; the randomness of verifier since there is only logarithmatic many bits. So given any \\(L \\in \\NP\\) and \\(x\\), we can first construct the \\PCP verifier \\(V\\) and then using CL theorem, construct a Boolean formula \\(\\phi_i(q) = V(x,q;r=i)\\) such that \\(\\phi_i : \\set{0,1}^q \\to \\set{0,1}\\). By adding all \\(2^{O(\\log)}\\) constraints we can obtain the formula \\(\\phi\\). Completeness guarantees that when \\(x \\in L\\) we have \\(\\func{val}(\\phi) = 1\\) while soundness guarantees that when \\(x \\not\\in L\\), we have \\(\\func{val}(\\phi) \\le \\frac{1}{2}\\).\nAnd then we prove the opposite direction. Suppose there exists some ρ such that ρ-GAPqCSP is \\NP-hard, we want to prove \\(\\NP = \\PCP(\\log, 1)\\).\nThis is also very intuitive. For any \\(L \\in \\NP\\), the verifier can first convert it into an qCSP instance φ, and then randomly choose an index \\(i \\sample [m]\\), finds out what \\(q\\) literals \\(\\phi_i\\) depends on, and query the prover about that \\(q\\)-bits in the assignment. Completeness is guaranteed since if \\(x \\in L\\), \\(f(x)\\) is satisfiable. While soundness error is at most \\(\\rho\\), since for any answer the verifier gives, at most \\(\\rho\\)-portion is satisfied, so the verifier will be caught with \\(1 - \\rho\\) probability.\nWhile the argument is the same to that on the slides and on the textbook, I find it a bit dubious. The randomness \\(i\\) must be private otherwise there is no soundness. So how can we argue the query \\(q\\) does not leak \\(i\\)?\nPerhaps the definition of \\(\\PCP\\) already guarantees that the proof π is \u0026ldquo;committed\u0026rdquo;. The format is \\(V^{\\pi}(x, r)\\) after all.\nFinally we prove the equivalence between the last two views.\nThe hardness of approximating 3SAT directly implies the existence of some ρ-GAPqCSP instance. So we have to prove the converse direction. We can write some q-literal constraint function \\(\\phi_i\\) as the conjunction of at most \\(2^q\\) clauses. If \\(\\phi_i\\) is not satisfied, then at least one of the clauses is not satisfied. So we simply reduced the approximation factor from \\(1 - \\rho\\) to \\(1 - \\frac{\\rho}{2^q}\\).\nLecture XI Onward to the proof of PCP !\nBut actually, we will only be concluding the difference between approximating \\(\\minvc\\) and \\(\\maxis\\) and introducing Fourier Transform over the finite field \\(GF(2^n)\\).\nInapproximability \\minvc and \\maxis are very different from an approximation point of view, as stated by this theorem.\n\\begin{theorem} \\(\\exists \\rho \u0026lt; 1\\) s.t. \\(\\rho\\)-approximation to \\(\\minvc\\) is \\(\\NP\\)-hard. \\(\\forall \\rho \u0026lt; 1\\), \\(\\rho\\)-approximation to \\(\\maxis\\) is \\(\\NP\\)-hard. \\end{theorem}\n\\paragraph{Proof} This theorem relies on the reduction from \\(3\\SAT\\) to \\(\\maxis\\). First of all, the PCP theorem states that there exists \\(\\rho_0\\) such that \\(\\rho_0\\)Gap\\(3\\SAT\\) is \\NP-hard. Using the reduction, we conclude that \\(\\frac{\\rho_0}{7}\\)-approximation for \\(\\maxis\\) is also \\NP-hard. Suppose we have an \\(\\frac{6}{7-\\rho}\\)-approximation algorithm for \\minvc (ρ = \\(\\frac{\\rho_0}{7}\\)), then on this specific graph graph, since \\(|IS| \u0026lt; \\frac{n}{7}\\), we have an\n\\begin{align*} \\frac{n - IS}{n - \\rho IS} \u0026amp;= \\frac{ \\frac{n}{IS} - 1}{ \\frac{n}{IS} - \\rho} \\\\ \u0026amp;\\ge \\frac{6}{7 - \\rho} \\\\ \u0026amp;= \\frac{6}{7 - \\frac{6}{7 - \\rho_0}} \\\\ \u0026amp;= \\frac{42 - 6\\rho_0}{42 - 7\\rho_0} \\\\ \u0026amp;\\ge \\frac{42\\rho_0 - 7\\rho_0^2}{42 - 7\\rho_0} \\\\ \u0026amp;= \\rho_0. \\end{align*}\nThis conclude the first part of the proof. For the second part, we use a \u0026ldquo;performance amplification\u0026rdquo; idea to prove that even if we have a small \\(\\rho^{\\prime}\\)-approximation algorithm for \\maxis, then we can find \\(\\rho\\)-approximation as well.\nFirst of all, for a graph \\(G\\) with maximum-sized independent set \\(IS\\), observe that there exists a constant \\(k \\in \\NN\\) such that \\(\\rho_0 \\binom{ \\abs{IS} }{k} \\ge \\binom{\\rho \\abs{IS} }{k}\\). In order to see this, let \\(k = \\frac{\\log \\rho}{\\log \\rho_0}\\), then \\( \\rho_0 \\binom{ \\abs{IS} }{k} \\approx (\\rho \\abs{IS} )^k \\approx \\binom{\\rho \\abs{IS} }{k}\\).\nDefine a new graph \\(G^k\\) such that its every vertice is a \\(k\\)-subset of \\(G\\) and two nodes \\(S_1\\) and \\(S_2\\) are disconnected iff. \\(S_1 \\cap S_2\\) forms an independent set of \\(G\\). Now we apply the \\(\\rho_0\\)-approximation algorithm to \\(G^k\\), and we claim that from its output, we can collect an independent set of \\(G\\) of size at least \\(\\rho \\abs{IS}\\).\nThe output of \\(\\rho_0\\)-approximation algorithm is at least \\(\\rho_0 \\binom{\\abs{IS}}{k} \\ge \\binom{\\rho \\abs{IS}}{k}\\) nodes. This implies there must be a \\(\\rho\\)-portion of the independent set \\(IS\\) that can be extracted. This concludes the proof.\nFourier Transform over \\(GF(2^{n})\\) In this section we shall see that the three concepts are essentially the same:\nLinear functions \\(\\set{f : \\bit^n \\to \\bit | f(x) + f(y) = f(x + y)}\\) Fourier basis \\(\\chi_S(x) = \\mathop{\\xor}_{i \\in S} x_i\\) Walsh-Hadamard codewords Isomorphism To simplify notations, we consider an isomorphic group \\(\\set{\\pm 1}\\) of \\(GF(2)\\). In that group, XOR operation is replaced with multiplication, \\(0\\) maps to \\(+1\\), and \\(1\\) maps to \\(-1\\).\nHilbert Space We call a linear space defined with inner product a Hilbert Space. In particular, we want to study the \\(2^n\\)-dimensional Hilbert space \\(\\RR^{\\set{\\pm 1}^n}\\). Three operations are defined over this space:\nAddition \\((f + g) (x) = f(x) + g(x)\\) Scalar Multiplication \\((cf)(x) = c f(x)\\) Expectation Inner Product \\( f \\circ g = \\expsub{x \\in \\set{\\pm 1}^n }{f(x)g(x)}\\) The standard orthogonal basis for this space is \\(\\set{ e_x }_{x \\in \\set{\\pm 1}^n}\\). We shall see that fourier basis are also a set of good orthogonal basis for this space.\nFourier Basis We define Fourier Basis \\(\\set { \\chi_{\\alpha} = \\prod_{i \\in \\alpha} x_i : \\alpha \\subseteq [n]}\\). There are three properties about this basis:\nLinearity \\(\\forall \\alpha \\subseteq [n]\\), \\(\\forall x, y \\in \\set{\\pm 1}^n\\), \\(\\chi_{\\alpha}(x)\\chi_{\\alpha}(y) = \\chi_{\\alpha}(x \\cdot y)\\) Unity \\(\\forall \\alpha \\subseteq [n]\\), \\(\\chi_{\\alpha} \\cdot \\chi_{\\alpha} = 1\\) Orthogonal \\(\\forall \\alpha, \\beta\\), \\(\\alpha \\ne \\beta\\), \\(\\chi_{\\alpha} \\circ \\chi_{\\beta} = 0\\) The first property can be proved using \\( \\chi_{\\alpha} (x) \\chi_{\\alpha}(y) = (\\prod_{i \\in \\alpha} x_i \\prod_{i \\in \\alpha} y_i = \\prod_{i \\in \\alpha} x_i y_i = \\chi_{\\alpha} (x \\cdot y)\\).\nThe second property can be proved using the first property. Since \\(\\chi_{\\alpha} \\circ \\chi_{\\alpha} = \\expsub{x}{\\chi_{\\alpha}(x) \\chi_{\\alpha}(x) = \\expsub{x}{\\bf 1}} = 1\\).\nThe third property is commonly refered to as \u0026ldquo;random subsum principle\u0026rdquo;. It can be explained in the following way. WLOG, we can assume there exists a set \\(\\gamma = \\alpha \\setminus \\beta \\ne \\emptyset\\). Fixing any assignment local to β and summing over all other assignments, we would get changes only at \\(\\chi_{\\alpha}\\). And the result would be zero, since the number of odd sums and even sums are equal. So by summing over all possible assignments local to \\(\\gamma\\), we can prove this principle.\nOther Properties Let \\(f = \\hat{f}_{\\alpha} \\chi_{\\alpha}\\), then we have \\(\\hat{f}_{\\alpha} = f \\circ \\chi_{\\alpha}\\) and \\(f \\circ f = \\sum_{\\alpha} \\hat{f}_{\\alpha}^2\\).\nMore on Linearity Suppose some function \\(f : \\set{\\pm 1}^n \\to \\set{\\pm 1}\\) is \u0026ldquo;partially linear\u0026rdquo;, i.e.\n\\begin{equation*} \\Pr_{x, y} [f(x) f(y) = f(x \\cdot y)] \\ge \\frac{1}{2} + \\epsilon, \\end{equation*}\nthe next theorem states that the largest fourier coefficient of \\(f\\) is larger than \\(\\epsilon\\).\n\\paragraph{Proof}. Since \\(f\\) is binary, we have\n\\begin{align*} \\expsub{x, y}{f(x)f(y) f(x\\cdot y)} \\ge 2 \\epsilon. \\end{align*}\nThen by expanding the left term, we get\n\\begin{align*} \\expsub{x, y}{f(x)f(y) f(x\\cdot y)} \u0026amp;= \\expsub{x, y}{\\sum_{\\alpha} \\hat{f}_{\\alpha} \\chi_{\\alpha}(x) \\sum_{\\beta} \\hat{f}_{\\beta} \\chi_{\\beta}(y) \\sum_{\\gamma} \\hat{f}_{\\gamma} \\chi_{\\gamma}(x \\cdot y)} \\\\ \u0026amp;= \\expsub{x,y}{\\sum_{\\alpha, \\beta, \\gamma} \\hat{f}_{\\alpha} \\hat{f}_{\\beta} \\hat{f}_{\\gamma} \\chi_{\\alpha}(x) \\chi_{\\beta}(y) \\chi_{\\gamma}(x) \\chi_{\\gamma}(y) )} \\\\ \u0026amp;= \\sum_{\\alpha, \\beta, \\gamma} \\hat{f}_{\\alpha} \\hat{f}_{\\beta} \\hat{f}_{\\gamma} \\expsub{x}{\\chi_{\\alpha}(x)\\chi_{\\gamma}(x)} \\expsub{y}{\\chi_{\\beta}(y) \\chi_{\\gamma}(y)} \\\\ \u0026amp;= \\sum_{\\alpha} \\hat{f}_{\\alpha}^3 \\\\ \u0026amp;\\le \\max_{\\alpha}{\\hat{f}_{\\alpha}} \\sum_{\\alpha}{\\hat{f}_{\\alpha}^2} \\\\ \u0026amp;= \\max_{\\alpha}{\\hat{f}_{\\alpha}}. \\end{align*}\nThus this concludes this theorem.\nNotice that the converse might not hold.\nimport itertools lst = list(itertools.product([-1, 1], repeat=6)) def maj(x): return (1/2 * x[0] + 1/2 * x[1] + 1/2 * x[2] - 1/2 * x[0] * x[1] * x[2]) def pred(x): a = maj(x[0:4]) * maj(x[3:6]) y = [x[i] * x[i+3] for i in range(3)] b = maj(y) if a == b: return 1 else: return 0 cnt = 0 for x in lst: if pred(x) == 1: cnt += 1 return cnt, cnt / len(lst) 40 0.625 Closeness For two functions \\(f\\), \\(g\\), we call \\(f\\) is \\(\\rho\\)-close to \\(g\\), if \\(\\Pr_x [f(x) = g(x)] \u0026gt; \\rho\\). Notice that if we restrict our attentions to \\(f, g: \\set{\\pm 1}^n \\to \\set{\\pm 1}\\), then it is equivalent to \\(\\expsub{x}{f(x)g(x)} = f \\circ g\u0026gt; 1 - 2\\rho\\). If we set \\(\\rho = \\frac{1}{2} + \\epsilon\\), this would be much clearer. We can further make further observations:\nIf \\(\\Pr_{x, y}[f(x) f(y) = f(x \\cdot y)] \\ge \\frac{1}{2} + \\epsilon\\), then \\(f\\) is \\(2\\epsilon\\)-close to \\(\\chi_{\\alpha}\\), where \\(\\hat{f}_{\\alpha}\\) is \\(f\\)\u0026rsquo;s largest Fourier coefficient. If \\(f, g : \\set{\\pm 1}^n \\to \\set{\\pm 1}\\), and \\(f \\circ g \\ge 2 \\epsilon\\), then we have \\(f\\) and \\(g\\) coincides at \\(\\frac{1}{2} + \\epsilon\\) portion of the input domain. Efficient Conversion of \\(\\NP\\) Certificates to \\(\\PCP\\) Proof In this section we prove that \\(\\NP \\subseteq \\PCP(\\poly, 1)\\). This is a weaker version of the PCP theorem, but its certificate conversion technique makes a good use of the error-amplification capability of Walsh-Hadamard code, and is in nature very useful even in the big proof. So we will study it in this section.\nWalsh-Hadamard Code We first define the Walsh-Hadamard function \\(\\func{WH}(u) : x \\mapsto u \\cdot x\\). This function encodes \\(n\\)-bit strings into a linear function.\nWe say \\(f\\) is a Walsh-Hadamard codeword if \\(f = \\func{WH}(u)\\) for some \\(u\\). Since a linear function\u0026rsquo;s evaluation can be written as \\(f(x) = \\sum_i f(e_i) x_i\\), we conclude that linear functions are exactly Walsh-Hadamard codewords.\nLocal Testing The goal of local testing is to verify whether \\(f\\) is a linear function with constant query complexity. For \\(\\delta \u0026lt; \\frac{1}{2}\\), we define an \\((1 - \\delta)\\)-linearity test such that if a function \\(f\\) is not \\((1 - \\delta)\\)-close to some linear function, then the test rejects with probability \\(\\ge \\frac{1}{2}\\).\nThe test is as follows. Randomly sample \\(x, y\\) and rejects if \\(f(x)f(y) \\ne f(x\\cdot y)\\). Repeat this process for \\(\\frac{1}{\\delta}\\) times, and if all tests pass, accept the input.\nThe error probability of this algorithm is \\(( 1 - \\delta )^{\\frac{1}{\\delta}} \\approx \\frac{1}{e} \u0026lt; \\frac{1}{2}\\).\nLocal Decoding The goal of local decoding is to evaluate \\(f\\) even if we only have a lossy source.\nSuppose \\(f\\) is \\((1 - \\delta)\\)-close (for some \\( \\delta \u0026lt; \\frac{1}{4}\\)) to some linear function \\(g\\), then we can evaluate \\(g(x)\\) by samplying \\(x^{\\prime}\\) at random and output \\(f(x \\cdot x^{\\prime}) f(x^{\\prime})\\). Using a union bound we conclude the error probability is at most \\(1 - 2\\delta\\).\n\\(\\NP \\subseteq \\PCP(\\poly, 1) \\) At this point I realized it is absolutely unnecessary and a waste of time reproducing all the fine details already wonderfully presented in the textbook and slides, so I will be brief in this section.\nThe proof is in three steps, plus a prequisite reduction to \\(\\lang{CKT}\\mbox{-}\\SAT\\). Notice that using arithmetization, we can use a quadratic equation of the form \\(A \\cdot (u \\otimes u) = b\\) to prove the satisfiability of a Boolean circuit.\nSo our \\(\\PCP\\) verifier \\(V^{\\pi }(x) \\) (\\(\\pi = (f, g)\\)) proceeds in the following three steps:\nPerform a \\(1 - \\delta\\) linearity test on \\(f, g\\) Sample \\(x, y \\sample \\bit^n\\) and test \\(f (x) f(y) = g(x \\otimes y)\\) Sample \\(r \\sample \\bit^m\\) and test \\(g(r^T A) = r^T b\\) The first step ensures \\(f, g\\) are indeed WH codewords (say, they encode \\(w\\) and \\(u\\)). The second step verifiers \\(u = w \\otimes w\\). In this step, what we actually do is to verify \\( (w \\otimes w) \\circ (x \\otimes y) = u \\circ (x\\otimes y)\\). If \\(u \\ne w \\otimes w\\), there will be half of the position that this equality will not hold, hence the soundness is \\(\\frac{1}{2}\\). The third step uses a good randomization (hashing) technique. If once again \\( A u \\ne b\\), by selecting a random \\(r\\), \\(Pr_r [r^T (Au + b) = 0] = \\frac{1}{2}\\). Hence the soundness error.\nLecture XII In this lecture Prof. Fu started by reviewing the proof of \u0026ldquo;reduced \\(\\PCP\\) theroem\u0026rdquo;. After that, he began introducing several prequisitives to the actual proof of the \\(\\PCP\\) theorem.\nLocal Testing / Decoding of WH Codeword Recall that with constant random queries, we can perform linearity testing and decoding of Walsh-Hadamard codewords. In particular,\n\\(\\forall \\delta \\in (0,1)\\), we can reject any codeword \\(f\\) that is not \\(1 - \\delta\\)-close to some linear function with probability at least \\(\\frac{1}{2}\\), by making \\(\\frac{1}{\\delta}\\) pairwise-independent queries to \\(f\\). \\(\\forall \\delta \\in (0, \\frac{1}{2})\\), and \\(\\forall x \\in \\bit^n\\), if some codeword \\(f\\) is \\(1 - \\delta\\)-close to some linear function \\(\\hat{f}\\), we can decode \\(\\hat{f}(x)\\) with probability at least \\(1 - 2\\delta\\), by sampling a random \\(x^{\\prime}\\), query \\(f(x^{\\prime})\\) and \\(f(x + x^{\\prime})\\), and finally output \\(f(x^{\\prime}) + f(x^{\\prime} + x)\\). Quadratic Equation in GF2 The satisfiability problem of quadratic boolean equations is \\(\\NP\\)-complete. This can be proved by reducing the \\(\\NP\\)-complete problem \\(\\cktsat\\) to \\(\\quadeq\\). We can introduce a variable for every wire on the circuit, and then translate the circuit gate-by-gate:\n\\(z = \\neg x \\to ZZ + XX = 1\\) \\(z = x \\land y \\to ZZ + XY = 0\\) \\(z = x \\lor y \\to ZZ = 1 - (1 - X)(1- Y) \\iff ZZ + XX + YY + XY = 0\\) It is trivial that the translation is in polynomial time (even in logspace), and the equation is satisfiable if and only if the circuit is satisfiable.\nPrequisitives to PCP The basic idea of \\(\\PCP\\) proof is very simple: gap amplification through random walk. But in order to \u0026ldquo;reduce\u0026rdquo; the problem into graph objects, we need to fiddle with the CSP instances a bit.\nCSP We generalize qCSP to non-binary alphabet (w.l.o.g we denote as \\([W]\\)) as \\(q\\CSP_W\\). And then define the promise version of CSP as \\(\\rho\\)-GAP \\(q\\CSP\\).\nOur goal therefore translates to proving the \\(\\NP\\)-hardness of \\(\\rho\\)-GAP \\(q\\CSP\\) problem for some constant \\(q\\) and \\(\\rho\\).\nCL-Reduction We will be working on CSP instances iteratively, so it is nice to bound the size growth during this process. Let \\(f\\) be a function mapping \\(\\CSP\\) instances into \\(\\CSP\\) instances. We call \\(f\\) a Constant-Linear blowup reduction if the following two conditions hold:\n\\(x\\) is satisfiable iff. \\(f(x)\\) is. \\(\\exists C, W\\) that only depends on the arity and alphabet size of \\(x\\), and \\(f(x)\\) is over a new alphabet \\([W]\\) and has no more than \\(C m\\) constraints (where \\(m\\) is the number of constraints in \\(x\\)). Main Lemma \\begin{lemma} There exist constants \\(q_0 \\ge 3\\) \\(\\epsilon_0 \u0026gt; 0\\) and CL-reduction \\(f\\) such that for every \\(q_0\\CSP\\) instance \\(\\varphi\\) and every \\(\\epsilon \u0026lt; \\epsilon_0\\) \\(f(\\varphi)\\) is a \\(q_0\\CSP\\) instance satisfying \\begin{equation*} \\func{val}(\\varphi) \u0026lt; 1 - \\epsilon \\implies \\func{val}(f(\\varphi)) \u0026lt; 1 - 2 \\epsilon. \\end{equation*} \\end{lemma}\nTo see that this lemma implies the PCP theorem, we can prove the \\(\\NP\\)-hardness of \\(\\epsilon_0\\)-GAP \\(q_0\\CSP\\) by applying the lemma \\(\\log m\\) times. So this lemma will be the main objective of the following three lectures.\nAs we will see, the proof of this lemma proceeds in three steps:\nReduce \\(q_0\\CSP\\) instance to \\(2\\CSP_W\\) instance which is \u0026ldquo;nice\u0026rdquo; Amplify the error of \\(2\\CSP_W\\) instance by introducing a larger alphabet \\(2\\CSP_{W^{\\prime}}\\) Reduce the alphabet size back to \\(2\\) and increase the arity back to \\(q_0\\) Lecture XIII Today, we focus on Step 1 in the proof of PCP theorem.\nI must say Prof. Fu\u0026rsquo;s decision that we should not proceed beyond the prequisitives of Lemma 2 is indeed wise.\nLemma 2 intuitively uses path product\u0026rsquo;s effect to amplify gap.\nDefinition of Nice For any \\(2\\CSP_W\\) instance \\(\\varphi\\), we define its constraint graph \\(G_{\\varphi}\\) by introducing \\(n\\) vertices, and an edge between every two literals in an constraint. A \\(2\\CSP_W\\) instance \\(\\varphi\\) is called \u0026ldquo;nice\u0026rdquo; if\nThere is a constant \\(d\\) such that \\(G_{\\varphi}\\) is a (\\(d\\), \\(0.9\\))-expander. At every vertex half of the edges are self-loops. (Note that we allow parallel edges and self-loops.) Lemma on Connectivity Let \\(G\\) be a \\(d\\)-regular graph with \\(n\\) vertices. Let \\(S\\) be a subset of its vertices and \\(T\\) be its compliment, we have\n\\begin{equation*} \\abs{ E(S, \\bar{S}) } \\ge (1 - \\lambda_G) \\frac{d \\abs{S} \\abs{\\bar{S}}}{n}. \\end{equation*}\nThis can be proved by defining \\(x\\) such that \\( x_i = \\abs{S} \\) where \\(i \\in T\\) and \\( x_i = \\abs{T}\\) where \\(i \\in S\\). It is clear that \\(x \\perp \\one\\) so we can bound \\(x^T A x\\) from Rayleigh quotient.\nThe proof proceeds by considering the value \\(\\sum_{i, j} A_{i, j} (x_i - x_j)^2\\). By definition, only those indices like \\(i \\in S\\) and \\(j \\in T\\) will be summed. So the value equals to \\(\\frac{2 \\abs{ E(S, T) } n^2}{d}\\). But we can also expand this equation and get \\(2 \\norm{x}^2 - 2 x^T A x\\). So we have\n\\begin{align*} \\frac{2 \\abs{ E(S, T) } n^2}{d} \u0026amp;= 2 \\norm{x}^2 - 2x^T A x \\\\ \\frac{2 \\abs{ E(S, T) } n^2}{d} \u0026amp;= 2 (\\abs{S} \\cdot \\abs{T}) n - 2x^T A x \\\\ \\frac{2 \\abs{ E(S, T) } n^2}{d} \u0026amp;\\ge 2 (\\abs{S} \\cdot \\abs{T}) n - 2 (\\lambda_G) (\\abs{S} \\cdot \\abs{T}) n \\\\ \\abs{ E(S, T) } \u0026amp;\\ge (1 - \\lambda_G) \\frac{d \\abs{S} \\abs{T}}{n}. \\end{align*}\nCorollary on Random Edge Suppose \\(G\\) is an expander, we can bound the probability that a random edge will be inside a subset \\(S : \\abs{S} \\le \\frac{n}{2}\\) by \\( \\frac{\\abs{S}}{n} (\\frac{1}{2} + \\frac{\\lambda_G}{2})\\). If we consider the path-product graph \\(G^l\\), then the result will be \\( \\frac{\\abs{S}}{n} (\\frac{1}{2} + \\frac{\\lambda_G^l}{2})\\), which also corresponds to random length \\(l\\) paths in \\(G\\).\nThe proof is very simple. Since we are on a \\(d\\)-regular graph, randomly choosing an edge is equivalent to randomly choose a vertex and then do one-step random walk. So we have\n\\begin{equation*} \\frac{\\abs{S}}{n} = \\Pr_{u, v \\sample E}[ u \\in S \\land v \\in S] + \\Pr_{u, v \\sample E} [u \\in S \\land v \\in T]. \\end{equation*}\nWhere the latter one is bounded by \\(\\frac{\\abs{S}}{n} (\\frac{1}{2} - \\frac{\\lambda_G}{2} )\\), thus proving this corollary.\nTransfigured Instances Since I think it is a waste of time to produce all the fine details which are already well-explained in the textbook and slides, I will only explain my understanding of key components in this proof.\nFirst we reduce the arity to \\(2\\), by enlarging the alphabet to \\(2^{q_0}\\). Now the new assignments can be understood as a \\(q_0\\)-long bit vector. We then introduce \\(m q_0\\) constraints, labelled as \\(\\varphi_{i, j}\\) that checks \\(y_i\\) satisfies the original constraint \\(\\varphi_i\\) and the \\(j^{th}\\) variable in \\(\\varphi_i\\) agrees with the assignment in \\(y_i\\). The size of such constraint is at most \\(2^{q_0 + 1}\\).\nWe would also like to analyze the gap changes through these steps. At this step, since we expand the constraints by \\(q_0\\) times, it holds that the gap deteriorates by at most \\(\\frac{1}{q_0}\\).\nThen we want to make the constraint graph regular. We do so by first finding a family of (\\(d - 1\\), \\(0.9\\))-expander graph family, and replacing every degree-\\(k\\) by \\(G_k\\). We then adds identity constraint to every internal edges, and add one external edge to every new nodes. It is straight forward to argue that the new graph is \\(d\\)-degree and there are \\(2m\\) nodes.\nAt this step, we need to use the expander property to analyze the gap loss. In particular, for any assignment to the \u0026ldquo;node cluster\u0026rdquo; that corresponds to some original variable \\(x_i\\), we define its plurality value as \\(w_i\\). Then let \\(t_i\\) to be the number of nodes in that cluster that disagrees with \\(w_i\\). It is clear that \\(\\sum_i t_i \\le 2m - \\frac{2m}{W}\\). The intuition is when \\(\\sum_i t_i\\) is small enough, then violated external edges will be large enough, whereas otherwise, the expander property will ensure that the violated internal edges will be large enough.\nIn particular, consider the case \\(\\sum_i t_i \\ge \\frac{\\epsilon m }{4}\\). Let \\(S_i\\) be the set of nodes that agrees with \\(w_i\\) and \\(\\bar{S_i}\\) its compliment in that cluster, and define \\(\\abs{S_i } + \\abs{ \\bar{S_i} } = k \\). By the expander property, we know that \\(\\abs{ E(S_i , \\bar{S_i}) } \\ge (1 - \\lambda_G) \\frac{(d - 1) \\abs{S_i} \\abs{\\bar{S_i}} }{k}\\). By definition, we have \\(\\frac{\\abs{S_i}}{k} \\ge \\frac{1}{W}\\). So altogether we have\n\\begin{equation*} \\sum_i \\abs{ E(S_i , \\bar{S_i}) } \\ge 0.1 \\frac{(d - 1) t_i}{W} \\ge \\frac{\\epsilon}{100dW} dm. \\end{equation*}\nOn the other hand, if we have \\(\\sum_i t_i \u0026lt; \\frac{\\epsilon m}{4}\\) then we can lower bound the violated constraints like this. Suppose all edges have the assignment \\(w_i\\), then at least \\(\\epsilon m\\) external edges are violated. By changing at most \\(\\sum_i t_i\\) terms, at most \\(2 \\sum_i t_i \u0026lt; \\frac{\\epsilon m}{2}\\) constrained are altered. Thus we still have at least \\(\\frac{\\epsilon m }{2} \\) violated constraints, which suffices, since \\(\\frac{\\epsilon m }{2 } \u0026gt; \\frac{\\epsilon}{100 dW} dm\\).\nFinally, we need to equip this graph with enough self-loops and make it an expander. We do so by adding \\(2d\\) self-loops at every node and embedding a (\\(n\\), \\(d\\), \\(0.1\\))-expander graph on top. The violated constraints will deterate by at most \\(4\\), and the spectral gap is at most \\(0.1 \\cdot \\frac{1}{4} + \\frac{3}{4} \u0026lt; 0.9\\).\nNotice that all the gap worsening factors only depend on \\(W\\) and \\(d\\), which depends on the arity \\(q_0\\) and is a constant respctively. So regradless of the expression, we can conclude that any loss of this step only depends on the arity \\(q_0\\) (which as we put together all three pieces, will be a constant).\nLecture XIV We cover gap amplification lemma (i.e. Step 2 of the PCP proof) in this lecture. The essense of it seems to be probabilistic method.\nBasic Idea By performing a \\(t\\)-step random walk on the constraint graph, and taking the conjunction of all the constraint edges, we can get roughly the same effect of taking \\(t\\) random edges, and the gap can surely be amplified. But in this way we are increasing the arity. In order to keep the arity at \\(2\\), Dinur\u0026rsquo;s idea is to increase the alphabet by letting a single variable representing the assignment of all \\(d^t\\) old variables (forming a circle / cluster around one variable). But in order to check the old constraints as well as consistency, we need to introduce new constraints, and some probabilistic methods of analyzing the gap amplifaciton effect.\nDetails Consider a \\(2\\CSP_W\\) instance \\(\\varphi\\) and its constraint graph \\(G_{\\varphi}\\). We identify each variable / node by \\(x_i\\) and constraint / edge \\(\\varphi_j(u, v)\\). We then introduce \\(X_i\\) as the assignment of circle of nodes of radius \\(t + \\sqrt{t}\\) from the node \\(x_i\\), with its alphabet \\(W^{d^{5t}}\\) (its a sufficiently large number).\nAs for the constraints, for each length \\(2t + 1\\) path \\(p\\), we place an constraint \\(C_p\\) of the form \\(\\land_{j \\in [t - \\sqrt{t}, t + \\sqrt{t}] } C_p^j\\) where \\(C_p^j\\) is the constraint corresponding to the \\(j^{th}\\) edge on the path, and wht \\(x_j\\) replaced with \\(X_1\\)\u0026rsquo;s claim on \\(x_j\\) and \\(x_{j+1}\\) with \\(X_{2t+2}\\)\u0026rsquo;s claim.\nLecture XV In this lecture we will finish Step 3 of the PCP proof. It is reletively easy to follow.\nThreshold Result by Hastad\u0026rsquo;s 3-Bit \\(\\PCP\\) Theorem This is called \u0026ldquo;threshold\u0026rdquo; result because there exists an \\(\\frac{7}{8}\\)-approximation algorithm for \\(\\maxsat\\). Actually I get a little bit confused at this problem, but then I realized the textbook already had explanations. First of all, by randomly selecting all literals, we can get an algorithm that with overwhelming probability outputs an assignment that satisfies at least a \\(\\frac{7}{8}\\)-portion of the clauses. We can derandomize it in the following ways:\nThe first way is to observe that since \\(\\expect{\\func{val}(\\varphi(x))} = \\frac{7m}{8}\\), we have\n\\begin{equation*} \\expect{\\func{val}(\\varphi(x))} = \\frac{1}{2} \\expect{\\func{val}(\\varphi(x| x_1 = 0))} + \\frac{1}{2} \\expect{\\func{val}(\\varphi(x| x_1 = 1))} \\end{equation*}\nand by checking the clause length, we can compute in polynomial time the condictional expectations, we can conclude that we can iteratively find such an assignment that satisfies at least a \\(\\frac{7}{8}\\) portion of the clauses.\nThe second way is by using \\(3\\)-wise independent hash function. By considering a larger field \\(GF(2^l)\\) where \\(l = \\ceil{ \\log (n) }\\), we can define the hash function \\(f_{a,b,c}(x) = ax^2 + bx + c\\), and then by the property of Vandermont matrix, we have the sequence \\(f(0)\\), \\(f(1)\\), \\(\\ldots\\), \\(f(n - 1)\\) is three-wise independent, and that suffices for the purpose of the distribution over assignment. The expectation claim still works, but since we are working on a polynomial sized sample space, we can do an exhausive search to find such an assignment.\nActually I find this version by scribes from some Oded Goldreich\u0026rsquo;s student. Here is the lecture website.\nFinal Examination All scores are B+? If higher scores are desired, you should give a presentation on Chapter 22.6 and Chapter 22.7. The topic is the proof of Hastad theorem and 22.6 is mandetory.\nLecture XVI What will we cover in this lecture? Cryptography!\nCryptography from a computational complexity perspective, and a strong focus on pseudorandomness.\nIntroduction Modern cryptography is based on computational complexity is a commonly acknowledged fact.\nOne-way function is the foundation of modern cryptography.\nComputationally Secure Encryption Syntax: A pair of algorithms \\(\\enc\\), \\(\\dec\\). The key is considered as an index to the two algorithms. In this syntax, \\(\\enc_k\\) must be injective to ensure correctness.\nShannon\u0026rsquo;s Perfect Secrecy For any two length-equal plaintext, the distributions of their ciphertexts under uniformly random key are identical.\nOne-time pad is one example of perfectly secure encryption.\nThat key length must be longer than message length (i.e. Shannon theorem) is implied by a later lemma.\nNegligible Functions A function \\(\\epsilon : \\NN \\to [0,1]\\) is negligible if\n\\begin{equation*} \\forall c \\exists N \\forall n \\ge N \\epsilon(n) \u0026lt; \\frac{1}{n^c}. \\end{equation*}\nA function is negligible if it goes to 0 faster than any inverse of polynomial functions.\nComputationally Secure Encryption Scheme An encryption scheme (\\(\\enc\\), \\(\\dec\\)) is computationally secure if for any \\(\\P\\)-time PTM \\(A\\) there is a negligible function \\(\\epsilon\\) such that\n\\begin{equation*} \\abs{ \\Pr_{x \\sample \\bit^{m}, k \\sample \\bit^n}[ A(\\enc_{k}(x)) = (i, b) \\land x_i = b] - \\frac{1}{2} } \\le \\epsilon(n). \\end{equation*}\nConditions on the Existence of Computationally Secure Encryption Suppose \\(\\P = \\NP\\)\nSo in conclusion, we must assume \\(\\P \\ne \\NP\\) in cryptography. In fact, we need the existence of OWF in cryptography, which is stronger than \\(\\P \\ne \\NP\\).\nPseudorandom Generator We need to shorten keys. This is done by replacing statistical randomness with computational ones.\nAlthough computational only makes sense if we consider time-resource constrained adversaries.\nSyntax: Let \\(G: \\bit^{*} \\to \\bit^{*}\\) and \\(l : \\NN \\to \\NN\\) be \\(\\P\\)-computable such that \\(l(n) \u0026gt; n\\) for all \\(n\\) for all \\(n\\) and \\(\\abs{G(x)} = l(|x|)\\) for all \\(x \\in \\bit^{*}\\).\n\\(G\\) is a computationally secure PRG of stretch \\(l(n)\\) if for every \\(\\P\\)-time PTM \\(A\\) there exists a negligible function \\(\\epsilon : \\NN \\to [0,1]\\) such that\n\\begin{equation*} \\abs{ \\Pr[A(G(U_n)) = 1] - \\Pr[A(U_{l(n)}) = 1] } \\le \\epsilon(n). \\end{equation*}\nPrior to Yao\u0026rsquo;s notion of PRG, there is another unpredictability notion. Let \\(G\\) and \\(l\\) be as defined above, then we have for all \\(\\P\\)-ime PTM \\(B\\) there is a negligible \\(\\epsilon\\) such that\n\\begin{equation*} \\abs{ \\Pr_{x \\sample \\bit^n, y := G(x), i \\sample [l(n)]} [B(1^n, y_1, \\ldots, y_{i-1}) = y_i] - \\frac{1}{2}} \\le \\epsilon(n). \\end{equation*}\nThe two notions are equivalent.\nApplication: Derandomization If PRG exists, then we can construct subexponential deterministic algorithms for problems in \\(\\BPP\\).\nPseudorandom Function A random function mapping \\(n\\)-bits to \\(n\\)-bits takes \\(n 2^n\\)-bits to describe, and are often very inefficient to compute. We want to find a subset of these functions, so that it has the effect that when randomly picking one from this subset, it has in some sense the same effect as randomly picking from all mapping functions.\nSince the description of a bona fide random function is very large, we have to use oracle Turing machine to capture the indistinguishability by computationally-confined distinguishers.\nThe equivalence between PRG and PRF: the GGM tree.\nPRF Applications CPA Secure encryption Message authentication code: \\(x \\mapsto f_k(x)\\) Lower Bound for Machine Learning Roughly speaking, PRF is not learnable but this does not seem like a useful result. Lecture XVII We try to finish the cryptography chapter this lecture.\nOne-Way Function It seems like OWF takes its definition from that of the unpredictability of PRG. But I think there are still some major differences.\nWe then try to prove the equivalence between PRG and OWF.\nExistence of OWF implies \\(\\P \\ne \\NP\\) The language \\(\\set{ (l, u, y) | \\exists x. f(x) = y \\land l \\le x \\le u } \\in \\NP\\). So if we assume \\(\\P = \\NP\\) then this language is in \\(P\\), which implies we can invert \\(f\\) using binary search.\nThe existence of OWF implies \\(\\P = \\NP\\) implies that to actually prove one-wayness is going to be very hard. Cryptography can only rely on conjectures.\nOWF implies PRG Two theorems.\nOWP implies PRG with polynomial stretch [Yao82] OWF implies PRG with polynomial stretch [HILL99] Since the second theorem has very involved proof, we will only prove the first theorem. Let \\(G(x,r ) = f(x), r, x^T r\\) where \\(f\\) is a one-way permutation.\nGoldreich Levin Theorem The text book uses a three stage proof, each corresponding to increasingly weaker additional assumptions, for pedagogical purpose.\n\\paragraph{Case 1.} The algorithm \\(A\\) can return \\(x^T r\\) for all \\(x\\), \\(r\\). Then we can find \\(x\\) by making \\(n\\) invocations.\nApplication: Tossing Coin Over Phone Alice samples \\(x, r \\sample \\bit^n\\) and sends \\(f(x), r\\) to Bob, where \\(f\\) is an OWP. Bob sends \\(b \\sample \\bit\\) to Alice Alice sends \\(x\\) to Bob Both agree on \\(x^T r \\oplus b\\) Zero Knowledge Proof A zero-knowledge proof system for any \\(L \\in \\NP\\)\nCompleteness prover can convince verifier for all \\(x \\in L\\) Soundness verifier can reject prover for all \\(x \\not \\in L\\) Perfect Zero Knowledge There for all \\(\\P\\)-time PTM verifier \\(P^{*}\\), exists an expected \\(\\P\\)-time PTM \\(S^{*}\\) (the simulator) that for any \\(x \\in L\\) and its certificate, the following holds \\begin{equation*} \\func{out}_{V^{*}}( P(x, u), V^{*}(x) ) \\equiv S^{*}(x). \\end{equation*}\nLecture XVIII This lecture we want to focus on proof complexity.\nThe goal of proof complexity is to prove lower bounds on proof size for tautologies in various proof systems.\nThe most famous lower bound problem is \\(\\P\\) vs. \\(\\NP\\), but it is too hard.\nSo we want to consider lower bound in some restricted models, e.g. proof complexity, circuit lower bound, decision tree, etc.\nTo study proof complexity of a system one takes a look at a special problem instance.\nSynopsis Examples Propositional calculus and resolution Examples There are many examples in the textbook, although Prof. Fu will only introduce one example.\nIn AI and formal verification, we often need to check if a proposition is a tautology. These problems are \\(\\coNP\\)-hard, so they are not believed to have short proofs. (Because most axiomic systems include propositional logic)\n\\paragraph{The Example} Suppose \\(A\\) is an \\(n \\times n\\) integer matrix and \\(b\\) is an \\(n\\)-dimensional integer vector.\nWe want to find a integer solution \\(a\\). We can find the solution set which we denote \\(\\mathcal{H}\\) as it is a Hilbert set, and it has well quasi-order as we define \\(a_1 \\le a_2\\) iff. \\(\\forall i \\in [n] a_1(i) \\le a_2[n]\\).\nSo with regard to \\(A, b\\) we can define its \\(\\mathcal{H}\\) set and its finite.\n\\begin{lemma} \\(\\norm{m}_1 \\le (1 + n \\norm{A}_{\\infty} + n \\norm{b}_{\\infty})^{r+1}\\) where \\(r\\) is the rank of \\(A\\). \\end{lemma}\nWith this lemma, we know the set \\(\\mathcal{H}\\) is polynomial-sized.\nPropositional Calculus and Resolution 命题演算 is propositional calculus.\nOur goal is given a propositional clause \\(\\phi\\), to prove it is a tautology. The idea is to prove \\(\\neg \\phi\\) is a contradiction. So we make it a CNF \\(\\psi\\).\nResolution Suppose \\(\\varphi = C_1 \\land C_2 \\land \\ldots \\land C_m\\), by resolution we mean to extend a sequence \\(C_1 \\land \\ldots \\land C_m \\land C_{m+1} \\land C_{j-1}\\) to \\(C_1 \\land \\ldots \\land C_m \\land C_{m+1} \\land C_{j-1} \\land C_j\\). Where \\(C_j\\) is \\(C^{\\prime} \\lor C^{\\prime\\prime}\\) and\nResolution is both sound and complete, and its length is at most \\(2^{O(n)}\\).\nPigeon Hole Problem 雀（鹊）巢原理，啊，我这里有一杯咖啡。 \u0026mdash; Prof. Fu\nWe restrict our attention to the pigeonhole problem.\nConclusion This lecture concludes the year-long lectures.\nPart I of this textbook introduces classical results on Turing machine.\nIn part II, people focus on more specific compuational models, trying to prove some lower bound results, e.g. circuit complexity, communication complexity, algebaric complexity (an extension to circuit complexity), proof complexity, etc.\nPart III of this textbook mainly focuses on pseudorandomness, although it is rather hard to make further progress. Rick From 2023 says that he witnessed some progress in the UOWHF construction in this year\u0026rsquo;s Eurocrypt by Xinyu Mao, so he would say that certain progress is still possible. So I guess don\u0026rsquo;t lose hope\nComplexity knowledge in the lectures should serve as aids to further investigate theoretical problems in other branches in computer science.\nThe exam lecture should be 90min long.\nI remember Prof. Fu mentioned that this technique is typically used to prove certain abilities can be \u0026ldquo;scaled up\u0026rdquo;, i.e. the ability to solve small scale problems can be used to \u0026ldquo;bootstrap\u0026rdquo; bigger problems. Or in the other direction, small impossibilities can be proved using bigger ones.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nI think diagonalization reveals the inherent limit of a finite machine, and to construct a machine/language is just a way to reveal the contradiction.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nThis is a naive idea, more polished result should be available, but I think reducing the number of tape is a bit meticulous.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"http://localhost:1313/note/comp/","summary":"\u003cp\u003eThis is my notes of the 18-19-1 course ``Computational Complexity\u0026rsquo;'.\u003c/p\u003e\n\u003ch2 id=\"lecture-1-introduction\"\u003eLecture 1: Introduction\u003c/h2\u003e\n\u003ch3 id=\"introduction\"\u003eIntroduction\u003c/h3\u003e\n\u003cp\u003eThis is the lecture note of Prof. Fu\u0026rsquo;s \u003cem\u003eComputational Complexity\u003c/em\u003e (not\nto be confused with the \u003cem\u003eComputational Complexity: Advanced Topics\u003c/em\u003e in\nthe second semester). As Prof. Fu is not following strictly the\nstructure of the book, I consider it necessary to take notes of the\nessential contents taught in the lectures, and subsequently organized\nthem as a series.\u003c/p\u003e","title":"计算复杂性课程笔记"}]