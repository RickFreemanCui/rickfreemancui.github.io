<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="noindex, nofollow">
<title>可证明安全理论笔记 | Hongrui Cui&#39;s Homepage</title>
<meta name="keywords" content="">
<meta name="description" content="BASIC INFORMATION This is the notes of the course ``Provable Security&rsquo;&rsquo;. The first few courses will be taught online. While subsequent courses are still unsettled.
I took this course last year, and I am pretty confident about my grasp of basic concepts like universal hash function, GL theorem, basic PRG, PRF constructions, etc. But contents like CRHF and PRP are still rather alien to me, so in this course I will review the previous contents and try to master the missing pieces.">
<meta name="author" content="崔泓睿">
<link rel="canonical" href="http://localhost:1313/note/provsec/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css" integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z&#43;V9&#43;cO1A=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:1313/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:1313/apple-touch-icon.png">
<link rel="mask-icon" href="http://localhost:1313/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="http://localhost:1313/note/provsec/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
<script type="text/javascript" async
    src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
        MathJax.Hub.Config({
            tex2jax: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']],
                processEscapes: true,
                processEnvironments: true,
                skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
                TeX: {
                    equationNumbers: { autoNumber: "AMS" },
                    extensions: ["AMSmath.js", "AMSsymbols.js"]
                }
            },
            "HTML-CSS": {
                availableFonts: ["Arial", "TeX"],
                preferredFont: "TeX",
                webFont: "TeX"
            }
        });

        MathJax.Hub.Queue(function () {
            
            
            
            var all = MathJax.Hub.getAllJax(), i;
            for (i = 0; i < all.length; i += 1) {
                all[i].SourceElement().parentNode.className += ' has-jax';
            }
        });
    </script>

<style>
    code.has-jax {
        font: inherit;
        font-size: 100%;
        background: inherit;
        border: inherit;
        color: #515151;
    }
</style>


</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:1313/" accesskey="h" title="Hongrui Cui&#39;s Homepage (Alt + H)">Hongrui Cui&#39;s Homepage</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
                <ul class="lang-switch"><li>|</li>
                </ul>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://localhost:1313/misc/" title="Misc">
                    <span>Misc</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/paper/" title="Paper">
                    <span>Paper</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/note/" title="Note">
                    <span>Note</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/talk/" title="Talk">
                    <span>Talk</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/about/" title="About">
                    <span>About</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      可证明安全理论笔记
    </h1>
    <div class="post-meta">崔泓睿

</div>
  </header> 
  <div class="post-content"><h2 id="basic-information">BASIC INFORMATION<a hidden class="anchor" aria-hidden="true" href="#basic-information">#</a></h2>
<p>This is the notes of the course ``Provable Security&rsquo;&rsquo;. The first few courses
will be taught online. While subsequent courses are still unsettled.</p>
<p>I took this course last year, and I am pretty confident about my grasp of basic
concepts like universal hash function, GL theorem, basic PRG, PRF constructions,
etc. But contents like CRHF and PRP are still rather alien to me, so in this
course I will review the previous contents and try to master the missing pieces.
Also it is desireable to incopreate the previous notes and complete the notes
altogegher.</p>
<div class="table-caption">
  <span class="table-number">Table 1:</span>
  Basic Information
</div>
<table>
<thead>
<tr>
<th>TEACHER</th>
<th>郁昱，刘振</th>
</tr>
</thead>
<tbody>
<tr>
<td>LOCATION</td>
<td>陈瑞球楼108</td>
</tr>
<tr>
<td>CODE</td>
<td>C033728200203300M01</td>
</tr>
<tr>
<td>ZOOM NUMBER</td>
<td>284739677</td>
</tr>
<tr>
<td>ZOOM CODE</td>
<td>09333040</td>
</tr>
<tr>
<td>LINK</td>
<td><a href="https://zoom.com.cn/j/284739677">https://zoom.com.cn/j/284739677</a></td>
</tr>
</tbody>
</table>
<h2 id="homework">Homework<a hidden class="anchor" aria-hidden="true" href="#homework">#</a></h2>
<p>This section is dedicated to all homework and exercises throughout the lecture
(along with their solutions of course).</p>
<h3 id="18-19-2-lecture-2">18-19-2 Lecture 2<a hidden class="anchor" aria-hidden="true" href="#18-19-2-lecture-2">#</a></h3>
<ol>
<li>Prove conditional LHL</li>
<li>Non-existence of deterministic randomness extractor</li>
<li>one-time message authentication code</li>
<li>equivalence between min-entropy and collision entropy</li>
</ol>
<p>For solutions please refer to [Homework](#18-19-2 Lecture 2 Homework).</p>
<h3 id="18-19-2-lecture-4">18-19-2 Lecture 4<a hidden class="anchor" aria-hidden="true" href="#18-19-2-lecture-4">#</a></h3>
<ol>
<li>Improving advantage in GL-theorem proof ,i.e. difference between guessing
game (exact preimage) and inverting game (any satisfying preimage).</li>
<li>Exercies 6.1 6.2 6.4 6.6 from KL book</li>
</ol>
<p>Answer can be found in Sec. [Homework](#18-19-2 Lecture 4 Homework).</p>
<h3 id="19-20-2-lecture-2">19-20-2 Lecture 2<a hidden class="anchor" aria-hidden="true" href="#19-20-2-lecture-2">#</a></h3>
<p>Existence of independent code [Lecture 2](#19-20-2 Lecture 2)</p>
<p>For an event \(E\), we use the indicator function</p>
<p>\begin{equation}
I(E) =
\begin{cases}
1 &amp; E\\
0 &amp; \bar{E}
\end{cases}\enspace.
\end{equation}</p>
<p>Fix an \(i\), we bound the probability</p>
<p>\begin{equation}
p = \Pr_{C}[\Pr_{r\leftarrow R_i^m}[Cr = 0] &gt; \frac{1+\zeta}{2^n}]. \end{equation}</p>
<p>First we expand the inner probability expression</p>
<p>\begin{equation}
p = \Pr_C[\frac{1}{\binom{m}{i}} (\sum_{r^{\prime}: |r^{\prime}| =
i}I(Cr^{\prime} = 0)) &gt; \frac{1+\zeta}{2^n}]. \end{equation}</p>
<p>And then we transform the form to facilitate Chebyshev&rsquo;s Inequality. (It is easy
to observe that \(\mathsf{E}_{C}[I(Cr=0)] = \frac{1}{2^n}\).)</p>
<p>\begin{align*}
p &amp;= \Pr_C[(\sum_{r^{\prime}: |r^{\prime}| = i}I(Cr^{\prime} = 0)) -
\frac{\binom{m}{i}}{2^n} &gt; \binom{m}{i} \frac{\zeta}{2^n}] \\
&amp;\le
\Pr_C[\left| (\sum_{r^{\prime}: |r^{\prime}| = i}I(Cr^{\prime} = 0)) -
\frac{\binom{m}{i}}{2^n} \right| &gt; \binom{m}{i} \frac{\zeta}{2^n}] \\
&amp;\le
\frac{\underset{C}{Var}{(\sum_{r^{\prime}: |r^{\prime}| = i}I(Cr^{\prime} = 0))}}
{(\binom{m}{i} {\frac{\zeta}{2^n}})^2}\enspace.
\end{align*}</p>
<p>Notice that for distinct \(r_1\) and \(r_2\), the random variable \(I(C r_1 =
0\) and \(I(C r_2 = 0\) are independent since \(I(C (r_1 - r_2)\) follows the
same distribution as either of them. This means we can further expand the
expression as</p>
<p>\begin{equation}
p \le \frac{ \sum_{r^{\prime}: |r^{\prime}| = i}\underset{C}{Var}{(I(Cr^{\prime}
= 0))}}{(\binom{m}{i} {\frac{\zeta}{2^n}})^2}\enspace.
\end{equation}</p>
<p>Since once \(r\) is fixed, \(I(Cr = 0)\) follows the Bernoulli distribution with
\(\mu = \frac{1}{2^n}\), we can further write the expression as</p>
<p>\begin{align*}~
p &amp;\le \frac{ \binom{m}{i} \mu - \mu^2}{(\binom{m}{i} {\frac{\zeta}{2^n}})^2} \\
&amp;\le \frac{2^n \binom{m}{i}^{-1}}{\zeta^2}\enspace.
\end{align*}</p>
<p>Since \(i \le \frac{k}{2}\) and \(\binom{m}{i} \ge \binom{m}{k/2} \ge
(\frac{m}{k/2})^{k/2}\), we have</p>
<p>\begin{align*}
p &amp;\le \frac{2^{n - \frac{k}{2} \log{\frac{2m}{k}}}}{\zeta^2} \\
&amp;\le \frac{2^{n - \frac{k}{2} \log{\frac{m}{k}} + \frac{\log m}{2}}}
{\zeta^2}\enspace.
\end{align*}</p>
<p>Using a union bound on all possible values of \(i\), we conclude the proof of
this lemma.</p>
<h3 id="19-20-2-lecture-5">19-20-2 Lecture 5<a hidden class="anchor" aria-hidden="true" href="#19-20-2-lecture-5">#</a></h3>
<h4 id="prg-from-lpn">PRG from LPN<a hidden class="anchor" aria-hidden="true" href="#prg-from-lpn">#</a></h4>
<p>Link: [Lecture 5](#19-20-2 Lecture 5)</p>
<p>Following usual LPN conventions, we define the LPN distribution \(LPN_{n,\mu}^m
:= (A, As+e)\), where \(A\leftarrow U_{m\times n}\), \(s\leftarrow U_n\), and \(e
\leftarrow Ber_{\mu}^m\). The (\(n\), \(\mu\), \(m\))-DLPN assumption postulate that for
any probablistic polynomial time distinguisher, the advantage of distinguishing
\(LPN_{n,\mu}^m\) apart from uniform distribution is at most \(\epsilon =
\mathsf{negl}\). We now construct a PRG from (\(n\), \(1/16\), \(m\))-DLPN assumption.</p>
<p>The construction is very simple. On \(4m + n\) bit input, the algorithm \(g\)
produces \(4.2m\) bits of output from the following procedure:</p>
<ol>
<li>Parse the \(4m\) bits of input (denoted as \(r\)) as \(m\) 4-bit blocks, and produce noise \(e\) by taking the logical AND of each block.</li>
<li>Produce first \(m\) bit by \(y_1 = A\cdot s + e\) where \(s\) is the remaining \(n\) bits of input.</li>
<li>Produce the rest \(3.2m\) bits by using the universal hash function \(h\).</li>
</ol>
<p>Note that the matrix \(A\) and hash function \(f\) are both public randomness,
and can be considered as part of both input and output. We prove the
pseudorandomness of output below.</p>
<p>Proof (sketch). We consider the more general case of generating \(\mu = 2^t\)
Bernoulli noise from \(mt\) random bits. The aforementioned sampling algorithm
actually wasted a lot of randomness, which can actually be recycled to
facilitate a positive stretch.</p>
<p><strong>Claim.</strong> The min-entropy of \(r\) conditioned on \(e\) is at least \(mt(1 -
2^{-\Omega{t}})\) except with probability \(e^{-m2^{-t}/3}\).</p>
<p>This can be shown from the following argument. By Chernoff bound, the
probability of \(e\) having more than \(2^{-t+1}m\) ones is at most \(2^{-m
2^{-t}/3}\). Thus, conditioned on this event, at least
\(m(1-2^{-t+1})\log(2^t-1)\) bits of \(r\) are unpredictable. Using the fact
that \(\log(2^t-1) &gt; \log(2^{t(1 - 2\Omega(t))})\) we can conclude that the
conditional min-entropy of \(r\) in this case is at least \(mt(1 -
2^{-\Omega{t}})\).</p>
<p>The rest of the proof follows by a standard hybrid argument. In particular,</p>
<dl>
<dt>Hybrid 1</dt>
<dd>The algorithm \(g\) aborts whenever \(|e| &gt; 2^{-t+1}m\). From the Chernoff bound, the output in this case is statistically close to the real distribution.</dd>
<dt>Hybrid 2</dt>
<dd>Replace hashed output \(h( r)\) with uniform randomness. The output is indistinguishable from Hybrid 1 from Leftover Hash Lemma.</dd>
<dt>Hybrid 3</dt>
<dd>Replace the first part of output by uniform randomness. The output is indistinguishable from Hybrid 2 from Decisional LPN assumption under constant noise rate.</dd>
<dt>Hybrid 4</dt>
<dd>Remove artifitial abort introduced in Hybrid 1. Once again, this is statistically indistinguishable from Hybrid 2. This is also the uniform distribution.</dd>
</dl>
<p>The constants in the aformentioned construction are chosen so that \( m (1 -
2^{-t+1}) \log(2^t-1) &gt; m(t-1) + d\) where \(d = \omega(\log n)\) is an
appropriate entropy loss.</p>
<h4 id="clpn-and-dlpn-equivalence">CLPN and DLPN Equivalence<a hidden class="anchor" aria-hidden="true" href="#clpn-and-dlpn-equivalence">#</a></h4>
<p>Link: [Exercises](#19-20-2 Lecture 5 Exercises) Proof is in the link.</p>
<h3 id="19-20-2-lecture-6">19-20-2 Lecture 6<a hidden class="anchor" aria-hidden="true" href="#19-20-2-lecture-6">#</a></h3>
<p>Levin&rsquo;s Trick: [Exercise: Domain Extension for PRFs](#19-20-2 Lecture 6 Exercises) Proof is in the link.</p>
<h2 id="18-19-2-lecture-2">18-19-2 Lecture 2<a hidden class="anchor" aria-hidden="true" href="#18-19-2-lecture-2">#</a></h2>
<p>In this note, the content of this week&rsquo;s lecture on provable security by
Prof. Yu is summarized, from the handout and my own note taken at the lecture.
Additionally, I will give my answers to the homework given at the end of this
week&rsquo;s handout.</p>
<h3 id="lecture-content">Lecture Content<a hidden class="anchor" aria-hidden="true" href="#lecture-content">#</a></h3>
<p>Several key concepts were introduced in this week&rsquo;s lecture along with their
definitions. These includes \(\varepsilon\) -security of private key encryption
schemes, statistical distance, minimum entropy and unpredictability, randomness
extractor, and leftover hash lemma. The reader might be already familiar with
these concepts, and if that is the case, they should agree with my opinion that
the theory of probability are heavily used in those definition and results.</p>
<p>Anyway, the following is derived from my notes taken during the lecture.</p>
<h4 id="indistinguishability">Indistinguishability<a hidden class="anchor" aria-hidden="true" href="#indistinguishability">#</a></h4>
<p>Indistinguishability and resilience to key recovery attack are the two primary
means to defining the security of a encryption scheme. We define the following
indistinguishability experiment:</p>
<p><a href="/ox-hugo/PrivK.png">privk</a></p>
<p>There are several points to note here:</p>
<ul>
<li>Unlike the indistinguishability experiment in the public key</li>
</ul>
<p>encryption scheme, the adversarial algorithm \(A=(A_1,D)\) here does not output a
state. This is because the adversary&rsquo;s power is unlimited, and therefore (in my
opinion) the decryption algorithm can run the message generation algorithm again
to get all the state information it needs, ergo the state need not to be passed.</p>
<ul>
<li>The advantage of the adversary here is defined as the probability</li>
</ul>
<p>\(\Pr[\mathsf{PrivK}^{eav}_{\mathsf{A,\Pi}}] - 1/2\).</p>
<h4 id="statistical-security">Statistical Security<a hidden class="anchor" aria-hidden="true" href="#statistical-security">#</a></h4>
<p>There are two ways to define statistical security (i.e. \(\varepsilon\) -secure),
and they are equivalent. Note that in the indistinguishability experiment
version of the definition, the probability \[
\Pr[\mathsf{PrivK}^{eav}_{\mathsf{A,\Pi}}] &lt; 1/2 + \varepsilon/2 \] implies \[
1/2 - \varepsilon/2 &lt; \Pr[\mathsf{PrivK}^{eav}_{\mathsf{A,\Pi}}] &lt; 1/2 +
\varepsilon/2.\] This is because if the upper bound of the success probability
is bounded, then the lower bound must follow the same margin. If not, negate the
distinguisher with very low success probability will get an adversary that
breaks the upper bound.</p>
<p>When an encryption scheme achieves \(0\) -security, we say that it is <em>perfectly
secure</em>. Vernam&rsquo;s Cipher (One-time pad) is such a cipher.</p>
<h4 id="statistical-distance--sd">Statistical Distance (SD)<a hidden class="anchor" aria-hidden="true" href="#statistical-distance--sd">#</a></h4>
<p>The definition of statistical distance is as follows: \[ \mathsf{SD}(X,Y)
\overset{\text{def}}{=} 1/2 \sum_x{|\Pr[X=x]-\Pr[Y=x]|}, \]</p>
<p>and we say \(X\) is \(\varepsilon\) -close to \(Y\) if \(\mathsf{SD}(X,Y) &lt;
\varepsilon\).</p>
<p>There is also a lemma about the advantage limit of any distinguisher on two
distributions with limited statistical distance. For random variables \(X\) and
\(Y\) defined over set \(\mathcal{S}\), and for any distinguisher \(\mathsf{D} :
\mathcal{S} \rightarrow \{0,1\}\), we have</p>
<p>\[ \left| \Pr[\mathsf{D}(X)=1]-\Pr[\mathsf{D}(Y)=1] \right| \leq \mathsf{SD}(X,Y). \]
The proof is actually not hard, since the distinguisher \(\mathsf{D}\) is
all-powerful, we can think of it as deterministic, and therefore (w.l.o.g. we
assume \(\Pr[\mathsf{D}(X)=1]\geq\Pr[\mathsf{D}(Y)=1]\))</p>
<p>\begin{align*}
|\Pr[\mathsf{D}(X)=1]-\Pr[\mathsf{D}(Y)=1]| &amp;=
|\sum_{x\in S:\mathsf{D}(x)=1}{\Pr[X=x]-\Pr[Y=x]} |\\
&amp;\leq |\sum_{x\in S:\mathsf{D}(x)=1 \cap S:\Pr[X=x]\geq\Pr[Y=x]} {\Pr[X=x]-\Pr[Y=x]}|\\
&amp;\leq |\sum_{x\in S:\Pr[X=x]\geq\Pr[Y=x]}{\Pr[X=x]-\Pr[Y=x]} |\\
&amp;=\mathsf{SD}(X,Y)\enspace.
\end{align*}</p>
<p>The two inequality holds if and only if the two sets are equal. (The last
equality is a little tricky.)</p>
<p>The statistical distance \(\mathsf{SD}\) is a metric, meaning the following
properties holds:</p>
<ol>
<li>non-negativity</li>
<li>identity of indiscernibles</li>
<li>symmetry</li>
<li>triangle inequality.</li>
</ol>
<p>Statistical distance also has the following additional properties:</p>
<ol>
<li>no greater than 1 (the equality holds if and only if the elements with
positive probability in the two distributions does not intersect.)</li>
<li>replacement: for every function \(f\), it holds that \(\mathsf{SD}(f(X),f(Y))
\leq \mathsf{SD}(X,Y)\). (the equality holds if and only if \(f\) is a bijective
map.)</li>
</ol>
<h4 id="statistical-security-of-otp">Statistical Security of OTP<a hidden class="anchor" aria-hidden="true" href="#statistical-security-of-otp">#</a></h4>
<p>Replacing the key-generation algorithm \(\mathsf{Gen}\) in OTP by an algorithm
\(\mathsf{Gen}^{\prime}\) that draws key according to some distribution
\(\tilde{K}\) that is \(\varepsilon\) -close to \(U_n\) will gives us an encryption
scheme that is \(2\varepsilon\) -secure.</p>
<p>The proof is as follows, fix message \(m_0, m_1 \in \{0,1\}^n\), \(m_0 \neq m_1\).
We have for any distinguisher \(\mathsf{D}\),</p>
<p>\begin{align*}
|\Pr[\mathsf{D}(m_0 \oplus \tilde{K})=1] - \Pr[\mathsf{D}(m_1 \oplus \tilde{K})=1]| &amp;\leq \mathsf{SD}(m_0 \oplus \tilde{K}, m_1 \oplus \tilde{K})\\
&amp;\leq \mathsf{SD}(m_0 \oplus \tilde{K},m_0 \oplus U_n) + \mathsf{SD}(m_1 \oplus
\tilde{K},m_0 \oplus U_n)\\
&amp;\leq \mathsf{SD}(\tilde{K}, U_n) +
\mathsf{SD}(\tilde{K}, U_n)\\
&amp;= 2\varepsilon\enspace.
\end{align*}</p>
<h4 id="unpredictability-and-min-entropy">Unpredictability and Min-Entropy<a hidden class="anchor" aria-hidden="true" href="#unpredictability-and-min-entropy">#</a></h4>
<p>Definition for unpredictability is as follows, a random variable \(X\) is
\(\varepsilon\) -unpredictable if for any algorithm \(A\), we have \(\Pr[A(1^n) = X]
\leq \varepsilon\).</p>
<p>Min-entropy is defined as \[ \mathbf{H}_{\infty}(X)\overset{\text{def}}{=}
-\log(\max_{x\in \mathcal{X}}\Pr[X=x]).\]</p>
<p>There are also average min-entropy and conditional unpredictability definitions.
For joint random variable \((X,Z)\), we say that \(X\) is \(\varepsilon\)
-unpredictable given \(Z\) if for every algorithm \(A\) it holds that
\(\Pr[A(1^n,Z)=X]\leq \varepsilon\). While the average min-entropy of \(X\)
conditioned on \(Z\), denoted by \(\mathbf{H}_{\infty}(X|Z)\), is defined by \[
\mathbf{H}_{\infty}(X|Z) \overset{\text{def}}{=} \mathop{\mathbb{E}}_{z
\leftarrow Z}(\max_{x\in \mathcal{X}} \Pr[X=x|Z=z]). \]</p>
<p>It holds that a random variable \(X\) is \(\varepsilon\) -unpredictable if and only
if its min-entropy \(\mathbf{H}_{\infty}(X) \geq \log(1/\varepsilon)\).</p>
<h4 id="randomness-extractor">Randomness Extractor<a hidden class="anchor" aria-hidden="true" href="#randomness-extractor">#</a></h4>
<p>This part is not covered in the handout, as Prof. Yu added them to his slides
that he personally said &ldquo;specially prepared since so many students showed up in
his class&rdquo;. Therefore, I would not be able to get more detailed content apart
from my notes.</p>
<p>First observe that a key with high min-entropy does not guarantee security. To
see this, observe that if there is a distribution that always output \(0\) on the
first bit, followed by \(n-1\) uniformly random bits. Now, if we use this
distribution as the key distribution in place of the uniform distribution in
OTP, and test it in the indistinguishability experiment, the adversary will
always win, ergo the scheme is completely insecure. We want to have a randomness
extractor, that given input with some min-entropy, gives output that is has some
small statistical distance to the uniform distribution. That is, for a (\(n\),
\(k\), \(m\), \(\varepsilon\))-randomness extractor, if its input is \(n\) -bit long and
has min-entropy of \(k\), the output will be \(\varepsilon\) -close to \(U_m\).
However, even for \(m=1\), \(k=n-1\), such a deterministic extractor does not exist.
In order to see this, for any deterministic extractors, we can get the set
\(S_0:\mathsf{Ext}(x) = 0\) and \(S_1:\mathsf{Ext}(x) = 1\), and w.l.o.g. assume
\(|S_0|\geq|S_1|\). Then consider the distribution on \(\{0,1\}^{n}\) that has
probability \(1/|S_0|\) when \(x\in S_0\) and \(0\) otherwise. The output of the
extractor \(\mathsf{Ext}\) will have \(1/2\) statistical distance from \(U_1\).</p>
<p>And therefore to achieve our goal of randomness extractor, additional
modification must be added. The approach introduced is randomness extractor with
a seed (i.e. universal hash functions).</p>
<h4 id="universal-hash-function-and-leftover-hash-lemma">Universal Hash Function and Leftover Hash Lemma<a hidden class="anchor" aria-hidden="true" href="#universal-hash-function-and-leftover-hash-lemma">#</a></h4>
<p>The definition of universal hash function is as follows. \(\mathcal{H} \subseteq
\{0,1\}^l\rightarrow\{0,1\}^t\) is a family of universal hash function if for any
distinct \(x_1,x_2\in \{0,1\}^l\), it holds that \[
\Pr_{h\overset{\$}{\leftarrow}\mathcal{H}}[h(x_1)=h(x_2)] \leq 2^{-t}.\] For
example, \(\mathcal{H}=\{h_a:h_a(x)\overset{\text{def}}{=}(a \cdot x)_{[t]}\}\) is a
family of universal hash functions, and \(|\mathcal{H}|=2^{l}\).</p>
<p>The leftover hash lemma states that universal hash functions are good randomness
extractors.</p>
<p>For any integers \(d \leq k \leq l\), let \(\mathcal{H} \subseteq
\{0,1\}^l\rightarrow\{0,1\}^{k-d}\) be a family of universal hash functions.
Then, for any random variables \(X\) defined over \(\{0,1\}^l\) with min-entropy no
less than \(k\), it holds that \[ \mathsf{SD}(H(X),U_{k-d}|H) \leq 2^{-d/2-1},\]
where \(H\) is the random variable that is uniformly distributed over all members
of \(\mathcal{H}\).</p>
<p>Prof. Yu skipped the proof at the lecture, but I think he will catch up with
that in the next lecture. Nevertheless, I have read the proof and proved
corollary 3.1 which is a conditional version of leftover hash lemma, and also
the first homework. The key to the proof is to use a Cauchy-Schwartz inequality
to create a quadratic term, which also introduces a square root.</p>
<p>One application of the leftover hash lemma is the privacy amplification.
Prof. Yu also introduced another concept called <em>non-malleable extractor</em>, which
is like \(\forall A,\forall s, A(s) \neq s\), and for \(X\) with min-entropy \(k\), we
have \[ (\mathsf{Ext}(X,U_d), \mathsf{Ext}(X,A(U_d)),U_d)
\overset{\varepsilon}{\approx}(U_m, \mathsf{Ext}(X,A(U_d)),U_d). \] Honestly, I
have not grasped the idea of this definition until now. Maybe I will consult
with others later.</p>
<h3 id="homework-18-19-2-lecture-2-homework">Homework {#18-19-2 Lecture 2 Homework}<a hidden class="anchor" aria-hidden="true" href="#homework-18-19-2-lecture-2-homework">#</a></h3>
<p>The following is my solutions to the four homework problems in handout
#2</p>
<!--list-separator-->
<ul>
<li>
<p>Prove Corollary 3.1 (Conditional Leftover Hash Lemma)</p>
<p>Suppose for integers \(d\leq k \le l\) and
\(\mathcal{H}:\{0,1\}^{l}\to\{0,1\}^{k-d}\) be the same as assumed in leftover
hash lemma (a universal hash function family). For any random variable \((X,Z)\)
where \(X\) is over \(\{0,1\}^l\) with average min-entropy \(\mathbf{H}_\infty(X|Z)
\geq k\) it holds that \[ \mathsf{SD}(H(X),U_{k-d}|H,Z)\le 2^{-d/2-1}\] where \(H\)
is the random variable that is uniformly distributed over all members of
\(\mathcal{H}\).</p>
<p>The proof is as follows. By \(\mathbf{H}_\infty(X|Z) \geq k\), we have that \[
\mathop{\mathbb{E}}_{z \leftarrow Z}(\max_{x\in \mathcal{X}} \Pr[X=x|Z=z]) \le
2^{-k}.\] Now lets analyze the statistical distance (let \(S=\{0,1\}^{k-d}\)),</p>
<p>\begin{align*}
\mathsf{SD}&amp;(H(X),U_{k-d}|H,Z) =
\mathsf{SD}((H(X),H,Z),(U_{k-d},H,Z))\\
&amp;=1/2\cdot\sum_{h\in\mathcal{H},z\in
Z,s\in S}|\Pr[H(X)=s\land H=h\land Z=z]-\Pr[U_{k-d}=s\land H=h\land
Z=z]|\\
&amp;=1/2\cdot\sum_{h\in\mathcal{H},z\in Z,s\in
S}|1/|\mathcal{H}|\cdot(\Pr[h(X)=s|Z=z]\cdot\Pr[Z=z]-1/|S|\cdot\Pr[Z=z])|\\ &amp;=1/2\cdot\sum_{h\in\mathcal{H},s\in
S}|\frac{1}{\sqrt{|\mathcal{H}||S|}}|\cdot|\sum_{z\in
Z}(\frac{\sqrt{|S|}}{\sqrt{|\mathcal{H}|}}\cdot(\Pr[h(X)=s\land
Z=z]-1/|S|\cdot\Pr[Z=z]))|\\
&amp;\leq1/2\cdot\left( \sum_{h\in\mathcal{H},s\in
S}(\sum_{z\in
Z}\Pr[Z=z]^2(\frac{|S|}{|\mathcal{H}|}\Pr[h(X)=s|Z=z]^2-\frac{2\Pr[h(X)=s|Z=z]}{|\mathcal{H}|}+\frac{1}{|S||\mathcal{H}|}))
\right)^{1/2}\\
&amp;=1/2\cdot\left(\sum_{z\in
Z}\Pr[Z=z]^2[(\sum_{h\in\mathcal{H},s\in
S}\frac{|S|}{|\mathcal{H}|}\Pr[h(X)=s|Z=z]^2)-1]\right)^{1/2}\\
&amp;\leq
1/2\cdot\left(\sum_{z\in Z}\Pr[Z=z]^2\cdot\max_{x\in
X}\Pr[X=x|Z=z]\cdot|S|\right)^{1/2}\\
&amp;\leq 2^{-d/2-1}.
\end{align*}</p>
<p>The final inequality relies on the fact that \(\Pr[Z=z]^2\leq\Pr[Z=z]\).</p>
</li>
</ul>
<!--list-separator-->
<ul>
<li>
<p>Non-Existence of Deterministic Randomness Extractor</p>
<p>For any deterministic function \(h:\{0,1\}^n\to\{0,1\}\), define the sets
\(S_0:=\{x|h(x)=0\}\) and \(S_1:=\{x|h(x)=1\}\). Then there must exist a set \(S_b\)
such that \(|S_b|\geq2^{n-1}\). Construct such a distribution that has probability
\(1/|S_b|\) for any element in \(S_b\) and \(0\) for \(S_{1-b}\). The distribution has
min-entropy at least \(n-1\). But applying such input to \(h\) would get result that
has \(1/2\) statistical distance to \(U_1\).</p>
</li>
</ul>
<!--list-separator-->
<ul>
<li>
<p>One-Time Message Authentication Code</p>
<p>We only need to compute the probability that the adversary succeeds. Consider
that such event happens would indicate
\(w_2\cdot(m-m^\prime)=\sigma-\sigma^\prime\), and therefore the adversary can
completely compute \(W_2\). And completely succeeding in getting \(W_2\) would
indicate such an attack is successful. This gives us the crude equivalence of
the two events. The probability of successfully guessing \(W_2\), conditioned on
\(Z\) is at most \(2^n \cdot 2^{-n-t}\), completing the proof.</p>
</li>
</ul>
<!--list-separator-->
<ul>
<li>
<p>Equivalence Between Min-Entropy and Collision Entropy</p>
<p>For random variable \(X\), define the collision probability</p>
<p>\[ \mathsf{CP}(X)\overset{\text{def}}{=}\sum_x{\Pr[X=x]^2}\enspace, \]</p>
<p>and collision entropy</p>
<p>\[ \mathbf{H}_2(X)=-\log(\mathsf{CP}(X))\enspace.\]</p>
<p>Show that for any \(X\) with \(\mathbf{H}_2(X)\geq k\) and any \(0&lt;\delta&lt;1\)
there exists some \(Y\) with \(\mathbf{H}_\infty(Y)\ge k-\log(1/\delta)\)
such that \(\mathsf{SD}(X,Y)\leq \delta\).</p>
<p>First observe that \(\sum_x{\Pr[X=x]^2}\le 2^{-k}\) implies
\(\mathbf{H}_0(X)\ge k\), which implies \(|\mathcal{X}|\ge 2^k\) (the
sample space). Then define the set \(S:=\{x|\Pr[X=x]\le 1/\delta \cdot
2^{-k}\}\). Define the distribution \(Y\) such that for every \(x\in
\mathcal{X}\setminus S\), \(\Pr[Y=x]=1/\delta \cdot 2^{-k}\).  And
distribute the difference between \(X\) in to the values \(x\in S\) on top
of \(\Pr[X=x]\) while keeping \(\Pr[Y=x]\le 1/\delta\cdot 2^{-k}\). This
is possible since \(|\mathcal{X}|\ge 2^k\). The resulting distribution
will have statistical distance less than \(\delta\).</p>
</li>
</ul>
<h2 id="18-19-2-lecture-3">18-19-2 Lecture 3<a hidden class="anchor" aria-hidden="true" href="#18-19-2-lecture-3">#</a></h2>
<p>In this note, the content of this week&rsquo;s lecture on provable security by
Prof. Yu is summarized, from the handout and my own note taken at the lecture.
Additionally, I will try to prove the equivalence of semantic security and
indistinguishability here.</p>
<h3 id="lecture-content">Lecture Content<a hidden class="anchor" aria-hidden="true" href="#lecture-content">#</a></h3>
<p>As some important proofs were skipped in the last lecture, the lecture started
by explaining the proof of the leftover hash lemma in the second handout. The
rest of the lecture continued on the computational approach to modern
cryptography (computational complexity based approach), and introduced very
important concepts like pseudorandom generator, replacement lemma, and hybrid
argument. The lecture ended right after hybrid argument was introduced and
explained in detail.</p>
<h4 id="proof-of-leftover-hash-lemma">Proof of Leftover Hash Lemma<a hidden class="anchor" aria-hidden="true" href="#proof-of-leftover-hash-lemma">#</a></h4>
<p>Recall that the leftover hash lemma states that for any integers \(d \leq k \leq
l\), let \(\mathcal{H} \subseteq \{0,1\}^l\rightarrow\{0,1\}^{k-d}\) be a family of
universal hash functions. Then, for any random variables \(X\) defined over
\(\{0,1\}^l\) with min-entropy no less than \(k\), it holds that \[
\mathsf{SD}(H(X),U_{k-d}|H) \leq 2^{-d/2-1},\] where \(H\) is the random variable
that is uniformly distributed over all members of \(\mathcal{H}\).</p>
<p>Informally, the leftover hash lemma states that universal hash function is a
\((l,k,k-d,2^{-d/2-1})\) -randomness extractor. The proof uses Cauchy-Schwartz
inequality, which is quite common in the reductions on lattice, according to
Wenling, since the equality can be achieved (whey the two vectors have the same
direction), and can be easily extended to the complex number field. In my
opinion, the core part of the proof is to analyze the collision probability. The
proof is as follows (for convenience I denote the set \(\{0,1\}^{k-d}\) by \(S\)):</p>
<p>\begin{align*}
\mathsf{SD}&amp;(H(X),U_{k-d}|H) =
\mathsf{SD}((H(X),H),(U_{k-d},H))\\
&amp;=1/2\sum_{s\in\{0,1\}^{k-d},h\in\mathcal{H}}|\Pr[H(X)=s\land H=h]-
\Pr[U_{k-d}=s\land H=h]|\\
&amp;=1/2\sum_{h\in\mathcal{H}}1/|\mathcal{H}|\cdot\sum_{s\in S} |
\Pr[H(X)=s|H=h]-1/|S||\\
&amp;=1/2\sum_{s\in\{0,1\}^{k-d},h\in\mathcal{H}}
\frac{1}{\sqrt{|S||\mathcal{H}|}}
\cdot|\frac{\sqrt{|S|}}{\sqrt{|\mathcal{H}|}}
(\Pr[H(X)=s|H=h]-1/|S|)|\\
&amp;=1/2(\sum_{s\in\{0,1\}^{k-d},h\in\mathcal{H}}
\frac{|S|}{|\mathcal{H}|}
(\Pr[H(X)=s|H=h]^2-2\Pr[H(X)=s|H=h]/|S|+1/|S|^2))^{1/2}\\
&amp;=1/2((\sum_{s\in\{0,1\}^{k-d},h\in\mathcal{H}}
\frac{|S|}{|\mathcal{H}|}
\Pr[H(X)=s|H=h]^2)-1)^{1/2}\\
&amp;=1/2(|S|(\sum_{h\in\mathcal{H}}
\frac{1}{|\mathcal{H}|}\sum_{s\in S}
\Pr[H(X)=s|H=h]^2)-1)^{1/2}
\end{align*}</p>
<p>In this step, we should consider the meaning of the quadratic probability term.
It essentially means the expectation of the probability of two identically
independent variables sampled according to distribution \(X\), after applied to
\(h\in\mathcal{H}\), collides. The expectation is over the uniformly random choice
of \(h\). According to the fact that \(\mathcal{H}\) is a family of universal hash
functions, we can split the probability into two cases.</p>
<ul>
<li>Case 1: \(X_1=X_2\) (we denote the two random variables by \(X_1\) and</li>
</ul>
<p>\(X_2\)). In this case, the collision will always happen.</p>
<ul>
<li>Case 2: \(X_1 \neq X_2\). In this case, by the property of universal</li>
</ul>
<p>hash function, for any \(x_1\neq x_2\), the probability of \(h(x_1)=h(x_2)\) when
applying a uniformly random \(h\leftarrow\mathcal{H}\) is less than \(2^{k-d}\).</p>
<p>For convenience, denote \(\mathbf{Collide}\) the event that such collision happens
(the sample space is \(S\times\mathcal{H}\)), we have</p>
<p>\begin{align*}
\Pr[\mathbf{Collide}] &amp;= \Pr[X_1= X_2]\cdot
\Pr[\mathbf{Collide}|X_1=X_2]+\Pr[X_1\neq X_2]\cdot
\Pr[\mathbf{Collide}|X_1\neq X_2]\\
&amp;\leq \Pr[X_1=X_2]+\Pr[\mathbf{Collide}|X_1\neq X_2]\\
&amp;\leq \sum_{s\in S}\Pr[X_1=s]^2+2^{^{-k+d}}\\
&amp;\leq \max_{s\in S}\Pr[X=s] + 2^{^{-k+d}}\\
&amp;\leq 2^{-k}+2^{-k+d}\enspace.
\end{align*}</p>
<p>Putting this into the previous equation, we have</p>
<p>\begin{align*}
\mathsf{SD}(H(X),U_{k-d}|H) &amp;\leq
1/2 (|S|(\sum_{h\in\mathcal{H}}\frac{1}{|\mathcal{H}|}
\sum_{s\in S}\Pr[H(X)=s|H=h]^2)-1)^{1/2}\\
&amp;=1/2(2^{k-d}(2^{-k}+2^{-k+d})-1)^{1/2}\\
&amp;=2^{-d/2-1}\enspace.
\end{align*}</p>
<p>And that completes the proof.</p>
<!--list-separator-->
<ul>
<li>
<p>Other Points that Arise in the Proof</p>
<p>The above was exactly as explained in the lecture, except for one detail. I
think the probability \(\Pr[X_1=X_2]\) can be enlarged pretty easily by writing it
in the quadratic form and enlarging every term to a probability times the
maximumly possible probability, and nothing is wrong with this notion. However,
in the lecture, a different approach is used. In particular, Prof. Yu first
introduced a lemma concerning random variables. The lemma states that <em>Any X of
min-entropy k can be represented as a convex combination of flat distributions
over sets of size \(2^k\)</em>. The notion written on the blackboard that day was \[ X
= p_1X_1+p_2X_2+\ldots+p_mX_m.\] In the above equation, we have
\(\sum_{i\in[m]}p_i=1\), ergo convex combination. But the idea was that with
probability \(p_i\), \(X\) will take value from random variable \(X_i\). Hanlin
explained to me that this can be treated as breaking the large probability into
smaller ones, and placing them in different distributions. When thinking in this
way, the collision probability can be easily understood. In particular, if all
the \(m\) subsets are the same, the collision probability is exactly \(2^{-k}\).
However, if there is any event in the set that takes probability less than
\(2^{-k}\), the total collision probability will be less than \(2^{-k}\). This can
easily be obtained by observing \((p_1+p_2)^2 \geq p_1^2 +p_2^2\). According to
Hanlin, the convex combination approach is simply a more formal way of stating
this fact.</p>
<p>There is another way of deriving this fact. There is a uniform way of defining
entropy, called Renyi entropy, defined as \[
\text{H}_\alpha(X)=\frac{1}{1-\alpha}\log\left(\sum_{i\in[n]}p_i^\alpha\right).\]
When \(\alpha=0\), we get the max-entropy, which is the logarithmic of the size of
sample space; when \(\alpha \to 1\), we get Shannon Entropy (I have not proved it
myself); when \(\alpha=2\), we get collision entropy, which is exactly what we
need in the previous example; and when \(\alpha \to \infty\), we get min-entropy.
More importantly, for any discrete random variable \(X\) with finite sample space
(I added the constraint myself, since currently I know under such conditions the
fact holds), we have the following relations \[
\text{H}_0(X)\ge\text{H}_1(X)\ge\text{H}_2(X)\ge\ldots\ge\text{H}_\infty(X). \]
The equality holds when \(X\) is uniformly random. From this fact we can easily
derive that in the proof of leftover hash lemma, we have \[
\Pr[X_1=X_2]=2^{-\text{H}_2(X)}\le 2^{-\text{H}_\infty(X)}=2^{-k}. \] And that
is the second way to derive the probability, which seems more natural. In fact,
the requirement on min-entropy in the lemma can be relaxed to requiring the
random variable \(X\) have collision entropy at least \(k\).</p>
</li>
</ul>
<h4 id="privacy-amplification-an-application-of-leftover-hash-lemma">Privacy Amplification: an Application of Leftover Hash Lemma<a hidden class="anchor" aria-hidden="true" href="#privacy-amplification-an-application-of-leftover-hash-lemma">#</a></h4>
<p>The problem setting of privacy amplification is that when the communicating
parties share a secret \(W\), which has some information leaked to an
eavesdropping adversary, which we denote by \(Z\). By a corollary of the leftover
hash lemma, when \(\text{H}_\infty(W|Z)\geq k\), applying a universal hash
function \(\mathcal{H}:\{0,1\}^l\to\{0,1\}^{k-d}\) will get output that is
\(2^{-d/2-1}\) -close to uniform random distribution \(U_{k-d}\), conditioned on \(W\)
and \(H\). And that can be used as good source of randomness (at least it can be
used as key in Vernam&rsquo;s cipher to get statistically-secure encryption). The
process is illustrated in the figure below.</p>
<p><a id="figure--fig:privacy-amp"></a></p>
<figure>
    <img loading="lazy" src="/ox-hugo/PrivacyAmplification.png"
         alt="Figure 2: Privacy Amplification"/> <figcaption>
            <p><span class="figure-number">Figure 2: </span>Privacy Amplification</p>
        </figcaption>
</figure>

<p>However, this scheme is only secure against an <em>eavesdropping</em> only adversary.
An active adversary may temper with the message sent between parties, and easily
make the two parties have inconsistent results. Prof. Yu then mentioned that
using message authentication code, parties can detect message tempering. And
that is also is the third problem of the second lecture&rsquo;s problem set.</p>
<h4 id="one-time-message-authentication-code">One-Time Message Authentication Code<a hidden class="anchor" aria-hidden="true" href="#one-time-message-authentication-code">#</a></h4>
<p>By adding message authentication code (MAC), the receiving party can effectively
detect tempering during the transmission with high probability. The third
problem of the problem set in the previous lecture proposes a MAC scheme when
the two parties share a secret and only use it once (ergo one-time). The scheme
works as follows:</p>
<p><a id="figure--fig:it-mac"></a></p>
<figure>
    <img loading="lazy" src="/ox-hugo/One-TimeMAC.png"
         alt="Figure 3: One-time MAC (IT-MAC)"/> <figcaption>
            <p><span class="figure-number">Figure 3: </span>One-time MAC (IT-MAC)</p>
        </figcaption>
</figure>

<p>The two parties of communication share a \(2n\) bit secret, denoted by
\(W=(W_1,W_2)\), of which some information \(Z\) is leaked to an adversary. The
average min-entropy of \(W\) conditioned on \(Z\) is at least \(n+t\), namely,
\(\text{H}_\infty(W|Z) \ge n+t\). It can be proved that in this scheme, for any
message \(m\), the adversary&rsquo;s success probability \[ \Pr_{(w_1,w_2)\gets W,z\gets
Z}[m^\prime=A(m,\sigma,z):m\ne m^\prime\land\sigma^\prime=w_1+m^\prime\cdot
w_2]\le 2^{-t}. \] However, as Prof. Yu mentioned in his lecture, the
min-entropy of the shared secret is at least \(n+t\) bits, while the constructed
scheme can only guarantee at least \(t\) bit of security (I do not know for sure
such notion is correct, but from the \(\varepsilon\) -secure notion in the
previous lecture I am confident about that). In other words, there is a \(n\) bit
<em>entropy loss.</em> He then stated by using pseudorandomness, such problem can be
solved.</p>
<h4 id="modern-cryptography-computational-approach">Modern Cryptography: Computational Approach<a hidden class="anchor" aria-hidden="true" href="#modern-cryptography-computational-approach">#</a></h4>
<p>The content of the third handout starts from here, meaning the previous contents
focus on perfect or statistical security, which although being secure against
all-mighty adversaries, is utterly inefficient in practice. In particular,
notice that the key space of a perfectly-secure encryption scheme has to be at
least as large as its message space. This means that if we consider the key and
message as binary strings, the key must be at least as long as the message, and
that is obviously ineffective.</p>
<p>The modern approach of cryptography (i.e. the computational-complexity based
approach) resolves this problem by relaxing the notion of security, in
particular, only requiring security against efficient adversaries (since the
asymptotic notion is considered in most cases, this means the advantage of the
adversary ends in time polynomial in the security parameter). In this way, not
only the efficiency can be improved, but also many other interesting and useful
constructions can be built. (Recall that in the first course of Prof. Liu&rsquo;s
<em>Modern Cryptographic Algorithm</em>, it is explained that assuming one-way function
exists, the entire symmetric cryptography can be constructed, e.g. pseudorandom
generator, IND-CPA secure encryption etc.)</p>
<p>The lecture has different focus with the third handout. In particular, the
handout proved several facts concerning the indistinguishability encryption test
in the KL book, namely, any \(\mathsf{PPT}\) adversary cannot guess with
probability better than negligible one bit of the plaintext given the ciphertext
in an indistinguishable encryption scheme. Another fact is one very similar to
semantic security, except that auxiliary information is not considered. Once
again, the Prof. Yu proves in the handout that the indistinguishability
definition implies this semantic security-like definition. But the proof of the
equivalence between indistinguishability and semantic security was not mentioned
in the handout. I think in the lecture all of the above content was gone through
in less than five minutes. The focus here was on
computational-indistinguishability (the more general definition, on any
distributions) and pseudorandom generator (which comes with the first hybrid
argument proof).</p>
<h4 id="computational-indistinguishable-encryptions">Computational Indistinguishable Encryptions<a hidden class="anchor" aria-hidden="true" href="#computational-indistinguishable-encryptions">#</a></h4>
<p>Similar to the definition in the previous lecture, we define the
indistinguishability experiment for private-key encryption scheme \(\Pi =
(\mathsf{Gen},\mathsf{Enc},\mathsf{Dec})​\) with respect to \(\mathsf{PPT}​\)
adversary \(A=(A_1,D)​\) here.</p>
<p><a id="figure--fig:sk-enc2"></a></p>
<figure>
    <img loading="lazy" src="/ox-hugo/PrivK2.png"
         alt="Figure 4: Symmetric Key Encryption Security Experiment"/> <figcaption>
            <p><span class="figure-number">Figure 4: </span>Symmetric Key Encryption Security Experiment</p>
        </figcaption>
</figure>

<p>Note that in this experiment, since \(A\) is not all-mighty, and could use
randomness in \(A_1\), state information (e.g. random coin used) is passed from
\(A_1\) to \(D\). We call the encryption scheme \(\Pi =
(\mathsf{Gen},\mathsf{Enc},\mathsf{Dec})\) has indistinguishable encryptions in
the presence of an eavesdropper if for all \(\mathsf{PPT}\) adversaries \(A\), there
exists a negligible function \(negl(\cdot)\) such that
\(\Pr[\mathsf{PrivK}_{A,\Pi}^{eav}=1]\le 1/2 + negl(\kappa)\), the probability is
over the choice of key \(k\), bit \(b\), randomness used in the encryption, and
randomness used in \(A\). An alternative way of defining this is to state that for
all \(\mathsf{PPT}\) adversaries \(A\), there exists a negligible function
\(negl(\cdot)\) such that
\(\Pr[D(1^\kappa,\mathsf{Enc}_k(m_0),state)=1]-\Pr[D(1^\kappa,\mathsf{Enc}_k(m_1),state)=1]\le
negl(\kappa)\), where \((m_0,m_1,state)\gets A_1(1^\kappa)\). The proof is similar
to the one in the previous lecture. One point to note though, is that in the
previous proof, \(m_0\) and \(m_1\) are arbitrary so long as they are not identical.
This is because the definition considered all possible adversaries, and
therefore it is equivalent to the case when \((m_0,m_1)\gets A_1(1^\kappa)\).</p>
<h4 id="pseudorandom-generator">Pseudorandom Generator<a hidden class="anchor" aria-hidden="true" href="#pseudorandom-generator">#</a></h4>
<p>The definition of pseudorandom generator is as follows. Let \(l(\cdot)\)
be a polynomial and let \(g\) be a deterministic polynomial-time
algorithm such that upon any input \(s\in\{0,1\}^n\), the algorithm \(g\)
outputs a string of length \(l(n)&gt;n\). We say that \(g\) is a pseudorandom
generator (PRG) if for all \(\mathsf{PPT}\) distinguishers \(D\), there
exists a negligible function \(negl(\cdot)\) such that</p>
<p>\[ |\Pr[D(g(U_n)=1)-\Pr[D(U_{l(n)})=1]|\leq \mathsf{negl}(n), \]</p>
<p>where the probability is take over the random coins used by \(D\) and
\(U_n\) (respectively \(U_{l(n)}\)). The difference between the output and
input lengths \(l(n)-n\) is called the stretch factor of \(g\).</p>
<!--list-separator-->
<ul>
<li>
<p>An Alternative Definition of PRG&rsquo;s Security</p>
<p>Prof. Yu then introduced an alternative definition of PRG, namely
\((t,\varepsilon)​\) n-secure PRG. This is similar to the \((t,\varepsilon)​\)
-indistinguishable encryption in the handout. The definition states that if for
any \(\mathsf{PPT}​\) distinguisher \(D​\) of running time at most \(t​\), the advantage
of the distinguisher on \(g(U_n)​\) and \(U_{l(n)}​\) is at most \(\varepsilon​\).
Prof. Yu then mentioned that when setting the parameters \(t=n^{\omega(1)}​\) and
\(\varepsilon=n^{o(1)}​\), the two definitions are equivalent. (Right now I am
convinced that \((t,\varepsilon)​\) -secure implies the previous definition, but
remain skeptical whether it is possible to construct an advantage that becomes
non-negligible when \(t​\) becomes super-polynomial. But this seems not worthy of
pursuing compared to the definitions and hybrid argument to be introduced
later.)</p>
<p>At this point, Prof. Yu mentioned in the lecture (and also in the handout), that
PRG&rsquo;s security is only guaranteed against efficient adversaries. Consider
\(g:\{0,1\}^n\to\{0,1\}^{l(n)}\) as a PRG and an adversary \(D: x\mapsto x\in
g(\{0,1\}^n)\), then the advantage of the adversary is</p>
<p>\begin{align*}
\Pr[D(g(U_n))=1]-\Pr[D(U_{l(n)})=1] &amp;= 1 - |g(\{0,1\}^n)|/2^{l(n)}\\
&amp;\ge 1-2^{n-l(n)}\\
&amp;\ge 1/2\enspace.
\end{align*}</p>
<p>The last inequality holds since the stretch of the PRG is at least \(1\). This
means the distinguisher \(D\) has constant advantage, and therefore the PRG \(g\) is
definitely not secure in this case.</p>
</li>
</ul>
<!--list-separator-->
<ul>
<li>
<p>Replacement Lemma</p>
<p>The \((t,\varepsilon)\) -security of PRG enables a very versatile lemma called
replacement lemma. I remember Prof. Yu mentioned this some afternoon in the lab
the year before. He wrote this on the window of the lab and I remembered he
asked someone to answer that. Anyway, the lemma states that if distribution \(X\)
and \(Y\) is \((t,\varepsilon)\) -indistinguishable, and function \(f\) (defined over
the union of the two distributions&rsquo; sample space) is \(T\) -computable, then the
derived distribution \(f(X)\) and \(f(Y)\) is at least \((t-T,\varepsilon)\)
-indistinguishable.</p>
<p>The proof is actually rather simple. Suppose that the result does not hold, then
by contradiction, there exists a distinguisher \(D\) that runs in time at most
\(t-T\), and distinguishes the two distributions with probability larger than
\(\varepsilon\), namely \[ |\Pr[D(f(X))=1]-\Pr[D(f(Y))=1]|&gt;\varepsilon. \] This
already implies contradiction to the assumption. In order to see this, consider
a distinguisher \(D^\prime(\cdot)=D(f(\cdot))\). This distinguisher will run in
time at most \(t\), but will distinguish \(X\) and \(Y\) with probability greater than
\(\varepsilon\). And therefore the distribution \(f(X)\) and \(f(Y)\) is at least
\((t-T,\varepsilon)\) -indistinguishable.</p>
<p>Note that this lemma can be used to explain the replacement property of
statistical distance. Prof. Yu explained this in brevity but I think I can
elaborate a little here. First consider the equivalent definition of statistical
distance as the maximum advantage among all distinguishers (no constraint on
computational power here), and that could be roughly translated into
\((\infty,\mathsf{SD}(X,Y))\) -indistinguishable. By applying substracting a \(T\)
from the infinity limit of the running time, no actual limit is applied to the
distinguisher. Now, we have when \(\mathsf{SD}(X,Y)\ge \varepsilon\), \(f(X)\) and
\(f(Y)\) are at least \((\infty,\varepsilon)\) -indistinguishable, the advantage of
any distinguishers on these two distributions is at most \(\varepsilon\). By the
fact that the maximum of advantage is just statistical distance, we get
\(\mathsf{SD}(f(X),f(Y)) \le\varepsilon=\mathsf{SD}(X,Y)\).</p>
</li>
</ul>
<h4 id="stretching-the-output-length-of-prg-hybrid-argument">Stretching the Output Length of PRG: Hybrid Argument<a hidden class="anchor" aria-hidden="true" href="#stretching-the-output-length-of-prg-hybrid-argument">#</a></h4>
<p>By sequentially composing PRG to itself, a PRG with small stretch can be
extended to get arbitrarily long pseudorandom bits. This is presented in the
following lemma.</p>
<p>Let</p>
<p>\begin{align*}
g:\{0,1\}^{n}&amp;\to\{0,1\}^{n+s(n)}\\
s_i&amp;\mapsto(s_{i+1},r_{i+1})\enspace,
\end{align*}</p>
<p>where \(s_i,s_{i+1}\in\{0,1\}^n\), \(r_{i+1}\in\{0,1\}^{s(n)}\) be a
\((t(n),\varepsilon(n))\) -secure PRG, and for any \(q(n)\in\mathbb{N}\), define</p>
<p>\begin{align*}
g^q:\{0,1\}^n&amp;\to\{0,1\}^{n+q(n)s(n)}\\
s_0&amp;\mapsto(s_{q(n)},r_{q(n)},r_{q(n)-1},\ldots,r_1)\enspace,
\end{align*}</p>
<p>where for \(0\le i\le q(n)-1\), iteratively compute
\((s_{i+1},r_{i+1}):=g(s_i)\). Then, we have that \(g^{q(n)}\) is a
\((t(n)-q(n)\cdot\mathsf{poly}(n), q(n)\cdot\varepsilon(n))\) -secure PRG, where
\(\mathsf{poly}(n)\) is the running time of computing function \(g\).</p>
<p>The proof of this lemma demonstrated hybrid argument, which is extensively used
in the field of cryptography. And since this is the first time it appears, it is
worthwhile to pay more attention to that. I found that by using replacement
lemma, some of the details of the proof in the handout can be hidden. The
following is my slightly modified proof.</p>
<p>Like in the handout, we define the following distributions (note by placing the
old output in the right hand side, the output of the function can be depicted as
growing to the left, leaving pseudorandom stretches on the right hand side, and
the notion actually aligned the seeds on the left hand side, the blank space on
the right side can be filled with anything, so long as they are identically
distributed, the adjacent two distributions will only have one iteration&rsquo;s
difference. I think this is the intuition behind constructing the series of
distributions, a series of padded mimic snapshots along with the growth of the
pseudorandom bits.)</p>
<p>\begin{align*}
H_0&amp;\overset{\text{def}}{=}g^q(U_n)\\
H_1&amp;\overset{\text{def}}{=}(g^{q-1}(U_n),U_s)\\
H_2&amp;\overset{\text{def}}{=}(g^{q-2}(U_n),U_{2s})\\
&amp;\vdots\\
H_{q-1}&amp;\overset{\text{def}}{=}(g(U_n),U_{(q-1)s})\\
H_{q}&amp;\overset{\text{def}}{=}U_{n+qs}\enspace.\\
\end{align*}</p>
<p>After this, we can observe that for any \(i\in[q]\), the adjacent distributions
\(H_i\) and \(H_{i-1}\) can be derived by applying $g<sup>q-i</sup> to the distribution in
the assumption, namely, \(g(U_n)\) and \(U_{n+s}\), and padding \(U_{(i-1)s}\) to the
right hand side of the random variables. By replacement lemma, \(g(U_n)\) and
\(U_{n+s}\) is \((t,\varepsilon)\) -indistinguishable, then the resulting
distribution is \((t-(q-i)\cdot\mathsf{poly}(n),\varepsilon)\) -indistinguishable,
which implies it is \((t-q\cdot\mathsf{poly}(n),\varepsilon)\) -indistinguishable.
Then by using the triangle inequality, we have for any probabilistic
distinguisher \(D\) with running time no more than \(t-q\cdot\mathsf{poly}(n)\), the
advantage of \(D\) distinguishing $H_0 and \(H_q\) is</p>
<p>\begin{align*}
|\Pr[D(H_0)=1]-\Pr[D(H_q)=1]| &amp;\leq
\sum_{i=1}^q|\Pr[D(H_{i-1})=1]-\Pr[D(H_i)=1]|\\
&amp;\leq q\cdot\varepsilon\enspace,
\end{align*}</p>
<p>and that completes the proof.</p>
<h2 id="18-19-2-lecture-4">18-19-2 Lecture 4<a hidden class="anchor" aria-hidden="true" href="#18-19-2-lecture-4">#</a></h2>
<p>In this note, the content of this week&rsquo;s lecture on provable security by
Prof. Yu is summarized, from the handout and my own note taken at the lecture.
This week&rsquo;s lecture focuses on hardcore predicate of one-way function and
Goldreich-Levin Theorem.</p>
<h3 id="lecture-content">Lecture Content<a hidden class="anchor" aria-hidden="true" href="#lecture-content">#</a></h3>
<p>In this lecture the main focus is on the theoretical construction of
pseudorandom generators. Namely, a lemma concerning hardcore bit of one-way
permutation implies pseudorandom generator (which works the other way as well)
and Goldreich-Levin theorem were introduced. The proof of Goldreich-Levin
theorem uses a concept called list decoding, which is a little mind-blowing for
me. The lecture begins by giving hints on the last homework of the second
lecture.</p>
<h4 id="equivalence-between-min-entropy-and-collision-entropy">Equivalence Between Min-Entropy and Collision Entropy<a hidden class="anchor" aria-hidden="true" href="#equivalence-between-min-entropy-and-collision-entropy">#</a></h4>
<p>In the first ten minute of the lecture, Prof. Yu explained to the class how to
give answer to the fourth question of the homework in the second handout. The
problem is that given a distribution \(X\) with collision-entropy
\(\mathbf{H}_2(X)\geq k\), \(\forall\delta: 0&lt; \delta &lt;1\), it is possible to
construct another distribution \(Y\) such that \(\mathbf{H}_\infty(Y)\geq
k-\log(1/\delta)\), and \(\mathsf{SD}(X,Y)\le \delta\).</p>
<p>The answer to this question is given in the note of lecture 2. I think
Prof. Yu&rsquo;s answer implies that the rest of the set
\(S:=\{x|\Pr[X=x]&gt;1/\delta\cdot2^{-k}\}\) can be ignored in the distribution of
\(Y\). However, I think this will make the question rather disappointing, since
constructing another distribution over the exact sample space of \(X\) seems like
a stronger guarantee. This is why I argued about the upper bound of minimum
probability in the previous answer. This guarantees that when putting the extra
probability to the probability over the set \(S\), there exists an assignment that
does not exceed the maximum probability requirement \(\Pr[Y=x]\le
1/\delta\cdot2^{-k}\).</p>
<p>Another point to note is that the result \(\Pr[X\in S]&lt;\delta\) can be treated as
the result of Markov&rsquo;s inequality. This is because we can treat the collision
probability as the expectation of random variable \(\Pr[X]\), which is no more
than \(2^{-k}\). And ergo the result.</p>
<h4 id="one-way-functions-and-permutations">One-Way Functions and Permutations<a hidden class="anchor" aria-hidden="true" href="#one-way-functions-and-permutations">#</a></h4>
<p>The definition of one-way function here is the same with that given in
Prof. Liu&rsquo;s lecture. Namely, given a function family
\(f:\{0,1\}^{n}\to\{0,1\}^{l(n)}\) is a one-way function ensemble if it is</p>
<ul>
<li>Easy-to-Compute: \(f\) can be computed by some algorithm in time</li>
</ul>
<p>\(\mathsf{poly}(n)\),</p>
<ul>
<li>Hard-to-Invert: for every \(\mathsf{PPT} A\), there exists a negligible</li>
</ul>
<p>function \(negl(\cdot)\) such that \[ \Pr_{X\gets U_n,x^\prime\gets
A(1^n,f(X))}[f(x)=f(x^\prime)]\le negl(n). \]</p>
<p>Despite the similarity, Prof. Yu did argued in the handout that the more formal
definition, where the domain and ranges are arbitrary sets and explicit sampling
algorithms may be needed to sample a random element over the domain.</p>
<!--list-separator-->
<ul>
<li>
<p>An Intuitive Interpretation of Implication</p>
<p>The relationship between one-way function exists (denoted by
\(\mathsf{OWF}\)) and \(\mathcal{P}\ne\mathcal{NP}\) was also mentioned in
the class. \(\mathsf{OWF}\) implies \(\mathcal{P}\ne\mathcal{NP}\), or
written in a more standard form,
\(\mathsf{OWF}\le\mathcal{P}\ne\mathcal{NP}\). In my intuitive opinion,
this can be interpreted as there are two big truth tables with some
entries&rsquo; value unknown. But from some evidence we can conjecture that
they are true. Now the stronger assumption (the one that implies
others) has more entries that are conjectured correct, and the ones
that need to be conjectured correct is only a subset of the first
one. This already explained the first one&rsquo;s conjecture correctness
implies the second one&rsquo;s correctness. What&rsquo;s more, if by
contradiction, an entry of the second one is wrong (contradicting the
assumption), then we can surely say that the first conjecture is not
correct (since all the conjectured entries need to be correct to make
the assumption correct), which also means that the contradicting entry
is more &rsquo;lethal&rsquo; than the other entries outside the subset in the
first assumption. Since finding a more powerful false entry is harder,
this explains why intuitively, the implies sign &lsquo;\(\le\)&rsquo; can be
understood as &ldquo;the hardness is lesser or equal than&rdquo;.</p>
</li>
</ul>
<!--list-separator-->
<ul>
<li>
<p>One-Way Functions based on Different Assuptions</p>
<p>There are different assumption on which one-way functions can be constructed.
Some of them are listed in the handout, they are</p>
<ul>
<li>Integer Factorization,</li>
<li>Subset Sum, and</li>
<li>Discrete Logarithm.</li>
</ul>
<p>The first and third one have been extensively studied and tested in practice.</p>
</li>
</ul>
<h4 id="hard-core-predicates-of-one-way-functions">Hard-core Predicates of One-Way Functions<a hidden class="anchor" aria-hidden="true" href="#hard-core-predicates-of-one-way-functions">#</a></h4>
<p>The definition of hard-core predicate is as follows. A polynomial-time
computable predicate \(h_c:\{0,1\}^n\to \{0,1\}\) is called a hard-core
predicate of a function \(f\) if for every \(\mathsf{PPT}\) algorithm \(A\),
there exists a negligible function \(negl(\cdot)\) such that \[
\Pr_{X\gets U_n}[A(1^n,f(X)=h_c(X)]\leq 1/2+negl(n), \] where the
probability is take over the choice of \(X\) and the random coins of
\(A\).</p>
<p>Note that hard-core predicate exists implies one-wayness. The
following theorem states that for one-way permutations, hard-core
predicates imply the explicit construction of pseudorandom
generators. The theorem is as follows.</p>
<p>If a permutation \(f:\{0,1\}^n\to\{0,1\}^n\) has a hard-core predicate
\(h_c:\{0,1\}^n\to\{0,1\}\), then the function \(g(x) = (f(x),h_c(x))\) is a
pseudorandom generator with a single bit stretch.</p>
<p>The proof given in the handout concerns deterministic distinguisher of
pseudorandomness, and imposes stronger limit to the distinguisher of
pseudorandomness (in that proof if the hard-core predicate is
\((t(n),\varepsilon(n))\) -hard then the output of \(g(\cdot)\) is
\((t(n)/2,\varepsilon(n))\) -indistinguishable from \(U_{n+1}\)). I tried
to improve the proof by concerning \(\mathsf{PPT}\) adversaries and
remove the loss in running time limit. The proof is as follows.</p>
<p>Suppose by contradiction, there is a \(\mathsf{PPT}\) adversary \(A\) of
running time \(t(n)\) that can distinguish pseudorandomness such that</p>
<p>\begin{equation*}
\Pr_{X\gets U_n}[A(f(X),h_c(X))=1]-
\Pr_{X_1\gets U_{n}, X_2\gets U_1}[A(X_1,X_2)=1]&gt;
\varepsilon(n)\enspace.
\end{equation*}</p>
<p>Observe the latter probability can be written as \[
1/2\cdot\Pr[A(X_1,h_c(X_1))] + 1/2\cdot\Pr[A(X_1,1\oplus h_c(X_1))],
\] which means \[ 1/2\cdot\Pr_{X\gets
U_n}[A(f(X),h_c(X))=1]-1/2\cdot\Pr[A(X_1,1\oplus
h_c(X_1))]&gt;\varepsilon(n)\enspace. \] Now construct a \(\mathsf{PPT}\)
algorithm \(D\) that computes the hardcode bit of input, given the
output of the one-way permutation. After \(D\) gets its input \(f(X)\), it
samples a random bit \(b\gets U_1\), and then calls \(A\), and get
\(b^\prime \gets A(f(X),b)\). If \(b^\prime = 1\), output \(b\); else,
output \(1\oplus b\).</p>
<p>The probability that \(D\) succeed is as follows,</p>
<p>\begin{align*}
\Pr_{X,b,r}[\text{D wins}]&amp;=\Pr[b=h_c(X)]\cdot
\Pr[b^\prime=1|b=h_c(X)]+\Pr[b=1\oplus h_c(X)]\cdot
\Pr[b^\prime=0|b=1\oplus h_c(X)]\\
&amp;=1/2\cdot\Pr[A(f(X),h_c(X))=1]+
1/2\cdot(1-\Pr[A(f(X),1\oplus h_c(X))=1])\\
&amp;&gt;1/2 + \varepsilon(n)\enspace.
\end{align*}</p>
<p>And that contradicts the assumption that \(h_c(\cdot)\) is a
(\(t(n)\),\(\varepsilon(n)\))-hard-core predicate for one-way permutation \(f\).</p>
<!--list-separator-->
<ul>
<li>
<p>Reverse Thinking</p>
<p>Note that the previous theorem essentially states that next bit unpredictability
implies pseudorandomness. Actually the result works in the other direction as
well. Namely, for a pseudorandom generator \(g:\{0,1\}^n\to\{0,1\}^{l(n)}\),
\(\forall i \in [l(n)-1]\), \(\forall \mathsf{PPT} A\), there exists a negligible
function \(negl(\cdot)\), such that \[ \Pr_{X\gets
U_n}[A(f(X)_{[1:i]})=f(X)_{[i+1]}] \le 1/2 + negl(n). \] This is actually quite
trivial (which I failed to realize after it was brought up in class, when
Prof. Yu noticed me mumbling, as if I knew how to prove it, but it turned out I
could not present the complete answer). Suppose that there exists some position
\(i\) and a algorithm $A that satisfies the above probability&rsquo;s negation, then for
the construction of pseudorandom distinguisher \(D\), apply the first \(i\) bits of
the input to \(A\) and output \(1\) if the predicted bit equals \(f(X)_{[i+1]}\). The
probability of \(D\) outputting \(1\) in the case of real randomness is \(1/2\), and
in the pseudorandom case, it is \(\Pr_{X\gets
U_n}[A(f(X)_{[1:i]})=f(X)_{[i+1]}]\). It is obvious that the advantage of the
adversary is non-negligible.</p>
</li>
</ul>
<h4 id="universal-construction-of-hard-core-predicates-goldreich-levin">Universal Construction of Hard-Core Predicates: Goldreich-Levin<a hidden class="anchor" aria-hidden="true" href="#universal-construction-of-hard-core-predicates-goldreich-levin">#</a></h4>
<p>Theorem</p>
<p>Digested from the handout, we have &ldquo;It was conjectured that every one-way
function has a hard-core predicate, and this was proven by Goldreich and Levin
in STOC 1989.&rdquo; Prof. Yu mentioned that the creativity of this proof is that it
uses Chebyshev&rsquo;s inequality instead of Chernoff bound, which does not require
all components are independent, but only pairwise independent. And that reduces
the number of guesses needed in the proof, and therefore increases the success
probability as well.</p>
<p>The proof given in the handout is the complete proof, unlike in the KL book,
where the proof is given in steps, first a simplified case, then the full proof.
Prof. Yu did managed to organize the proof in separate independent modules.
There are mainly two techniques in this proof, in my opinion. The first one is
how to use list decoding to convert a couple of guesses of the hard-core bit
into an inversion of the preimage with high probability (\(1/2\) to be specific).
The other one is to use Chebyshev&rsquo;s inequality instead of Chernoff bound, which
could reduce the number of guesses needed, ergo increasing the success
probability of the inversion algorithm.</p>
<p>There is one remaining problem to be solved. I think the number of guesses
\(l=\lceil\log(1+2n/\varepsilon(n)^2)\rceil\) does not guarantees
\(2^{-l}\ge\varepsilon(n)^2/4n\) (although $2<sup>-l</sup>≥ε(n)^2/8n can be
guaranteed).</p>
<p>The proof is as follows. Suppose by contradiction there exists a \(\mathsf{PPT}\)
algorithm \(A\) such that \[ \Pr_{x\gets U_n,r\gets
U_n}[A(f(x),r)=\mathsf{gl}(x,r)]&gt;1/2+\varepsilon(n), \] where the probability is
taken over the choice of \(x, r​\) and the internal random coins of \(A​\). We first
argue there exists a set \(S​\) of size \(|S| \ge \varepsilon(n)/2​\) such that
\(\forall x \in S, \Pr_{r\gets
U_n}[A(f(x),r)=\mathsf{gl}(x,r)]&gt;1/2+\varepsilon(n)/2​\). This is due to Markov&rsquo;s
inequality (not the normal form, since the direction of inequality is inversed).
Note that</p>
<p>\begin{align*}
\Pr_{x\gets U_n,r\gets U_n}[A(f(x),r)=\mathsf{gl}(x,r)]
&amp;=\sum_{x}\Pr[X=x]\cdot\Pr_{r\gets U_n}[A(f(x),r)=\mathsf{gl}(x,r)]\\
&amp;\le\Pr[X\not\in S]\cdot(1/2+\varepsilon(n)/2)+\Pr[X\in S]\\
&amp;\le 1/2+\varepsilon(n)/2 +\Pr[X\in S]\enspace,
\end{align*}</p>
<p>which means \(\Pr[X\in S]\ge \varepsilon(n)/2\). Conditioned on
\(X\in S\), we construct the following efficient algorithm that can invert \(f\)
given \(f(x):x\in S\) with probability no less than \(\varepsilon(n)^2/16n\) (in the
handout this is \(\varepsilon(n)^2/8n\) but I think that might have a tiny
problem). This reduces our problem to constructing such an algorithm.</p>
<p>The inversion algorithm \(A^\prime​\) works as follows. (Let \(l =
\lceil\log(2n/\varepsilon(n)^2+1)\rceil​\).)</p>
<ol>
<li>Uniformly and independently samples \(s^1,\ldots,s^l\gets U_n\), and
\(\sigma^1,\ldots,\sigma^l\gets U_1\), where \(\sigma^i\) is a guess
for \(\mathsf{gl}(x,s^i)\).</li>
<li>For every non-empty subset \(\mathcal{I}\subseteq [l]\), let
\(r^{\mathcal{I}}\overset{\text{def}}{=}\mathop{\oplus}_{i\in\mathcal{I}}s^i\),
\(\tau^{\mathcal{I}}\overset{\text{def}}{=}\mathop{\oplus}_{i\in\mathcal{I}}\sigma^i\). Each
\(\tau^{\mathcal{I}}\) is a guess for \(r^{\mathcal{I}}\), because if
all the \(\sigma^i\)&rsquo;s are correct guesses, the resulting
\(\tau^{\mathcal{I}}\)&rsquo;s are also correct guesses.</li>
<li>For every \(j \in [n]\), make a guess about the \(j^{\text{th}}\) bit
of input \(x\), denoted by \(x_j\), as follows:
<ol>
<li>
<p>For every non-empty subset \(\mathcal{I}\subseteq [l]\), set
\(v_j^{\mathcal{I}}:=\tau^\mathcal{I}\oplus
A(f(x),r^{\mathcal{I}}\oplus e_j)\), where</p>
<p>\[ e_j \overset{\text{def}}{=}\underbrace{0\ldots0}_{j-1}
1\underbrace{0\ldots0}_{n-j}. \]</p>
</li>
<li>
<p>Do a majority voting on candidate values
\(\{v_j^{\mathcal{I}}:\emptyset \ne\mathcal{I}\subseteq[l]\}\), and
let \(x_j^\prime\) be the majority bit of them.</p>
</li>
</ol>
</li>
</ol>
<p>Now we claim that conditioned on \(x \in S\), the success probability of
\(A^\prime\) is over \(\varepsilon(n)^2/16n\). First of all, The
probability of \(\sigma^1,\ldots,\sigma^{l}\) all being correct guesses
is $2<sup>-l</sup> which is greater than \(\epsilon(n)^2/8n\) (this is where the
divergence comes from). Conditioned on that, we now analyze the
probability that voting on bit \(x_j\) succeeds. Recall that we have
already proved</p>
<p>\begin{align*}
\Pr_{X\gets U_n}[A^\prime(f(X)) = X]&amp;\ge\Pr_{X\gets U_n}[X\in S]\cdot\min_{x\in
S}\Pr[A^\prime(x)=x]\\
&amp;\ge \varepsilon(n)/2 \cdot\varepsilon(n)^2/8n
\cdot\min_{x\in S}
\Pr[x^\prime_1=x_1\land x^\prime_2=x_2\land\ldots\land x^\prime_n=x_n]\\
&amp;=\varepsilon(n)/2 \cdot\varepsilon(n)^2/8n\cdot
(1- \min_{x\in S}
\Pr[x^\prime_1\ne x_1\lor x^\prime_2\ne x_2
\lor\ldots\lor x^\prime_n\ne x_n])\\
&amp;\ge\varepsilon(n)/2 \cdot\varepsilon(n)^2/8n\cdot
(1- \sum_{i\in[n]}\Pr[x^\prime_i\ne x_i])\enspace,
\end{align*}</p>
<p>where from the second line the probability is conditioned on all \(\sigma^i\)&rsquo;s
are correct guesses and the last inequality is from union bound and the
requirement of \(x\) is from the previous equation. It suffices to prove for any
\(x\in S\), \(\Pr[x^\prime_i\ne x_i]\le 1/2n\) for all \(i\in [n]\), and we will prove
it below.</p>
<p>Note that in the third step of \(A^\prime\), if the \(j^{\text{th}}\) bit of \(x\) is
\(0\), then adding \(e_j\) to \(r^{\mathcal{I}}\) does not change the hard-core bit,
and the output \(v_j^{\mathcal{I}}\) will be \(0\). On the other hand, if \(x_j = 1\),
then the output will be inverted and \(v_j^{\mathcal{I}}=1\). This means \[
\Pr[v_j^{\mathcal{I}}\text{ is correct}] = \Pr[A(f(x),r^{\mathcal{I}}) =
\mathsf{gl}(x,r^\mathcal{I})] \ge1/2+\varepsilon(n)/2. \] Let \(m = 2^{l}-1 &gt;
2n/\varepsilon(n)^2\), which is the number of candidates for the majority voting,
and denote \(\mathsf{E}^\mathcal{I}\) be the event that \(v_j^{\mathcal{I}}\) is
correct. By the construction of \(r^{\mathcal{I}}\)&rsquo;s, we have that they are
pairwise independent. Now we analyze the probability of the event that less than
half of the \(v_j^{\mathcal{I}}\)&rsquo;s are correct, which is</p>
<p>\begin{align*}
\Pr[\sum_{\mathcal{I}\in[l]}\mathsf{E}^{\mathcal{I}}&lt;m/2] &amp;=
\Pr[\sum_{\mathcal{I}\in[l]}\mathsf{E}^{\mathcal{I}}-m\mu&lt;m/2-m\mu]\\
&amp;\le\Pr[\sum_{\mathcal{I}\in[l]}\mathsf{E}^{\mathcal{I}}-m\mu&lt;-m\cdot\varepsilon(n)/2]\\
&amp;\le\Pr[|\sum_{\mathcal{I}\in[l]}\mathsf{E}^{\mathcal{I}}-m\mu|&gt;m\cdot\varepsilon(n)/2]\\
&amp;\le \frac{Var(\sum_{\mathcal{I}\in[l]}\mathsf{E}^{\mathcal{I}})}
{(m\cdot\varepsilon(n)/2)^2}.
\end{align*}</p>
<p>The last inequality is due to Chebyshev&rsquo;s inequality. Note that since each two
\(\mathsf{E}^{\mathcal{I}}\)&rsquo;s are pairwise independent, this means</p>
<p>\[ Var(\sum_{\mathcal{I}\in[l]}\mathsf{E}^{\mathcal{I}}) =
\sum_{\mathcal{I}\in[l]}Var(\mathsf{E}^{\mathcal{I}}) \le m\cdot 1/4. \]</p>
<p>Bringing that to the equation above, we have</p>
<p>\begin{align*}
\Pr[\sum_{\mathcal{I}\in[l]}\mathsf{E}^{\mathcal{I}}&lt;m/2] &amp;\le
\frac{Var(\sum_{\mathcal{I}\in[l]}\mathsf{E}^{\mathcal{I}})}{(m\cdot\varepsilon(n)/2)^2}\\ &amp;\le\frac{m\cdot1/4}{m^2\cdot\varepsilon(n)^2\cdot1/4}\\ &amp;\le\frac{1}{2n/\varepsilon(n)^2\cdot\varepsilon(n)^2}\\ &amp;=1/2n.
\end{align*}</p>
<p>And that completes the proof of Goldreich-Levin Theorem.</p>
<h4 id="a-central-theorem-in-cryptography">A Central Theorem in Cryptography<a hidden class="anchor" aria-hidden="true" href="#a-central-theorem-in-cryptography">#</a></h4>
<p>The previous two lemma combined gives us the result <em>one-way permutation implies
pseudorandom generators</em>. In fact, a more general statement that <em>one-way
function implies pseudorandom generators</em> is also true. This is proved by Håstad
et al. in [HILL99]. The proof is much more involved and not suitable for this
lecture. Prof. Yu mentioned in class that this construction is more of
theoretical interest than of practical value, since the loss in efficiency,
although polynomial, is still very large. The simplified cases are that of
one-way permutations (which has already been proved), and regular one-way
functions (every image has the same number of preimages).</p>
<h3 id="homework-18-19-2-lecture-4-homework">Homework {#18-19-2 Lecture 4 Homework}<a hidden class="anchor" aria-hidden="true" href="#homework-18-19-2-lecture-4-homework">#</a></h3>
<p>The handout of this lecture has five homework problems. The first one is to
improve the advantage loss in the original proof. The rest of the problems are
from KL book.</p>
<!--list-separator-->
<ul>
<li>
<p>Improving the Advantage Loss in the Proof of Goldreich-Levin Theorem</p>
<p>What the previous proof proves is essentially assuming some algorithm \(A\) of
running time \(t(n)\) can guess the hard-core bit with probability better than
\(1/2 + \varepsilon(n)\), then there is another algorithm \(A^\prime\) of running
time \(\mathsf{poly}(1/\varepsilon(n),n)\) that can compute \(x\) from \(f(x)\) with
probability better than \(\varepsilon(n)^3/16n\) (which is non-negligible if
\(\varepsilon(n)\) is). This is a stronger guarantee than the one required in
one-wayness experiment, where only \(x^\prime \in f^{-1}(f(x))\) is needed. If we
add a simple check after \(A^\prime\) output \(x^\prime\), and re-guess \(x\) with
fresh randomness if \(f(x^\prime)\ne f(x)\), we can increase the success
probability to \(\varepsilon(n)/4\).</p>
<p>There is a detail that need to be paid attention to in the previous argument.
The first probability that \(x\in S\) only considers the very preimage \(x\), while
in the modified proof, we need to consider all other preimages. Actually, this
is not a problem, since the only information that \(A\) learns is \(f(x)\), and that
is the same for all other preimages \(x^\prime \in f^{-1}(f(x))\). Conditioned on
\(x\in S\), we can safely conclude that all other preimages are in \(S\).</p>
<p>The other point I think may be a caveat is that by repeating the guessing
process, we need to calculate the expected running time of \(A^\prime\), since
it&rsquo;s halting is probabilistic now. This should not be a big problem, since the
success probability of one guessing is more one over some polynomial, and the
inverse is smaller than that polynomial, on infinitely many \(n\)&rsquo;s. Despite this,
the specific halting strategy should be specified to make sure \(A^\prime\) runs
in polynomial time.</p>
</li>
</ul>
<!--list-separator-->
<ul>
<li>
<p>Exercise 6.1 from KL Book</p>
<p>For \(f(x,y) = x+y\), output \((x+y,0)\) on the output; for \(f(x)=x^2\), just use
interpolation to find \(x\).</p>
</li>
</ul>
<!--list-separator-->
<ul>
<li>
<p>Exercise 6.2 from KL Book</p>
<p>Assuming \(f:\{0,1\}^n\to\{0,1\}^{l(n)}​\) is a one-way function (family), it
follows from one-wayness that for all \(\mathsf{PPT}​\) algorithm \(A​\), there exists
a negligible function \(negl(\cdot)​\) such that \[ \Pr_{X\gets U_n,x^\prime\gets
A(f(X))}[f(x^\prime)=f(X)] &lt; negl(n). \] Now construct another function
\(f^\prime:\{0,1\}^n\to\{0,1\}^{l(n)}\) that behaves exactly like \(f\) except on
\(x=0^n\), where it outputs \(0^{l(n)}\). For any \(\mathsf{PPT}\) algorithm \(A\), the
success probability of inverting \(f^\prime\) is</p>
<p>\begin{align*}
\Pr_{X\gets U_n,x^\prime\gets
A(f^\prime(X))}[f^\prime(x^\prime)=f^\prime(X)]\leq2^{-n}+\Pr_{X\gets
U_n,x^\prime\gets A(f(X))}[f(x^\prime)=f(X)]\enspace,
\end{align*}</p>
<p>which is still negligible. This means \(f^\prime\) is also a one-way function. The
KL book maybe tries to tell me one-wayness is a statistical result, changing one
term will not essentially change the overall characteristics.</p>
</li>
</ul>
<!--list-separator-->
<ul>
<li>
<p>Exercise 6.4 from KL Book</p>
<p>The proof is trivial.</p>
</li>
</ul>
<!--list-separator-->
<ul>
<li>
<p>Exercise 6.6 from KL Book</p>
<p>If \(f(\cdot)\) is a one-way function, then \(g(x) = f(f(x))\) is a
one-way function. This is because \(f\) is efficiently computable, and
therefore it is easy to construct an algorithm to invert \(f\) given an
algorithm to invert \(g\).  The second part is essentially the same.</p>
</li>
</ul>
<h2 id="pilot-course">Pilot Course<a hidden class="anchor" aria-hidden="true" href="#pilot-course">#</a></h2>
<h3 id="basic-information">Basic Information<a hidden class="anchor" aria-hidden="true" href="#basic-information">#</a></h3>
<ul>
<li>Lecturers: 郁昱, 刘振</li>
<li>Canvas website: oc.sjtu.edu.cn/courses/19984</li>
</ul>
<h3 id="outline">Outline<a hidden class="anchor" aria-hidden="true" href="#outline">#</a></h3>
<h4 id="testing-signing-in--not-accounted-as-score-reference">Testing Signing in (not accounted as score reference)<a hidden class="anchor" aria-hidden="true" href="#testing-signing-in--not-accounted-as-score-reference">#</a></h4>
<!--list-separator-->
<ul>
<li>Since this is only a testing course, absence will not be penatied.</li>
</ul>
<h4 id="testing-zoom-website">Testing Zoom website<a hidden class="anchor" aria-hidden="true" href="#testing-zoom-website">#</a></h4>
<h4 id="begin-at-exactly-8-55">Begin at exactly 8:55<a hidden class="anchor" aria-hidden="true" href="#begin-at-exactly-8-55">#</a></h4>
<h4 id="15-students-enrolled">15 students enrolled<a hidden class="anchor" aria-hidden="true" href="#15-students-enrolled">#</a></h4>
<h4 id="class-outline">Class Outline<a hidden class="anchor" aria-hidden="true" href="#class-outline">#</a></h4>
<!--list-separator-->
<ul>
<li>Classical Cryptography</li>
</ul>
<!--list-separator-->
<ul>
<li>Modern Cryptography</li>
</ul>
<!--list-separator-->
<ul>
<li>Post-quantum Cryptography</li>
</ul>
<!--list-separator-->
<ul>
<li>Concluding Remarks</li>
</ul>
<h4 id="natural-proof-inbetween-area-between-security-and-insecurity-dot">Natural Proof: inbetween area between security and insecurity.<a hidden class="anchor" aria-hidden="true" href="#natural-proof-inbetween-area-between-security-and-insecurity-dot">#</a></h4>
<h4 id="correspondence-between-crypto-complexity-and-math">Correspondence between crypto, complexity and math<a hidden class="anchor" aria-hidden="true" href="#correspondence-between-crypto-complexity-and-math">#</a></h4>
<table>
<thead>
<tr>
<th>Cryptography</th>
<th>Complexity</th>
<th>Math</th>
</tr>
</thead>
<tbody>
<tr>
<td>PRG, Stream Cipher</td>
<td>PRG, Derandomization</td>
<td></td>
</tr>
<tr>
<td>PRF, Block Ciphers, Authentication</td>
<td>Hardness of learning, Natural proof barrriers</td>
<td></td>
</tr>
<tr>
<td>Privacy amplification</td>
<td>Randomness extraction</td>
<td>Expanders, Ramsey Graphs</td>
</tr>
<tr>
<td>Succinct ZK arguments</td>
<td>PCP, Locally testable Codes</td>
<td></td>
</tr>
<tr>
<td>Leakage-resilient crypto</td>
<td>Dense model theorems, hardcore sets</td>
<td>primes in arithmetic progression</td>
</tr>
<tr>
<td>Obfuscation</td>
<td>Hard search problems</td>
<td></td>
</tr>
<tr>
<td>private information retrieval</td>
<td>locally decodable codes</td>
<td>extremal set theory</td>
</tr>
<tr>
<td>HE, homomorphic secret sharing</td>
<td>locally random reductions, program checking</td>
<td></td>
</tr>
</tbody>
</table>
<h2 id="lecture-1">Lecture 1<a hidden class="anchor" aria-hidden="true" href="#lecture-1">#</a></h2>
<h3 id="introduction">Introduction<a hidden class="anchor" aria-hidden="true" href="#introduction">#</a></h3>
<p>Not all slides will be uploaded to canvas prior to the lecture.</p>
<p>Provable security is an important aspect of modern cryptography.</p>
<p>Prerequisites:</p>
<ul>
<li>read formal proofs</li>
<li>analyze complexity of algorithms</li>
<li>familiarity with basic probability theory</li>
</ul>
<p>Textbooks:</p>
<ul>
<li>KL book</li>
<li>Foundations of cryptography</li>
<li>research papers</li>
</ul>
<h4 id="what-is-cryptography">What is Cryptography<a hidden class="anchor" aria-hidden="true" href="#what-is-cryptography">#</a></h4>
<p>Cryptography is a part of modern theoretical computer
science. Pseudorandomness, communication complexity, and ZK are also
useful tools in TCS in general.</p>
<p>Godel prize topics:</p>
<ul>
<li>Natural proof &ndash; problems that are hard to prove or disprove,
natural proof</li>
</ul>
<p>proves that the proof itself is hard.</p>
<p>Cryptography is not all like mathematics. In crypto, people are only
concerned with moderate problems, and efficient algorithms.</p>
<p>More on that table:</p>
<table>
<thead>
<tr>
<th>Cryptography</th>
<th>Complexity</th>
<th>Math</th>
</tr>
</thead>
<tbody>
<tr>
<td>PRG, Stream Cipher</td>
<td>PRG, Derandomization</td>
<td></td>
</tr>
<tr>
<td>PRF, Block Ciphers, Authentication</td>
<td>Hardness of learning, Natural proof barrriers</td>
<td></td>
</tr>
<tr>
<td>Privacy amplification</td>
<td>Randomness extraction</td>
<td>Expanders, Ramsey Graphs</td>
</tr>
<tr>
<td>Succinct ZK arguments</td>
<td>PCP, Locally testable Codes</td>
<td></td>
</tr>
<tr>
<td>Leakage-resilient crypto</td>
<td>Dense model theorems, hardcore sets</td>
<td>primes in arithmetic progression</td>
</tr>
<tr>
<td>Obfuscation</td>
<td>Hard search problems</td>
<td></td>
</tr>
<tr>
<td>private information retrieval</td>
<td>locally decodable codes</td>
<td>extremal set theory</td>
</tr>
<tr>
<td>HE, homomorphic secret sharing</td>
<td>locally random reductions, program checking</td>
<td></td>
</tr>
</tbody>
</table>
<h4 id="classic-cryptography">Classic Cryptography<a hidden class="anchor" aria-hidden="true" href="#classic-cryptography">#</a></h4>
<p>Traditionally the definition is about secure communication, while the modern
verison is more versatile.</p>
<h4 id="basic-primitives">Basic primitives:<a hidden class="anchor" aria-hidden="true" href="#basic-primitives">#</a></h4>
<ul>
<li>one-way function: for randomly chosen pre-image, it is hard to find any</li>
</ul>
<p>pre-image correponding to the image.</p>
<ul>
<li>pseudorandom generator: randomness amplification</li>
<li>pseudorandom function: PRG, but even better</li>
</ul>
<h4 id="some-basic-tasks">Some basic tasks:<a hidden class="anchor" aria-hidden="true" href="#some-basic-tasks">#</a></h4>
<ul>
<li>encryption: transformation of message that protects message against evasdroppers</li>
<li>MAC/Signature: protect message integrity the previous is the symmetric case</li>
</ul>
<p>while the latter one is public-key case</p>
<ul>
<li>Secure computation: protect input privacy while preserving functionality</li>
</ul>
<h4 id="applications">Applications:<a hidden class="anchor" aria-hidden="true" href="#applications">#</a></h4>
<ul>
<li>Secure communication</li>
<li>authetication</li>
<li>digital signature (MAC, but better)</li>
<li>privacy-preserving computation: MPC, HE, Obfuscation, etc.</li>
</ul>
<p>Obfuscation originates from software code protection, crypto community wants to
formalize it and enhance upon it, but so far no satisfying results.</p>
<ul>
<li>Combination of previous tools</li>
</ul>
<h4 id="symmetric-key-encryption--ske">Symmetric Key Encryption (SKE)<a hidden class="anchor" aria-hidden="true" href="#symmetric-key-encryption--ske">#</a></h4>
<p>A triplet of algorithms</p>
<ul>
<li>Key Generation: \(k \gets KeyGen(1^\kappa)\)</li>
<li>Encryption: \(c \gets Enc(m, k)\)</li>
<li>Decryption: \(m^\prime \gets Dec(c, k)\)</li>
</ul>
<p>Symmetric in the sense that the two parties share common secret knowledge
beforehand.</p>
<!--list-separator-->
<ul>
<li>
<p>Properties:</p>
<ul>
<li>Correctness: BPP or P</li>
<li>Security: passive or active, computaitonally bounded or unbounded (not like</li>
</ul>
<p>oracles)</p>
</li>
</ul>
<!--list-separator-->
<ul>
<li>
<p>Examples in classical cryptography:</p>
<p>Caesar Cipher, Enigma</p>
</li>
</ul>
<!--list-separator-->
<ul>
<li>
<p>Shannon&rsquo;s OTP</p>
<p>Just operations on the GF2 field. Perfectly secure in the sense that ciphertext
is independent of message. In other words, the mutual information between ct and
message is zero.</p>
<p>Perfect secrecy&rsquo;s limitation: \(|K| = |M|\)</p>
</li>
</ul>
<h4 id="shannon-s-entropy">Shannon&rsquo;s Entropy<a hidden class="anchor" aria-hidden="true" href="#shannon-s-entropy">#</a></h4>
<p>\(H = \sum_i p_i \cdot \log(1/p_i)\) \(I(X;Y) = H(X) - H(X|Y)\)</p>
<h4 id="adversarial-model">Adversarial Model<a hidden class="anchor" aria-hidden="true" href="#adversarial-model">#</a></h4>
<ul>
<li>Cihpertext-only attack</li>
<li>known-plaintext attack</li>
<li>chosen-plaintext attack</li>
<li>chosen-ciphertext attack</li>
</ul>
<h4 id="how-to-argue-security">How to argue security<a hidden class="anchor" aria-hidden="true" href="#how-to-argue-security">#</a></h4>
<p>Using reduction based proofs. If problem A is computationally hard, then crytpo
system B is secure against PPT adversaries. In practice, this is done through
showing that algorithm for B can be efficiently converted to algorithm for A.</p>
<h4 id="public-key-cryptogrpahy">Public Key Cryptogrpahy<a hidden class="anchor" aria-hidden="true" href="#public-key-cryptogrpahy">#</a></h4>
<p>Also a triplet of algorithms</p>
<ul>
<li>Keygen</li>
<li>Encryption</li>
<li>Decryption</li>
</ul>
<p>Definition of security: CPA game.</p>
<h4 id="modern-cryptography">Modern Cryptography<a hidden class="anchor" aria-hidden="true" href="#modern-cryptography">#</a></h4>
<p>Modern crypto bases security upon computationally hard problems, which
is what PKE do. But SKE normally does not have this requirement
(e.g. AES, DES).</p>
<p>The dawn of modern cryptogrphy: DH, RSA.</p>
<p>Decisional DH assumption: \((g^x, g^y, g^{xy}) \sim (g^x, g^y, g^z)\)</p>
<p>Pseudorandomness to break shannon&rsquo;s barrier: BMY generator (hybrid argument)</p>
<h4 id="the-hierarchy-of-cryptography">The hierarchy of cryptography<a hidden class="anchor" aria-hidden="true" href="#the-hierarchy-of-cryptography">#</a></h4>
<ul>
<li>Algorithmica: \(\P=\NP\)</li>
<li>Heuristica: \(\P\neq \NP\)</li>
<li>Pessiland: no OWF</li>
<li>Minicrypt: exists OWF</li>
<li>Cryptomania: exists PKC and MPC</li>
</ul>
<p>One-way functions: the minimal assumption for cryptography. Notice this is in
the average case sense. HILL theorem states that OWF implies PRG.</p>
<h4 id="not-all-cryptographic-primitive-has-secret">Not all cryptographic primitive has secret<a hidden class="anchor" aria-hidden="true" href="#not-all-cryptographic-primitive-has-secret">#</a></h4>
<p>CRHF: hard to find collision for a random instance of hash function.
\[\Pr_{h\gets H}[A(h)=(x,x^\prime): x\neq x^\prime, h(x) =
h(x^\prime)]\]</p>
<p>Practical instantiations of CRHF: MD5, SHA1, SHA256, SHA3</p>
<p>But what about a family of algorithms? This is due to definitional problems.</p>
<h4 id="two-party-computation">Two party computation<a hidden class="anchor" aria-hidden="true" href="#two-party-computation">#</a></h4>
<p>Garbled circuit in [Yao82b]. For practical application, c.f. Netherland sugar
beat auction case.</p>
<h4 id="the-quantum-crysis">The Quantum CRYSIS<a hidden class="anchor" aria-hidden="true" href="#the-quantum-crysis">#</a></h4>
<ul>
<li>Shor&rsquo;s algorithm: solves DL and Factoring in poly-time</li>
<li>Grover&rsquo;s algorithm: general quadratic speed-up</li>
</ul>
<p>It is believed that \(BQP \ne NP\).</p>
<p>NIST PQC candidate announcement.</p>
<p>``GOOD&rsquo;&rsquo; assumptions include:</p>
<ul>
<li>Lattice-based: e.g. LWE</li>
<li>Code-based: e.g. LPN</li>
<li>Hash-based: limited to digital sinature</li>
<li>Multivariate: no provable security?</li>
</ul>
<p>LWE and LPN problem, solving noisy equations over finite-field, similar to
solving equations over finite-field (plain elimination) or solving noisy
equations over infinite-field (projection), but actually different.</p>
<p>Decoding Random Linear q-ary codes. Message is \(s\), generation matrix is \(A\),
noisy codeword is \(A \cdot s + e\). This problem is NPC in the worst case, also
hard in the average case (the famous reduction).</p>
<p>LPN: sub-exponential algorithm exists but that&rsquo;s all for the status quo. BKW:
time complexity is \(2^{n/\log n}\) for constant noise rate.</p>
<h4 id="lpn-based-pke--one-bit">LPN-based PKE (one-bit)<a hidden class="anchor" aria-hidden="true" href="#lpn-based-pke--one-bit">#</a></h4>
<p>Alice (the receiver): \(a\gets \{0,1\}^{n\times n}\), \(\sk = s^T\), \(e^T \gets
B_\mu^n\) \(\pk = (a, s^T \cdot a + e^T)\)</p>
<p>Bob (the sender): \(s_1,e_1\gets B_\mu^n\) \(c_1 = a\cdot s_1 + e_1\), \(c_2 = b^T
\cdot s_1 + m\)</p>
<p>Security is easy to prove since all the messages are LPN instances or hard core
bits.</p>
<p>Piling-up lemma: for \(x,y\gets B_\mu^{2n}\): \(\Pr[x^T\cdot y = 0]\ge 1/2 +
2^{O(-n\mu^2)}\).</p>
<h2 id="lecture-2-19-20-2-lecture-2">Lecture 2 {#19-20-2 Lecture 2}<a hidden class="anchor" aria-hidden="true" href="#lecture-2-19-20-2-lecture-2">#</a></h2>
<h3 id="recaping-last-lecture">Recaping Last Lecture<a hidden class="anchor" aria-hidden="true" href="#recaping-last-lecture">#</a></h3>
<h4 id="crhf">CRHF<a hidden class="anchor" aria-hidden="true" href="#crhf">#</a></h4>
<p>Hard to find collision, and it can be based on several mathematical
assumptions.  Another caveat is that in this definition, we consider a
family of functions \(\mathcal{H}\), while in practice we only have only
one algorithm, e.g. SHA256, MD5.</p>
<p>Note that in non-uniform model the collision can be modelled as
auxiliary input, and thus the one-algorithm definition can be
trivially broken.</p>
<h4 id="multiparty-computation">Multiparty Computation<a hidden class="anchor" aria-hidden="true" href="#multiparty-computation">#</a></h4>
<p>Nothing is leaked beyond the input and output information.</p>
<h4 id="decoding-random-linear-code">Decoding Random Linear Code<a hidden class="anchor" aria-hidden="true" href="#decoding-random-linear-code">#</a></h4>
<p>Lattice / LPN based assumptions are these types of assumption. The
latest achievement based on these assumptions are Gentry in STOC 2009.</p>
<p>Introducing the <strong>homomorphic evaluation</strong> function \(\mathsf{Eval}(pk, f,
c_1,\ldots,c_t)\)</p>
<p>Important Limitation: Complexity of decrypting \(c^*\) must not depend
on the complexity of \(f\). Otherwise, one trivial solution is to keep
all the ciphertext inputs and the description of function f, then in
decryption, just decrypt and then evaluate. This goes against the goal
of computation outsourcing.</p>
<p>Cryptography is full of conjecture, surprisingly equivalence, and impossibility
results.</p>
<p>A good / famous example is Alice&rsquo;s Jewelry Store. Worker (server) works
(evaluates) on raw materials (inputs) to produce jewelry (output).</p>
<p>This is like MPC, but only one round of communication, very efficient in
communication.</p>
<p>Pre-2009 schemes are so called <strong>somewhat</strong> homomorphic, not fully.</p>
<h3 id="preliminaries-of-provable-security">Preliminaries of Provable Security<a hidden class="anchor" aria-hidden="true" href="#preliminaries-of-provable-security">#</a></h3>
<h4 id="writing-a-formal-proof">Writing a formal proof<a hidden class="anchor" aria-hidden="true" href="#writing-a-formal-proof">#</a></h4>
<dl>
<dt>Conditionally</dt>
<dd>by a reduction</dd>
<dt>Unconditionally</dt>
<dd>constructively or existentially</dd>
</dl>
<p>Most crypto proofs are conditional, the minimal assumption is the
existence of one-way function. And the existence of OWF considers
average-case hardness (most instances are hard), while \(\P \ne \NP\)
considers worst case hardness.</p>
<p>Though seemingly groundless, conjectures like RSA seems robust enough. A French
team successfully conducts cryptanalysis on ~ 800bits RSA.</p>
<p>Unconditionally proof usually involves information theory. Constructive results
are surely more satisfying than existential solution (which only provides
one-bit).</p>
<dl>
<dt>Disproof</dt>
<dd>provide one counterexample is sufficient</dd>
<dt>Proof hard to prove</dt>
<dd>shows that the proof itself is hard to come up with.</dd>
</dl>
<!--list-separator-->
<ul>
<li>
<p>Examples</p>
<ol>
<li>Shows the number of primes are infinite</li>
</ol>
<p>Use simple proof technique</p>
<ol>
<li>For sequentially ordered primes \(p_1,\ldots,p_n\), is</li>
</ol>
<p>\(p_1\cdot p_2 \cdot \ldots \cdot p_n \pm 1\) prime as well?</p>
<p>No, the prime list is not complete. Related problems are twin prime conjecture.</p>
<ol>
<li>Binary linear code</li>
</ol>
<p>A binary (m,n)-code has dimension n and length m. The generator matrix is of
size n by m.</p>
<p>Nearest Codeword Problem (NCP): given the generator matrix C and noisy codeword
\(t^T = s^T \cdot C + x^T\). Noise x is limited by its hamming weight which is
exactly \(d\). The solution is \(s^\prime\) such that \[ s^T \cdot C + x^T =
s^{\prime T} \cdot C + x^{\prime T} \]</p>
<p>Show most linear codes have unique decoding when codeword length m is large
enough. <img loading="lazy" src="/ox-hugo/NCP_LPN.png" alt=""  />
 This is an example of existential
probablistic proof.</p>
</li>
</ul>
<h4 id="notations-on-rv-s-and-sets">Notations on rv&rsquo;s and sets<a hidden class="anchor" aria-hidden="true" href="#notations-on-rv-s-and-sets">#</a></h4>
<p>Sets \(\bin\) is the most common one.</p>
<h4 id="notations-of-probability-distribution">Notations of probability distribution<a hidden class="anchor" aria-hidden="true" href="#notations-of-probability-distribution">#</a></h4>
<ul>
<li>non-negativity</li>
<li>maps from sample space to real number in [0,1]</li>
<li>add up to one</li>
</ul>
<h4 id="random-variables">Random variables<a hidden class="anchor" aria-hidden="true" href="#random-variables">#</a></h4>
<p>very similar to distribution</p>
<h4 id="events-and-independence">Events and Independence<a hidden class="anchor" aria-hidden="true" href="#events-and-independence">#</a></h4>
<p>Event is actually a subset of sample space, independent events are two &ldquo;regular&rdquo;
subspace. By regular I mean conditioning on one event the other one has the same
probability.</p>
<p>Independent variables: for every possible value, the corresponding events are
independent.</p>
<h4 id="polynomial-and-friends">Polynomial and friends<a hidden class="anchor" aria-hidden="true" href="#polynomial-and-friends">#</a></h4>
<p>Efficient algorithm means polynomial-time computable. In cryptogrpahy, we want
the problem for adversary is <strong>super-polynomial</strong> hard while the success
probability is some inverse of <strong>super-polynomial</strong> function.</p>
<p>A function \(f\) is superpolynomial if for every constant \(c&gt;0\) and all
sufficiently large \(n\) we have \(f(n) &gt; n^c\).</p>
<p>Negligible function is the inverse of some superpolynomial.</p>
<!--list-separator-->
<ul>
<li>
<p>Examples</p>
<p>Like \(2^{n/2}\), \(n^{\log n}\)</p>
</li>
</ul>
<h4 id="overwhelming-and-non-negligible">Overwhelming and non-negligible<a hidden class="anchor" aria-hidden="true" href="#overwhelming-and-non-negligible">#</a></h4>
<dl>
<dt>overwhelming</dt>
<dd>1 - negligible</dd>
<dt>non-negligible</dt>
<dd>not negligible (larger than some polynomial for</dd>
</dl>
<p>infinitely-many n&rsquo;s)</p>
<dl>
<dt>noticible</dt>
<dd>larger than some inverse of polynomial</dd>
</dl>
<p>example of non-negligible but non-noticible function: &ldquo;punch-out&rdquo; function at
all even / odd points.</p>
<h4 id="asymptotic-functions">asymptotic functions<a hidden class="anchor" aria-hidden="true" href="#asymptotic-functions">#</a></h4>
<p>big-oh notations.</p>
<table>
<thead>
<tr>
<th>asymptotic</th>
<th>meaning</th>
</tr>
</thead>
<tbody>
<tr>
<td>\(o\)</td>
<td>\(\leq\)</td>
</tr>
<tr>
<td>\(\omega\)</td>
<td>\(\geq\)</td>
</tr>
<tr>
<td>\(\theta\)</td>
<td>\(=\)</td>
</tr>
<tr>
<td>\(o\)</td>
<td>\(&lt;\)</td>
</tr>
<tr>
<td>\(\omega\)</td>
<td>\(&gt;\)</td>
</tr>
</tbody>
</table>
<h4 id="function-ensembles">Function Ensembles<a hidden class="anchor" aria-hidden="true" href="#function-ensembles">#</a></h4>
<p>Different functions for different problem scale.</p>
<p>Example: one-way function</p>
<p>Usual mathematical objects are functions of the security parameter.</p>
<h4 id="union-bound-and-markov-inequality">Union bound and Markov inequality<a hidden class="anchor" aria-hidden="true" href="#union-bound-and-markov-inequality">#</a></h4>
<p>Union Bound:</p>
<p>Markov Bound: \(\Pr[X \ge \delta \expect{X}]\le 1/\delta\)</p>
<h4 id="chebyshev-s-inequality">Chebyshev&rsquo;s Inequality<a hidden class="anchor" aria-hidden="true" href="#chebyshev-s-inequality">#</a></h4>
<p>\[ \prob{|X-\mu|\ge \delta\sigma} \le 1/{\delta^2} \]</p>
<h4 id="chernoff-bound-and-hoeffding-bound">Chernoff bound and Hoeffding Bound<a hidden class="anchor" aria-hidden="true" href="#chernoff-bound-and-hoeffding-bound">#</a></h4>
<p>There are additive form and multiplicative form</p>
<h4 id="piling-up-lemma-and-misc">Piling up Lemma and misc<a hidden class="anchor" aria-hidden="true" href="#piling-up-lemma-and-misc">#</a></h4>
<p>We have \(\prob{\bar{x} = 1} = 1/2 - 1/2 \cdot (1 - 2\mu)^n\)</p>
<p>Extreme cases: \(\mu = 0\) nothing changes; one \(\mu = 1/2\) then the result is
random.</p>
<dl>
<dt>Fact 1.</dt>
<dd>For any \(0\le x \le 1\) it holds that \(\log_2 (1+x) \ge x\)</dd>
</dl>
<p>For any \(x &gt; -1\) we have \(\log (1+x) \le x / \ln 2\)</p>
<dl>
<dt>Fact 2.</dt>
<dd>Binominal approximation</dd>
</dl>
<h4 id="another-homework-on-the-existence-of-independent-code">ANOTHER HOMEWORK on the existence of independent code<a hidden class="anchor" aria-hidden="true" href="#another-homework-on-the-existence-of-independent-code">#</a></h4>
<h2 id="lecture-3-19-20-2-lecture-3">Lecture 3 {#19-20-2 Lecture 3}<a hidden class="anchor" aria-hidden="true" href="#lecture-3-19-20-2-lecture-3">#</a></h2>
<h3 id="how-to-do-last-lecture-s-homework">How to do last lecture&rsquo;s homework<a hidden class="anchor" aria-hidden="true" href="#how-to-do-last-lecture-s-homework">#</a></h3>
<p>If C is a random matrix, then Cr is uniformly random. The answer will not be
distributed today, though.</p>
<h3 id="statistical-distance-indistinguishability-and-the-lhl">Statistical distance / indistinguishability and the LHL<a hidden class="anchor" aria-hidden="true" href="#statistical-distance-indistinguishability-and-the-lhl">#</a></h3>
<p>First define the indistinguishability experiment.</p>
<p>There are three levels of security:</p>
<dl>
<dt>Unconditionally secure / information-theoretically secure</dt>
<dd>advantage has</dd>
</dl>
<p>zero advantage</p>
<dl>
<dt>Statistically secure</dt>
<dd>adversary has negligible advantage</dd>
<dt>Computationally secure</dt>
<dd>pseudorandomness, etc.</dd>
</dl>
<p>The experiment here is about private key encryption</p>
<figure>
    <img loading="lazy" src="/ox-hugo/PrivK.png"
         alt="Figure 5: Private Key Encryption Experiment"/> <figcaption>
            <p><span class="figure-number">Figure 5: </span>Private Key Encryption Experiment</p>
        </figcaption>
</figure>

<p>The adversary&rsquo;s advantage is \(\mathsf{Adv}{eav}{\mathcal{A},\Pi} =
\Pr[b^\prime = b] -1/2\) Notice here the adversary is considered to be
all-powerful, and so it can determine which random coin is the most
advantageous, and so it doesnot has to be a randomized algorithm, or to keep
state information.</p>
<p>The above algorithm can also be transformed into an indistinguishability game,
such that the same \(\varepsilon\) is still the bound. We can use conditional
probability to prove this equivalence.</p>
<h3 id="one-time-pad-is-perfectly-secure">One-time pad is perfectly secure<a hidden class="anchor" aria-hidden="true" href="#one-time-pad-is-perfectly-secure">#</a></h3>
<p>OTP is defined over \(\{0,1\}^n\), we want to prove that this is perfect-secure.
And it is so simple, since any two ciphertexts are distributed identically, so
any adversary&rsquo;s advantage is zero.</p>
<h3 id="statistical-distance">Statistical Distance<a hidden class="anchor" aria-hidden="true" href="#statistical-distance">#</a></h3>
<p>For two distributions X,Y, the statistical distance is defined as:</p>
<p>\[\mathsf{SD}(X,Y):=1/2 \sum_x \left|\Pr[X=x]-\Pr[Y=x]\right|\]</p>
<p>And we can define conditional statistical
distance \(\mathsf{SD}(X,Y|Z):= \mathsf{SD}((X,Z),(Y,Z))\).</p>
<p>The 1/2 in the definition is to normalize the output to the range of [0,1].</p>
<p>SD provides a upper bound of the advantage of distinguishing two distributions.
This can be seen as \(D\) defines a distribution on the support. The best we can
do is to let it maximize the success probability (in the distinguishing game) on
every input.</p>
<p>SD is a metric since it has:</p>
<ul>
<li>non-negativity</li>
<li>identity of indiscernibles</li>
<li>symmetry</li>
<li>\(\mathsf{SD}(X,Z) \leq \mathsf{SD}(X,Y) + \mathsf{SD}(Y,Z)\)</li>
</ul>
<p>Furthermore, it has the following property:</p>
<dl>
<dt>no greater than one</dt>
<dd>the equality holds when supports of \(X,Y\) are disjoint.</dd>
<dt>replacement</dt>
<dd>for every function \(f\), \(\mathsf{SD}(f(X),f(Y))\leq\mathsf{SD}(X,Y)\)</dd>
</dl>
<h4 id="statistical-security-for-otp">Statistical Security for OTP<a hidden class="anchor" aria-hidden="true" href="#statistical-security-for-otp">#</a></h4>
<p>An application of replacement lemma can prove the indistinguishability when
replacing the key distribution from uniformly random to statistically close to
uniformly random. This can be understood intuitively by that the two ciphertexts
are both \(\varepsilon\) close to the uniform distribution, and they are at most
\(2\varepsilon\) far away.</p>
<h3 id="entropy">Entropy<a hidden class="anchor" aria-hidden="true" href="#entropy">#</a></h3>
<p>Renyi entropy of order \(\alpha \ge 0\) and \(\alpha \ne 1\) is defined as:
\[H_{\alpha}(X):=\frac{1}{1-\alpha}\log\left(\sum_{i}p_i^\alpha\right)\]</p>
<dl>
<dt>\(\alpha = 0\)</dt>
<dd>we have max-entropy;</dd>
<dt>\(\alpha = 2\)</dt>
<dd>we have collision entropy, i.e. \(-\log(\sum_i p_i^2)\);</dd>
<dt>\(\alpha \to 1\)</dt>
<dd>it converges to Shannon entropy;</dd>
<dt>\(\alpha \to \infty\)</dt>
<dd>we have min-entropy, minus log of the maximum entropy.</dd>
</dl>
<p>A classical example: a key that has 1/2 probability to take all zeros, and the
other cases uniform over all other possibilities. It has about n/2 Shannon
entropy, but still a very bad key source. We should instead focus on
min-entropy.</p>
<h3 id="two-lemmas-about-indistinguishability">Two lemmas about indistinguishability<a hidden class="anchor" aria-hidden="true" href="#two-lemmas-about-indistinguishability">#</a></h3>
<ol>
<li>
<p>Pilling-up lemma</p>
</li>
<li>
<p>Indistinguishablility amplification. For independent bit-strings
\(S_1,\ldots,S_l \in \FF^n_2\), we have the following bound on the statistical
distance of their XOR sum from uniform</p>
<p>\[\mathsf{SD}(\mathop{\oplus}_i S_i, U_n) \leq 1/2\prod_i(2\delta_i)\]</p>
</li>
</ol>
<h3 id="average-min-entropy-and-conditional-unpredictability">Average Min-entropy and Conditional Unpredictability<a hidden class="anchor" aria-hidden="true" href="#average-min-entropy-and-conditional-unpredictability">#</a></h3>
<p>X is \(\epsilon\) -unpredictable conditioned on \(Z\) means that</p>
<p>\[\Pr[\mathcal{A}(1^n, Z) = X]\le \varepsilon\]</p>
<p>And its entropic counterpart:
\[H_{\infty}(X|Z):=-\log(\expect{\max_x{\Pr[X=x|Z=z]}})\]</p>
<h3 id="randomness-extractors">Randomness Extractors<a hidden class="anchor" aria-hidden="true" href="#randomness-extractors">#</a></h3>
<p>Since min-entropy is not so good, can we extract unifrom randomness from flawed
sources? This is called a randomness extractor.</p>
<p>Unfortunately, a deterministic randomness extractor does not exist.</p>
<p>So, extractors must be probablistic. \((n,k,m,d,\varepsilon)\) extractor. Invest
d-bit randomness, when input is n-bit with k-bit min-entropy, the output is
\(varepsilon\) close to \(U_m\).</p>
<h3 id="universal-hash-functions">Universal Hash Functions<a hidden class="anchor" aria-hidden="true" href="#universal-hash-functions">#</a></h3>
<p>A family of hash functions \(H\subseteq \{h:\{0,1\}^l\to\{0,1\}^t\}\) is
called unifersal hash function if for every pair of distinct input \(x_1,x_2\), we
have \[\Pr[h(x_1) = h(x_2):h\leftarrow H]\le 1/2^t\] A trivial example of hash
function based on multiplication over finite field \(\FF_2^n\).</p>
<h3 id="leftover-hash-lemma">Leftover Hash Lemma<a hidden class="anchor" aria-hidden="true" href="#leftover-hash-lemma">#</a></h3>
<p>For any integer \(d \le k \le l\), let \(H\subseteq
\{h:\{0,1\}^l\to\{0,1\}^{k-d}\}\) be a family of universal hash functions,
then for any r.v. \(X\) defined over \(\{0,1\}^l\) with min-entropy at least
k-bit, then it holds that</p>
<p>\[\mathsf{SD}(H(X),U_{k-d}|H) \leq 2^{-1-d/2}\]</p>
<p>The proof is deferred to the next lecture.</p>
<h3 id="privacy-amplification">Privacy Amplification<a hidden class="anchor" aria-hidden="true" href="#privacy-amplification">#</a></h3>
<p>This is an application of LHL. Say Alice and Bob shares non-perfect source, they
can publicly sample a random hash function, and then transform their imperfect
randomness into randomness that is statistically close to uniform random. This
can then subsequently used as, say private key.</p>
<h2 id="lecture-4">Lecture 4<a hidden class="anchor" aria-hidden="true" href="#lecture-4">#</a></h2>
<h3 id="recap-of-last-lecture">Recap of last lecture<a hidden class="anchor" aria-hidden="true" href="#recap-of-last-lecture">#</a></h3>
<p>Two definitions (interactive game or indistinguishability plain) of
indistinguishability is equivalent. All of them can be generalized to
computational sense.</p>
<p>Statistical distance: difference between two distributions. The greatest
advantage is to output 1 every time \(\Pr[X=x] &gt; \Pr[Y=x]\), which is SD.</p>
<p>Statistical secure OTP: using randomness statistically close to uniform to
replace the random key. The advantage is times 2 since we uses a hybrid.</p>
<p>Entropy: Renyi Entropy</p>
<p>\[H_0(X) \ge H_1(X) \ge \ldots \ge \minentropy{X}\]</p>
<p>Equality takes when X is uniformly random</p>
<h4 id="piling-up-lemma">Piling-up Lemma<a hidden class="anchor" aria-hidden="true" href="#piling-up-lemma">#</a></h4>
<p>Generalization:</p>
<dl>
<dt>Differnet \(\mu\)</dt>
<dd>multiplication (though still independent)</dd>
</dl>
<p>Biased towards 1</p>
<dl>
<dt>Bit-vector XOR</dt>
<dd>still independent</dd>
</dl>
<p>\[\mathsf{SD}(\mathop\oplus_i X_i, U_n) = 1/2 \prod_i (2\mathsf{SD}(X_i, U_n))\]</p>
<h4 id="randomness-extractors">Randomness Extractors<a hidden class="anchor" aria-hidden="true" href="#randomness-extractors">#</a></h4>
<p>How to prove the existential result (from the inability result) ???</p>
<h4 id="leftover-hash-lemma">Leftover hash lemma<a hidden class="anchor" aria-hidden="true" href="#leftover-hash-lemma">#</a></h4>
<p>LHL: for any integer \(d\le k \le n\), let \(H \subseteq \{0,1\}^l \to
\{0,1\}^{k-d}\) be universal hash function. Then suppose \(X\) has minentropy k,
it holds that</p>
<p>\[\mathsf{SD}(H(X),U_{k-s} | H) \le 2^{-1-d/2}\]</p>
<p>Proof. Using Cauchy Inequality, then collision probability, and finally
collision entropy is big enough (\(\geq k\)).</p>
<p>In some proof the \(1/2\) coefficient is skipped for simplicity.</p>
<h4 id="conditional-lhl">Conditional LHL<a hidden class="anchor" aria-hidden="true" href="#conditional-lhl">#</a></h4>
<p>chain rule of min-entropy: for any \(Z\in\{0,1\}^L\), we have \[\minentropy{X|Z}
\ge \minentropy{X} - L\]</p>
<p>Proof 1. Suppose contradiction, first guess Z, whose success probability is more
than \(1/2^L\), and then use this as leakage to guess \(X\), which will have success
probability greater than \(2^{-\minentropy{X}}\)</p>
<p>Proof 2. Consider probability distribution of \(X\). It holds that the maximum
probability of \(X\) satisfies that \(\sup_x\Pr[X=x] = 2^{-\minentropy{X}}\), then
consider conditioning on a \(L\) -bit leakage. The best this leakage can do is to
&ldquo;shrink&rdquo; the table by \(2^L\), which is our case.</p>
<p>We can further extend LHL to the case with leakage.</p>
<h4 id="exericise">Exericise<a hidden class="anchor" aria-hidden="true" href="#exericise">#</a></h4>
<p>Equivalence between collision entropy and min-entropy Consider any \(X\) such that
\(H_2(X)\ge k\) and \(0&lt;\delta&lt;1\). We have</p>
<h3 id="computational-security">Computational Security<a hidden class="anchor" aria-hidden="true" href="#computational-security">#</a></h3>
<p>If we are constrained in information-theoretic world, then pkc is impossible. So
we need computational security.</p>
<p>E is \((t,\epsilon)\) secure if any \(A\) less than time \(t\) has advantage at most
\(\epsilon\).</p>
<dl>
<dt>Perfect security</dt>
<dd>\(t = \infty\), \(\epsilon = 0\)</dd>
<dt>Statistical Security</dt>
<dd>\(t = \infty\), \(\epsilon = n^{-\omega(1)}\)</dd>
<dt>Computational Security</dt>
<dd>\(t=n^{\omega{1}}\), \(\epsilon = n^{-\omega(1)}\)</dd>
</dl>
<p>Requirements (asympototic):</p>
<dl>
<dt>Efficiency</dt>
<dd>all algorithms must be poly time</dd>
<dt>Security</dt>
<dd>for any efficient adversary, the success prob. of it must be</dd>
</dl>
<p>bounded by some negligible function.</p>
<dl>
<dt>Efficiency (slightly stronger)</dt>
<dd>\(t=n^{\omega(1)}\),
\(\epsilon = n^{-\omega(1)}\) this implies the second one. But the second one
strictly does not imply this one.</dd>
</dl>
<h4 id="private-key-encryption">Private-Key Encryption<a hidden class="anchor" aria-hidden="true" href="#private-key-encryption">#</a></h4>
<p>Three algorithms: KeyGen, Enc, Dec.</p>
<p>Implications of indistinguishability:</p>
<ol>
<li>Impossible to guess any one-bit.</li>
<li>Impossible to compute any poly-time function of any efficiently samplable
\(m\).</li>
<li>Semantic Security. For any efficient auxiliary information \(h\) and
efficiently function \(f\). No efficiently sampable \(m\) can be learned \(f(m)\)
from its encryption with more advantage than without the encryption.</li>
</ol>
<h3 id="pseudorandom-generator--prg">Pseudorandom Generator (PRG)<a hidden class="anchor" aria-hidden="true" href="#pseudorandom-generator--prg">#</a></h3>
<p>PRG is <strong>an</strong> algorithm \(g:\{0,1\}^n\to\{0,1\}^l\) and \(l&gt;n\) such that for any
efficient \(D\) we have:</p>
<p>\[|\Pr[D(g(U_n))] - \Pr[D(U_l)] | = \mathsf{negl}\]</p>
<p>We can generalize it a bit by \((t,\varepsilon)\) i.e. quantifying the running
time.</p>
<h4 id="useful-lemmas">Useful Lemmas<a hidden class="anchor" aria-hidden="true" href="#useful-lemmas">#</a></h4>
<dl>
<dt>Replacement Lemma</dt>
<dd>If X, Y are \((t, \varepsilon)\) indistinguishable, and \(f\)
is \(T\) computable, then \(f(X)\), \(f(Y)\) are \((t-T, \varepsilon)\) ind.</dd>
</dl>
<p>Notice that here if we take \(t = \infty\) we have
\(\mathsf{SD}(X,Y) \geq \mathsf{SD} (f(X), f(Y))\)</p>
<dl>
<dt>Switching Lemma</dt>
<dd>If \(X_1\), \(X_2\), \(\ldots\), \(X_m\) satisfies that for any
\(1\le i \le m\), \((t_i, \epsilon_i)\) ind. then \(X_1\) and \(X_m\) are \((t,
\epsilon)\) ind. where \(t = \min_i{t_i}\) and \(\epsilon = \sum_i \epsilon_i\).</dd>
</dl>
<p>The minimum time needs to be considered.</p>
<h4 id="one-bit-stretch-implies-poly-bit-stretch">One-bit stretch implies poly-bit stretch<a hidden class="anchor" aria-hidden="true" href="#one-bit-stretch-implies-poly-bit-stretch">#</a></h4>
<p>Sequential composition of PRG.</p>
<p>If PRG is (\(t\), \(\epsilon\)) secure with stretch \(s\) then we can construct PRG
that is (\(t-q\cdot\poly\), \(q\cdot \epsilon\)) secure with stretch \(q\cdot s\).</p>
<p>Consider \(q-1\) hybrid states that interpolates between total pesudorandom and
ture randomness. We achieve this by replacing the previous \(i\cdot s +n\) blocks
with true randomness. Then any subsequent hybirds are bounded by \(t-q\poly\),
\(\epsilon\) ind. The two ends are therefore (\(t-q\cdot \poly\), \(q\varepsilon\))
ind.</p>
<h2 id="lecture-5-19-20-2-lecture-5">Lecture 5 {#19-20-2 Lecture 5}<a hidden class="anchor" aria-hidden="true" href="#lecture-5-19-20-2-lecture-5">#</a></h2>
<p>PRG-based fixed encryption: use PRG-generated pseudorandomness to implement OTP.
Now the security is computational rather than perfect or statistical.</p>
<p>Both perfect and statistical security are &ldquo;trivial&rdquo;. It is in the sense that key
space must be larger than message space. For statistical security there is
similar result.</p>
<p>A proof using hybrid-like argument shows that the advantage of distinguishing
(any) two ciphertexts is bounded by \(2\varepsilon(n)\) where \(\epsilon(n)\) is the
advantage of distinguishing \(g(U_n)\) and \(U_l\).</p>
<p>Homework: Decisional LPN with constant noise rate \(\mu=1/4\) and query \(q=2n\).
How to construct a PRG?</p>
<h3 id="one-way-functions-and-permutations">One-Way Functions and Permutations<a hidden class="anchor" aria-hidden="true" href="#one-way-functions-and-permutations">#</a></h3>
<p>Unlike complexity folks, we consider average-case hardness here.</p>
<p>We consider a family of functions \(f_n\) <strong>one-way</strong> if it is</p>
<dl>
<dt>Easy to compute</dt>
<dd>computable by a poly-time turing machine</dd>
<dt>hard to invert</dt>
<dd><strong>randomly</strong> sample a pre-image, it is hard (super-polynomial)
complexity to come up with a \(x^prime\) given \(y = f(x)\) such that \(f(x^\prime)
= y\).
<p>Note here hardness is defined with repect to coming up with any one satisfying
preimage, not the exact preimage, since the function might be lossy. I.d.
input information is much larger than output information.</p>
</dd>
</dl>
<p>Candidate OWFs</p>
<ul>
<li>Integer factorization</li>
<li>Subset-sum problem</li>
<li>Notice how non-discrete version is actually easy.</li>
</ul>
<h3 id="hardcore-predicate">Hardcore Predicate<a hidden class="anchor" aria-hidden="true" href="#hardcore-predicate">#</a></h3>
<p>By definition, a one-way function is hard-to-invert. Some information about the
preimage must be hard to get in some way.</p>
<p>Hardcore predicate formalizes this intuition.</p>
<p>A hardcore predicate \(h_c:\{0,1\}^n\to\bin\) is called a hard core
predicate of a function \(f:\{0,1\}^n\to\{0,1\}^l\) if for every ppt \(\mathcal{A}\),
we have \[ \Pr_{x\leftarrow U_n}[\mathcal{A}(f(x)) = h_c(x)] = 1/2 + \mathsf{negl}.\]</p>
<p>Result: one-way permutation + hardcore predicate -&gt; pseudorandom generator. Or:
Next-bit unpredictability implies pseudorandomness.</p>
<p>Exercise proof: How the existence of hardcore predicate implies one-wayness.
Notice that when inversion algorithm fails, we need to output a random bit to
guess the hard-core predicate to preserve non-negative advantage.</p>
<p>Statement. Suppose the probability of predicting \(h_c(x)\) from \(f(x): x\leftarrow
U_n\) is \(1/2 + \epsilon\) for any t-time adversary, then \((f(U_n),h_c(U_n))\) and
\(U_{n+1}\) is \(t/2\), \(\varepsilon\) indistinguishable.</p>
<p>Proof. Suppose there is a distinguisher \(D\) contradicting the assumption, then
we can conclude that \[\Pr[D(U_n),h_c(U_n)] - \Pr[D(U_n),1-h_c(U_n)] \ge
2\varepsilon\]</p>
<p>Then we design another algorithm \(D^\prime(y)\) that computes \(b_1 =
D^\prime(y,1)\) and \(b_0 = D^\prime(y,0)\). It outputs 1 if \(b_1 &gt; b_0\) and 0 if
\(b_0 &gt; b_1\) and random bit otherwise. We claim that the success probability of
this algorithm is \(\varepsilon\)</p>
<p>This statement is proved in 1982, but general hardcore construction for any owf
did not appear until 1989 (Golereich-Levin).</p>
<h3 id="proof-of-goldreich-levin-theorem">Proof of Goldreich-Levin Theorem<a hidden class="anchor" aria-hidden="true" href="#proof-of-goldreich-levin-theorem">#</a></h3>
<p>First recall the statement of GL theorem: for any oneway function \[ f_n :
\{0,1\}^n \to \{0,1\}^l,\] we have the following hardcore predicate \(h_c\)
for \(f^\prime\)</p>
<p>\begin{align*}
f^\prime(x,r) &amp;= f(x), r\\ h_c(x,r) &amp;= r^T \cdot x. \end{align*}</p>
<p>Technical roadmap:</p>
<ul>
<li>
<p>First prove the size of set
\[S: \Pr_r[\mathcal{A}(f(x),r) = h_c(x,r)] \ge 1/2 +\epsilon /2\] is at least
\(\epsilon /2\).</p>
<p>Using Markov argument. \[1/2 + \epsilon \le \Pr_{x,r}[\mathcal{A}(f(x),r) =
h_c(x,r)]\le 1\cdot p + (1/2+\epsilon/2)\cdot (1-p),\]</p>
<p>Which implies \(p \ge \epsilon /2\)</p>
</li>
<li>
<p>Then design an algorithm \(\mathcal{A}^\prime\) that invert \(f(x)\) with probability
at least \(\epsilon^3/(8n)\).</p>
<p>The trick here is using pair-wise independence. Let \(l\) be a small enough
&ldquo;row&rdquo; sample number. \(l = \ceil{\log(2n/\epsilon^2 + 1)}\).</p>
<p>Define \(\sigma^i \leftarrow \{0,1\}^n\) and \(\tau^i \leftarrow \bin\) for
\(i\in[l]\). Then let \(\tau^i\) be the guess of \(h_c(x, \sigma_i)\). Notice that
since we choose \(l\) small enough, the success probability \[1/2^l \ge
\epsilon^2/(4n)\] is just fine.</p>
<p>Now define \(I\) to be any non-empty subset of \([l]\) and</p>
<p>\begin{align*}
r^I &amp;= \mathop{\oplus}_{i\in I}\sigma^i\\ \tau^I &amp;= \mathop{\oplus}_{i\in
I}\tau^i \end{align*}</p>
</li>
</ul>
<p>Then let</p>
<p>\begin{align*}
v_j^I &amp;:= \tau^I \oplus \mathcal{A}(y, r^I\oplus e_j)\\
&amp;= \tau^I \oplus \mathcal{A}(y, r^I) \oplus x_j\enspace.
\end{align*}</p>
<p>Then do a majority voting on \(2^{l}-1\) candidates to determine \(x_j\).</p>
<p>Conditioned on all the guesses are correct, we then bound the probability that
there exists one vote that is wrong. First use a union bound. Then for any \(j\)
voting output \(x_j^\prime \ne x_j\) indicates that the number of correct vote is
less than \(m/2\) where \(m = 2^l - 1\). Now by chebyshev inequality, the mean is
\(m/2 + \epsilon m/2\), this probability is bounded by \(Var/(\epsilon m /2)^2\).
Since the votes are <strong>pair-wise</strong> independent, we can conclude that this
probability is bounded by \(1/2n\).</p>
<h3 id="a-central-theorem-in-cryptography">A Central Theorem in Cryptography<a hidden class="anchor" aria-hidden="true" href="#a-central-theorem-in-cryptography">#</a></h3>
<p>One-way functions imply pseudorandom generator. [HILL99]</p>
<p>What we actually proved is a decoding algorithm that convert \(\epsilon\)
advangage in distinguishing hardcore predicate into \(\epsilon^3/(16n)\) advantage
in decoding.</p>
<h3 id="exercises-19-20-2-lecture-5-exercises">Exercises {#19-20-2 Lecture 5 Exercises}<a hidden class="anchor" aria-hidden="true" href="#exercises-19-20-2-lecture-5-exercises">#</a></h3>
<p>Show the equivalence between Computational-LPN and Decisional-LPN.</p>
<p>Solution: Given LPN sample (\(a\), \(b\)), add uniformly random \(r\leftarrow\bin\)
to first bit of \(a\) i.e. output (\(a + e_{1}\cdot r\), \(b\)).</p>
<ul>
<li>When \(s_{1} = 0\) the output is LPN sample,</li>
<li>When \(s_{1} = 1\) the output is random sample.</li>
</ul>
<p>So we transformed a distinguisher for DLPN to an algorithm that solves
Search-LPN (first bit). We can then continue to solve for the rest of bits.</p>
<h2 id="lecture-6">Lecture 6<a hidden class="anchor" aria-hidden="true" href="#lecture-6">#</a></h2>
<p>Basing Pseudorandom Generators on Regular One-way Functions</p>
<h3 id="prg-from-regular-owf">PRG from Regular OWF<a hidden class="anchor" aria-hidden="true" href="#prg-from-regular-owf">#</a></h3>
<p>Definition: \(f:\{0,1\}^{n}\to\{0,1\}^{m}\) is an \(\epsilon\)-OWF if for all
polynomial adversary&rsquo;s inversion probability is smaller than \(\epsilon\): \[
\Pr_{x\leftarrow U_{n}}[A(1^{n}, f(x))\in f^{-1}(f(x))] \le \epsilon \]</p>
<p>Folklore: OWFs can be assumed to be length-preserving, i.e. \(m = n\): If \(m &gt; n\)
then pad zeros to input; if \(m &lt; n\) then pad zeros to output.</p>
<h4 id="regular-owf">Regular OWF<a hidden class="anchor" aria-hidden="true" href="#regular-owf">#</a></h4>
<p>Preimage size \(\alpha = |f^{-1}(y)|\) (to which we refer as regularity) is fixed.
We can further divide it into known-regular and unknown-regular.</p>
<h4 id="prg">PRG<a hidden class="anchor" aria-hidden="true" href="#prg">#</a></h4>
<p>Usual parameterized definition: advantage at most \(\epsilon\) when running time
is limited to \(t\).</p>
<p>The PRG introduced in previous lecture (the BM-Y Generator) relies on one-way
permutations. In this lecture, we want to extend it into regular one-way
function. Of course, the ultimate goal is PRG from <strong>any</strong> one-way function, but
it seems a little bit too involved for this lecture.</p>
<h4 id="entropy">Entropy<a hidden class="anchor" aria-hidden="true" href="#entropy">#</a></h4>
<p>Min entropy measures unpredictability. Conditional entropy is expectation on the
conditional maximum entropy.</p>
<dl>
<dt>Min Entropy</dt>
<dd>\(\minentropy{X} := -\log \max_{x} \Pr[X=x]\)</dd>
<dt>Average Min Entropy</dt>
<dd>\( \minentropy{X|Z} := -\log \mathsf{E}_{z}[\max_{x}\Pr[X=x|Z=z]]\)</dd>
</dl>
<p>The condition \(Z\) can be understood as leakage: if \(\minentropy{X|Z} \ge k\) then
\[\Pr_{X,Z}[A(z) = x]\le 2^{{-k}}\]</p>
<p>Consider the game of guessing randomly sampled \(x\) given \(f(x)\) &ndash; modified
inversion game (but succeed only if \(x^{\prime}\) is exactly the sampled \(x\)).</p>
<p>We can relax \(A\) to PPT to get <strong>pseudo-entropy</strong>.</p>
<p>The unpredictable pseudoentropy is thus defined as \[H_{u}(X|Z) = -\log
\max_{A}\Pr_{x,z}[x = A(z)].\]</p>
<p>Consider a \(2^{k}\)-regular \(\epsilon\)-regular OWF. We have \[H_{u}(X|f(X)) =
\log{1/\epsilon} + k.\]</p>
<h4 id="statistical-and-computational-distance">Statistical and Computational Distance<a hidden class="anchor" aria-hidden="true" href="#statistical-and-computational-distance">#</a></h4>
<p>Statistical distance is the maximum distinguishing probability of <strong>any</strong>
algorithm distinguishing two distributions.</p>
<p>\[\mathsf{SD}(X,Y) := \max_{D}\left|\Pr[D(X)= 1] - \Pr[D(Y) = 1]\right|,\]</p>
<p>Here \(D\) can be unbounded.</p>
<p>Computational distance is the result when relaxing the algorithm to PPT.</p>
<p>\[\mathsf{CD}(X,Y) := \max_{\ppt D}\left|\Pr[D(X) = 1] - \Pr[D(Y) = 1]\right|,\]</p>
<p>here \(D\) is limited to PPT.</p>
<h4 id="randomness-extraction">Randomness Extraction<a hidden class="anchor" aria-hidden="true" href="#randomness-extraction">#</a></h4>
<p>In short LHL and GL-theorem are both randomness extractors. The former one is
statistical while the latter one is computational.</p>
<p>Leftover Hash Lemma: Let (\(X\), \(Z\)) be any r.v. with \(\minentropy{X|Z} = k\) and
let \(h:\{0,1\}^{n} \to \{0,1\}^{k-d}\) be a (family of) universal hash
function, then we have</p>
<p>\[\mathsf{SD}((h, Z, h(x)), (h, Z, U_{k-d})) \leq 2^{-d/2}.\]</p>
<p>Goldreich-Levin Theorem: Let (\(X\), \(Z\)) be any r.v. with \(H_{u}(X|Z) = k\) then
there exists efficient hash \(h: \{0,1\}^{n}\to \{0,1\}^{L = O(k)}\) such that</p>
<p>\[\mathsf{CD}((h, Z, h(x)), (h, Z, U_{L})) \leq 2^{-\Omega{k}}\]</p>
<p>Normally we have \(k = \omega{k}\) (at least superpolynomial hardness), so the
computational distance is negligible.</p>
<h4 id="pseudoentropy-of-regular-owf">Pseudoentropy of regular OWF<a hidden class="anchor" aria-hidden="true" href="#pseudoentropy-of-regular-owf">#</a></h4>
<p>What is the UP of \(X\) given \(f(X)\) if \(f\) is a regular \(\epsilon\) OWF with
regularity \(\alpha = 2^{k}\)</p>
<p>The min-entropy is clearly \(k\) bits, but computationally speaking, we can do
better.</p>
<p>Claim: \(H_{u}(X|f(X)) = k + \log{1/\epsilon}\), where \[ \Pr_{{X}}[A(f(X)) \in
f^{-1}(f(X))] \le \epsilon \] And therefore \[ \Pr_{{X}}[A(f(X)) = X] \le
2^{-k}\epsilon \]</p>
<p>We can understand it in this way. Let event &ldquo;A succeeds&rdquo; denotes the event that
\(A\) successfully guesses the exact preimage. Then we have</p>
<p>\begin{align*}
\Pr[\text{A succeeds}] &amp;= \Pr[\text{A outputs coset}\land\text{A hits}] \\
&amp;= \Pr[\text{A outputs coset}]\cdot \Pr[\text{A hits}| \text{A outputs coset}] \\
&amp;= 2^{-k} \cdot \Pr[\text{A outputs coset}]\enspace,
\end{align*}</p>
<p>where by &ldquo;A outputs coset&rdquo; I mean the event A&rsquo;s output is in \(f^{-1}(f(x))\). The
last equality holds since when A output something in that set, the probability
it succeeds is exactly \(2^{-k}\).</p>
<h4 id="prgs-from-known-regular-owfs">PRGs from Known Regular OWFs<a hidden class="anchor" aria-hidden="true" href="#prgs-from-known-regular-owfs">#</a></h4>
<p>Proof given in Goldreich&rsquo;s book. Very complex, uses three hashes.</p>
<p>We have an alternative 3-line proof.</p>
<p>Assumption: \(f\) is \(\epsilon\)-one-way and \(2^{k}\) regular</p>
<ol>
<li>Hash \(f(X)\) to extract \(n-k\) bit (\(h_{1}(f(X))\)), since \(\minentropy{f(X)} = n-k\) (note that
we ignored entropy loss)</li>
<li>Hash \(X\) to extract \(k\) bits (\(h_{2}(X)\)), since \(\minentropy{X|f(X)} = k\) (once again,
entropy loss ignored.)</li>
<li>The key. Using chain rule \(H_{u}(X|f(X)) = k + \log(1/\epsilon)\) then
\[H_{u}(X|f(X), h_{2}(X)) \ge \log{1/\epsilon},\] Now extract
\(O(\log(1/\epsilon))\) bits using hard-core function \(h_{c}\).</li>
</ol>
<p>It is clear that the third step is crucial for gaining stretch.</p>
<p>Finally, use a hybrid argument to prove combined distribution is pseudorandom.
In particular, since it took me a while to see it clear, I might as well write
down for possible future reference.</p>
<p>Proposition: (\(h_{1}(f(X))\), \(h_{2}(X)\), \(h_{c}(X)\), \(h_{1}\), \(h_{2}\), \(h_{c}\))
is pseudorandom.</p>
<p>Proof. Consider hybrid distribution \[H_{1} := (h_{1}(f(X)), h_{2}(X), U_{L},
h_{1}, h_{2}, h_{c})\]</p>
<p>By GL-theorem, we have</p>
<p>\begin{align*}
\mathsf{CD}(h_{c}(X)), U_{L} | f(X), h_{2}(X), h_{2}, h_{c}) &amp;\le 2^{-\Omega(L)}\\
&amp;\le\Omega(\epsilon)
\end{align*}</p>
<p>Which means Hybrid 1 is indistinguishable to the real distribution.</p>
<p>Now Consider hybrid distribution 2</p>
<p>\[H_{2} := (h_{1}(f(X)), U_{k}, U_{L}, h_{1}, h_{2}, h_{c}). \]</p>
<p>By leftover hash lemma, we have</p>
<p>\begin{align*}
\mathsf{SD}(h_{2}(X), U_{k} | h_{2}, f(X)) \leq 2^{-d/2}
\end{align*}</p>
<p>For some properly chosen \(d\) to be super logarithmic. This implies hybird 1 and
hybrid 2 are indistinghishable.</p>
<p>Finally, consider Hybrid distribution 3</p>
<p>\[H_{3}:= (h_{1}(U_{n-k}), U_{k}, U_{L}, h_{1}, h_{2}, h_{c})\]</p>
<p>By leftover hash lemma, we have</p>
<p>\begin{align*}
\mathsf{SD}(h_{1}(f(X)), U_{n-k} | h_{1}) \leq 2^{{-d/2}}
\end{align*}</p>
<p>Once again, for some properly chosen \(d\). This implies hybrid 2 and hybrid 3 are
indistinguishable. Altogether, this concludes the proof.</p>
<p>The construction is optimum because it only calls \(f\) once and seed length is
linear in \(n\).</p>
<p>Multi-bit GL-Theorem is indeed worth investigating. From a facile result it
seems that \(h_{c}(x)\) is \(2^{m} (n\epsilon)^{1/3}\) close to \(U_{m}\).</p>
<h4 id="prgs-from-unknown-regular-owfs">PRGs from unknown-regular OWFs<a hidden class="anchor" aria-hidden="true" href="#prgs-from-unknown-regular-owfs">#</a></h4>
<p>The randomized iterate (CRYPTO 2006). The proof is again, too complex.</p>
<h4 id="lower-bounds--focs12">Lower Bounds (FOCS12)<a hidden class="anchor" aria-hidden="true" href="#lower-bounds--focs12">#</a></h4>
<p>Any black-box construction of PRG must make \(\Omega(n/\log n)\) calls to the OWF
to make PRG.</p>
<h4 id="prg-from-unknown-regular-owfs">PRG from unknown-regular OWFs<a hidden class="anchor" aria-hidden="true" href="#prg-from-unknown-regular-owfs">#</a></h4>
<p>Assumption: \(f\) is \(\epsilon\) regular and \(2^{k}\) regular (but \(k\) is unknown).</p>
<p>Let \(Y\) be the range of OWF, we define \(\bar{f}\) that is \(2^{n}\)-regular.</p>
<p>\begin{align*}
\bar{f}: Y \times \{0,1\}^{n} &amp;\to Y \\
\bar{f}:(y,r) &amp;\mapsto f(y\oplus r)
\end{align*}</p>
<p>If we call the vanilla construction for regular OWFs, then there is a problem.</p>
<p>To sample \(Y\) we need \(n\) bit, this makes the stretch negative.</p>
<p>To make it positive, we need to iterate it using hybrid argument.</p>
<p>This means we have to iterate \(\frac{n}{\log{1/\epsilon}}\) times to get a
positive stretch, which is tight (from FOCS 2012, BB constructions of PRG
requires \(\Omega(n / \log(1/\epsilon))\) OWF calls and \(\Omega(n / \log n)\) calls
in general.)</p>
<h3 id="pseudorandom-function">Pseudorandom Function<a hidden class="anchor" aria-hidden="true" href="#pseudorandom-function">#</a></h3>
<p>Security under CPA.</p>
<p>Adversary has oracle access to the encryption algorithm.</p>
<p>We can achieve CPA security (Secret-Key) from PRFs. The definition of \(\prf\) is
a family of keyed functions that is indistinguishable from random function given
oracle access.</p>
<p>An alternative definition is the distinguishing probability of any polynomial
points is negligible.</p>
<p>Is the two definition equivalent? Prof. Yu later changed this definition so that
the query does not depend on previous query results. This is clearly weaker. But
I think the &ldquo;forall&rdquo; type is equivalent. NOPE, you are trolled. In the
non-adaptive defintion, the query is independent on the key choice. The <strong>weak</strong>
PRF definition typically follows this syntax.</p>
<h3 id="why-pseudorandom">Why Pseudorandom<a hidden class="anchor" aria-hidden="true" href="#why-pseudorandom">#</a></h3>
<p>Efficient and equivalent to random function.</p>
<p>From PRF we immediately get a CPA-based encryption.</p>
<h3 id="the-ggm-construction-of-prf">The GGM Construction of PRF<a hidden class="anchor" aria-hidden="true" href="#the-ggm-construction-of-prf">#</a></h3>
<p>Let \(g\) be a length-doubling PRG, then we seek to construct a PRF from this \(g\).
Input \(x\) determines a path from root (the key) to leaf (the output).</p>
<p>\(g(x) = g_{1}(x) || g_{2}(x)\)</p>
<p>Parallel repetitiion of the PRG is still a PRG from a standard hybrid argument.</p>
<h4 id="first-attempt-shallow-ggm-tree">First Attempt: Shallow GGM Tree<a hidden class="anchor" aria-hidden="true" href="#first-attempt-shallow-ggm-tree">#</a></h4>
<p>Consider a \(l = O(\log n)\) depth tree. Then we can argue the stronger result
that the range concatenated is pseudorandom. The proof is a hybird argument by
replacing from layer 1 to layer \(l\) by uniform random. Since generating the
whole tree takes only polynomial time and the width of any layer is at most
polynomial, the proof follows by a standard hybrid argument.</p>
<p>But we need not to prove such a strong case. We can instead replace the oracle.</p>
<h4 id="the-general-case-of-ggm">The General Case of GGM<a hidden class="anchor" aria-hidden="true" href="#the-general-case-of-ggm">#</a></h4>
<p>Theorem: If \(g\) is a (\(t\), \(\epsilon\))-\(\prg\) and \(g\) is computable in
\(t_{g}\), then \(F\) is a (\(t^{\prime} = t/O(nt_{g})\), \(\epsilon n
t^{\prime}\))-\(\prf\).</p>
<p>We then construct \(n\) hybrids where \(H_{i}\) is the previous \(i\) layers replaced
by uniform random. Clearly \(H_{0}\) is the \(F\) distribution and \(H_{n}\) is
uniformly random.</p>
<p>The \(t^{\prime}\) term in the statment trolled me for a while, before I tried to
prove it myself and I realized that it is a clever choice of parameter to enable
a simpler result.</p>
<p>In particular, we need \(O(t^{\prime})\) samples (\(2n\) pseudorandom / random
bits), and simulation of the oracle takes \(O(t^{\prime} n t_{g}\) overhead.
Altogether, this implies \(t^{\prime} + O(t^{\prime} t_{g} n)\) time algorithm for
\(t^{\prime}\) samples. (Since for advantage, we have no trouble, it is skipped.)
We now need to have \(t^{\prime} + O(t^{\prime} t_{g} n) &lt; t - t^{\prime} t_{g}\)
to make use of the \(t\) bound. By setting \(t^{\prime} = t / O(n t_{g})\) we can
get this result.</p>
<h4 id="exercise-domain-extension-for-prfs-19-20-2-lecture-6-exercises">Exercise: Domain Extension for PRFs {#19-20-2 Lecture 6 Exercises}<a hidden class="anchor" aria-hidden="true" href="#exercise-domain-extension-for-prfs-19-20-2-lecture-6-exercises">#</a></h4>
<p>Levin&rsquo;s Trick: For any \(l\le n \in \NN\), let \(R_{1}\) be a random function
distribution over \(\{0,1\}^{l}\to\{0,1\}^{n}\) and \(H\) be a family of UHF
from \(n\) to \(l\), then argue that \(R_{1}(H_{{1}}(\cdot))\) is indistinguishable
from \(n\) to \(n\) random function.</p>
<p>Proof (informal). Consider an adversary that makes at most \(q\) queries to the
oracle, when non of the \(q\) queries collide, the output distribution is exactly
the same in \(R_{1}\circ H_{1}\) as in \(R\). So if we managed to argue this event
happens with probability \(1-\epsilon\) then the advantage between distinguishing
these two oracles are at most \(\epsilon\).</p>
<p>Consider the event that collision do happen. We denote \(\text{Collide}_{i}\) the
event that the \(i^{\text{th}}\) query becomes the first collision. It follows
from union bound that \[\Pr[\text{Collide}] \le
\sum_{i}\Pr[\text{Collide}_{i}]\] Where the probability is over random choice of
\(R_{1}\), \(H_{1}\), and the querying algorithm. The observation here is that when
\(\text{Collide}_{i}\) occurs, the first \(i-1\) oracle outputs are independently
random. And thus the information of \(H_{1}\) has not increased from these
outputs. Therefore, \[\text{Collide}_{i} \le \frac{i-1}{2^{l}}\] From another
union bound using the uniform hash property.</p>
<p>Altogether, this implies \[\Pr[\text{Collide}] \le \frac{q^{2}}{2^{l+1}},\]
Which is arguably good enough when \(l\) is not too small (e.g. \(1/2n\)).</p>
<!--list-separator-->
<ul>
<li>
<p>Bibliography</p>
<p>I did some research for a more rigorous proof, and all references point to a
paper by Levin in Combinatorica 1987: <a href="https://link.springer.com/article/10.1007/BF02579323">One way functions and pseudorandom
generator</a>. But it seems that from Nico&rsquo;s paper in CRYPTO 2015 &mdash; <a href="https://link.springer.com/chapter/10.1007%2F978-3-662-47989-6_16">Efficient
pseudorandom functions via on-the-fly adaption</a> that this results can be improved
when \(l\) is not big enough. The original paper is scanned and is in terrible
readability. So I may only consider reading it after I confirmed that my
aforementioned proof is incomplete.</p>
</li>
</ul>
<h2 id="lecture-7">Lecture 7<a hidden class="anchor" aria-hidden="true" href="#lecture-7">#</a></h2>
<h3 id="prf">PRF<a hidden class="anchor" aria-hidden="true" href="#prf">#</a></h3>
<p>PRF from PRG using GGM tree. Two proofs, the first one is a strong result, but
with limitation. The second one relaxed the result, but is able to prove
polynomial depth results.</p>
<h3 id="pseudorandom-functions-in-almost-constant-depth-from-low-noise-lpn">Pseudorandom functions in almost constant depth from low-noise LPN<a hidden class="anchor" aria-hidden="true" href="#pseudorandom-functions-in-almost-constant-depth-from-low-noise-lpn">#</a></h3>
<p>First introduce the LPN problem.</p>
<dl>
<dt>Search LPN</dt>
<dd>given a, \(y = ax+e\), find out \(x\)</dd>
<dt>Decisional LPN</dt>
<dd>distinguish \((a, y)\) with \(a, U_{q}\)</dd>
</dl>
<p>The two versions are polynomially equivalent.</p>
<p>Another fact. LPN and Hermite normal forms are equivalent.</p>
<ul>
<li>LPN \(\le\) HLPN, we have a \(n\) loss in query complexity</li>
<li>HLPN \(\le\) LPN, add uniform secret to LPN sample. No loss whatsoever and noise can be arbitrary.</li>
</ul>
<p>In the following construction, we assume \(x,e\) are both Bernoulli.</p>
<h4 id="hardness-of-lpn">Hardness of LPN<a hidden class="anchor" aria-hidden="true" href="#hardness-of-lpn">#</a></h4>
<p>Worst case hardness: decoding linear code Average-case hardness: BKW algorithm</p>
<ul>
<li>For constant noise \(\mu\) BKW: \(t = q = 2^{O(n/\log n)}\). Vadim&rsquo;s tradeoff: \(t = 2^{O(n/\log\log n)}\), \(q = n^{1 + \epsilon}\). For \(q = O(n)\), the best algorithm is \(t = 2^{{O(n)}}\).</li>
<li>For low noise LPN \(\mu = n^{-c}\). The best algorithm has \(t = poly(n,q)e^{n^{1-c}}\).</li>
</ul>
<h4 id="related-works">Related Works<a hidden class="anchor" aria-hidden="true" href="#related-works">#</a></h4>
<p>LPN to PRG, PRF, CCA PKE, etc.</p>
<h4 id="main-results">Main Results<a hidden class="anchor" aria-hidden="true" href="#main-results">#</a></h4>
<ul>
<li>Polynomial-stretch PRG in \(\AC_{0} \mod 2\)</li>
<li>PRF in \(\tilde{\AC_{0}} \mod 2\) (depth is \(\omega(1)\))</li>
</ul>
<p>Infeasibility result: quasi-polynomial hard PRF in \(\AC_0\) is impossible.</p>
<h4 id="notions">Notions<a hidden class="anchor" aria-hidden="true" href="#notions">#</a></h4>
<p>In this result, we consider randomized PRG, PRF.</p>
<p>We consider shared random matrix \(A\). This will incur a security loss from
hybrid argument (the secret now is a matrix rather than a vector).</p>
<p>Randomized PRF in this work is weak PRF.</p>
<h4 id="prg">PRG<a hidden class="anchor" aria-hidden="true" href="#prg">#</a></h4>
<p>We use an sampler/extractor to convert almost all entropy of input w into
Bernoulli-like noise \(x,e\).</p>
<p>Assume noise \(\mu = 2^{-i}\) for \(i\in\NN\). For \(\mu = n^{-c}\) (\(i = c\log
n\)), Shannon entropy of \(Ber_{\mu}\) \(\approx \mu\log(1/\mu)\).</p>
<p>This is very wastful for randomness. There are two solutions</p>
<ol>
<li>[Applebaum et al. 09], recycle randomness from \(r\).</li>
<li>[Yu Zhang 16], first use a <strong>pairwise</strong> independent hash function to expand randomness, then use AND to sample noise.</li>
</ol>
<p>Theorem: Let \(h_1, h_2, \ldots, h_q\) be 2-wise independent hash function, for
any source \(w\) of collision entropy \(\lambda\), and any constant \(0 &lt; \delta
\le 1\)</p>
<p>\[ \mathsf{SD}((a, (e_1, \ldots, e_q), (a, Ber_{\mu}^q))) &lt; \delta. \]</p>
<p>Alternative Bernoulli noise sampler &ndash; Bitwise OR, but can only use uniform
random input.</p>
<p>Theorem. Assume that the DLPN is (\(q = O(n)\), \(t\), \(\epsilon\))-hard on
input of size n</p>
<h4 id="prf">PRF<a hidden class="anchor" aria-hidden="true" href="#prf">#</a></h4>
<p>We assume there is a PRG with \(n\)-bit input and \(n^2\)-bit output. (i.e. a
synthesizer ?)</p>
<ol>
<li>Use GGM construction of depth \(d = \omega(1)\) to get a PRF of input size \(\omega(\log n)\)</li>
<li>Domain extension from \(\{0,1\}^{n}\) to \(\{0,1\}^{\omega{\log n}}\) using <strong>generalized</strong> levin&rsquo;s trick.</li>
</ol>
<h3 id="pseudorandom-permutation">Pseudorandom Permutation<a hidden class="anchor" aria-hidden="true" href="#pseudorandom-permutation">#</a></h3>
<p>Definition. <img loading="lazy" src="/ox-hugo/PRP.png" alt=""  />
</p>
<p>This definition follows a common paradigm in cryptography: efficient
approximation of ideal world from real world.</p>
<p>Feistel Networks: from PRF to PRP <img loading="lazy" src="/ox-hugo/feistel.png" alt=""  />
</p>
<p>The feature here is that both the permutation and its inverse are efficiently
computable. And it can be easily concatenated.</p>
<p>The Luby-Rackoff PRP from PRF: four round construction.</p>
<p>Proof sketch. Seems like we can use RO-like argument for first four hybrids, in
the final hybrid, i.e. using random function to implement a random permutation.
It seems like birthday attack is unavoidable in this case.</p>
<p>What if we reduce the network to three rounds? This suffices for
indistinguishability for only encryption oracle, rather than the evaluation
oracle.</p>
<p>What about two rounds? If we first do a hash function \(h_1\) at the beginning
and hash the two round output \(h_2\) after the end, we can do a PRP from two
round Feistel.</p>
<h3 id="constructions-of-block-ciphers">Constructions of Block Ciphers<a hidden class="anchor" aria-hidden="true" href="#constructions-of-block-ciphers">#</a></h3>
<p>Ideal vs. Reality</p>
<h4 id="in-theory">In theory<a hidden class="anchor" aria-hidden="true" href="#in-theory">#</a></h4>
<p>One-way function (actually, we learned OWP, regular OWF, not any OWF) -&gt; PRG -&gt;
PRF -&gt; PRP</p>
<h4 id="in-practice">In practice<a hidden class="anchor" aria-hidden="true" href="#in-practice">#</a></h4>
<p>Built from scratch: AES / DES</p>
<h3 id="a-prp-can-is-a-prf-up-to-a-birthday-bound">A PRP can is a PRF up to a birthday bound<a hidden class="anchor" aria-hidden="true" href="#a-prp-can-is-a-prf-up-to-a-birthday-bound">#</a></h3>
<p>A PRP is at first, a PRF. In practice, PRP is acquired easily from AES. But
permutation is a class more &ldquo;structured&rdquo; than random functions. So there is a
gap (luckily not too big) between PRF and PRP.</p>
<p>Lemma. A (\(t\), \(\epsilon\), \(q\))-secure PRP on n-bits is a (\(t\),
\(\epsilon + \frac{O(q^2)}{2^n}\), \(q\))-PRF.</p>
<p>Proof.</p>
<ul>
<li>Any (t, q)-Adv distinguishes PRP from RP with advantage \(\le \epsilon\).</li>
<li>Any (\(\infty\), q)-Adv distinguishes RP from RF with advantage \(O(q^{2}/2^{n})/\).</li>
</ul>
<h3 id="mode-of-operation">Mode of Operation<a hidden class="anchor" aria-hidden="true" href="#mode-of-operation">#</a></h3>
<p>Direct use of a block cipher is not recommended. Message are a multiple of the
cipher block size in length. The solution is different mode of operations.</p>
<ul>
<li>ECB (insecure)</li>
<li>Cipher Block Chaining</li>
<li>Cipher Feedback</li>
<li>Output Feedback</li>
<li>Counter (the difference from \(r, \prf_{k}( r)   \oplus x\) is that CTR hash shorter ct, but is stateful)</li>
</ul>
<h3 id="pseudoentropy-and-pseudorandomness-extraction">Pseudoentropy and Pseudorandomness Extraction<a hidden class="anchor" aria-hidden="true" href="#pseudoentropy-and-pseudorandomness-extraction">#</a></h3>
<p>Two types of Pseudoentropy.</p>
<dl>
<dt>HILL pseudoentropy</dt>
<dd>X has k bit HILL pentropy if it is indistinguishable in the non-uniform model from a k-bit unpredictable (unconditional) distribution.</dd>
<dt>Metric-type pseudoentropy</dt>
<dd>X has k bit Metrix type pseudoentropy if for every circuit D of size s there exists a distribution of at least k-bit min-entropy that is indistinghishable by \(D\) from \(X\).</dd>
</dl>
<h2 id="lecture-8">Lecture 8<a hidden class="anchor" aria-hidden="true" href="#lecture-8">#</a></h2>
<p>Pseudoentropy and pseudorandomness extraction.</p>
<h3 id="pseudoentropy">Pseudoentropy<a hidden class="anchor" aria-hidden="true" href="#pseudoentropy">#</a></h3>
<p>HILL and metric-type pesudoentropy.</p>
<ol>
<li>HILL pseudoentropy.
We say \(X\) has HILL pseudoentropy \(k\) if there exists a distribution
\(Y\) where \(\minentropy{Y} \ge k\) and \(\mathsf{CD}(X, Y) \leq \epsilon\).</li>
<li>Metric-type pseudoentropy.
We say \(X\) has metric-type pseudoentropy \(k\) if for every circuit \(D\)
of size \(s\) there exists a distribution \(Y\) with \(\minentropy{Y} \ge k\)
and \(\delta^D(X, Y) \le \epsilon\).</li>
</ol>
<p>Borak proved 2 implies 1 using von Neumman&rsquo;s Min-Max theorem. The idea is to
prove after exchanging the quantifiers, the result is to some extent,
equivalent.</p>
<h3 id="pseudoentropy-of-prg-conditioned-on-leakage">Pseudoentropy of PRG conditioned on leakage<a hidden class="anchor" aria-hidden="true" href="#pseudoentropy-of-prg-conditioned-on-leakage">#</a></h3>
<p>If \(\prg : \{0,1\}^n \to \{0,1\}^m\) and \(f : \{0,1\}^n \to
\{0,1\}^{\lambda}\) <img loading="lazy" src="/ox-hugo/prg_pseudoentropy.png" alt=""  />
</p>
<p>Without leakage, the pseudoentropy of PRG output is trivial. We want to prove
similar result conditioned on arbitrary leakage.</p>
<p>Why do we use probability instead of plain assertion? The reason is that some
leakage can be drastic. Using probability we can bypass this limitation. E.g.
the leakage function \(f\) is the hamming weight of input. If we observed that
\(f(x) = 0\), then it holds that \(x = 0\).</p>
<p>From the previous lemma 7, we only have to prove equation (4), which is a
seemingly weaker (and hopefully easier to prove) result.</p>
<p>This lecture is based on a FOCS 2008 paper: *Leakage Resilient Cryptography*这是一篇经典论文，贡献是</p>
<ol>
<li>
<p>结论非常庞大，而且它试图通过理论的方法解决实际密码实现上的问题</p>
</li>
<li>
<p>证明过程中的一个结论是 Dense Model Theorem, 它与Green-Tao定理存在着联系</p>
<p>Green-Tao: 质数包含所有长度的等差数列，即给定\(\ell\)，存在差为\(\ell\)的素数等差数列</p>
<p>我们使用集合上的Dense Model Theorem。</p>
</li>
</ol>
<p>Proof overview. <img loading="lazy" src="/ox-hugo/proof_stoc_2008.png" alt=""  />
</p>
<p>First consider the complement of the event, what we want to prove is &hellip;</p>
<p>One tricky part is that you can assume a 0-1 distinguisher can output one real
number. This special type of distinguisher can be implied by standard
distinguishers, by apprximating the probability \(\Pr[D=1]\).</p>
<p>Anyway, the proof showed that PRG is still secure under leakage. In particular,
we have for a \(\prg\), there exists a high-entropy \(Y\) such that \(\prg(X),
f(X)\) is indistinguishable from \(Y, f(Y)\). We can therefore use an extractor
to extract randomness from \(Y | f(Y)\). This means that even for leaky source,
we can extract randomness from PRG&rsquo;s output using randomness extractor (e.g.
universal hash function).</p>
<h3 id="non-uniform-key-wprf">Non-Uniform Key wPRF<a hidden class="anchor" aria-hidden="true" href="#non-uniform-key-wprf">#</a></h3>
<p>For a weak PRF, if we choose key to be slightly non-uniform, will the output
still be pseudorandom? <img loading="lazy" src="/ox-hugo/wPRF_leak.png" alt=""  />
</p>
<p>If you are interested, please refer to STOC 2008, EC 2009 (a simplified proof is
presented in TCC 2013).</p>
<h3 id="exercises">Exercises<a hidden class="anchor" aria-hidden="true" href="#exercises">#</a></h3>
<h4 id="existence-of-independent-code">Existence of Independent Code<a hidden class="anchor" aria-hidden="true" href="#existence-of-independent-code">#</a></h4>
<p>Independent code: \(k\)-independent and \(k = n\) means that the code \(C\) is
MDS code, which is trivial for \(\FF_2\), so typically we have \(k &lt; n\).</p>
<p>We relex the condition to proving a good enough probability over the choice of
\(C\).</p>
<p>We first expand the probability in to summation over \(r\), and then observe
that for random \(C\), since \(r\) is pair-wise disjoint, the r.v. \(Cr_1\) and
\(Cr_2\) are independent for any \(r_1 \ne r_2\). Notice that altogether they
are not independent (consider \(r_3 = r_1 + r_2\)). We can then use Chebyshev&rsquo;s
inequality to get the result.</p>
<h4 id="one-time-mac">One-Time MAC<a hidden class="anchor" aria-hidden="true" href="#one-time-mac">#</a></h4>
<p>Universal hash function</p>
<h4 id="collision-entropy-and-min-entropy-equivalence">Collision Entropy and Min-Entropy Equivalence<a hidden class="anchor" aria-hidden="true" href="#collision-entropy-and-min-entropy-equivalence">#</a></h4>
<p>Use Markov inequality.</p>
<h4 id="prg-from-lpn">PRG from LPN<a hidden class="anchor" aria-hidden="true" href="#prg-from-lpn">#</a></h4>
<p>One trick &mdash; flattening Shannon entropy. For \(H(w) = a\), we have
\(\minentropy{w_1, w_2, \ldots, w_n} \approx na\). The definition-based
conditional min-entorpy is somewhat pessimistic. The flattneing trick can be
userful here.</p>
<h2 id="lecture-9">Lecture 9<a hidden class="anchor" aria-hidden="true" href="#lecture-9">#</a></h2>
<h3 id="exercise-solutions">Exercise Solutions<a hidden class="anchor" aria-hidden="true" href="#exercise-solutions">#</a></h3>
<h4 id="prg-from-lpn">PRG from LPN<a hidden class="anchor" aria-hidden="true" href="#prg-from-lpn">#</a></h4>
<p>First of all standard LPN with \(q = 2n\) and \(\mu = \frac{1}{4}\) implies
Hermite normal form LPN&rsquo; where secret follows noise distribution
\(Ber_{\mu}^n\).</p>
<p>So we first sample a \(4n\)-bit random number, and then through bitwise-AND, get
a \(2n\)-bit random Bernoulli noise. Conditioned on this output, we still have
whp. \(\frac{3n}{2} - \lambda\) 2-bit pairs that have \(\log 3\) entropy.</p>
<p>Procedure:</p>
<ul>
<li>First sample \(x, e\) from \(4n\)-bit uniform randomness.</li>
<li>Then output \(A x + e\), and use randomness extractor to extract \(2n + \lambda\) bits.</li>
</ul>
<h4 id="search-lpn-and-decision-lpn">Search-LPN and Decision-LPN<a hidden class="anchor" aria-hidden="true" href="#search-lpn-and-decision-lpn">#</a></h4>
<p>From Decision-LPN to Search-LPN: Compute \(x\) and accept iff. the hamming
weight of \(y - Ax\) is small.</p>
<p>If input \(A, y\) follows LPN distribution, the algorithm will accept whp. If
the input follows uniform distribution, then from the fact that</p>
<p>\begin{equation*}
\Pr_{A, y} [ \exists s, |y - As| \le \lambda ] \le
2^{ -m + n + \lambda \log(m) },
\end{equation*}</p>
<p>we conclude that the probability the algorithm accept is bounded
by the previous negligible probability.</p>
<p>From Search-LPN to Decision-LPN: There are at least three very related methods.</p>
<p>The first one is the most &ldquo;orthodox&rdquo; one. Construct hybrid \(H_0\),
\(H_1\), \(\ldots\), \(H_q\). \(H_0\) is the LPN distribution, and
\(H_q\) is the uniform distribution. Using GL theorem we can conclude
from the one-wayness of LPN, changing \(a_i^T x\) to \(U_1\) is
indistinguishable. So by hybrid argument we can conclude that \(H_0\)
and \(H_q\) are indistinguishable.</p>
<p>Or we can follow the second way: using the LWE-like solver, solving the secret
bit-by-bit.</p>
<p>Finally, we can use a very unorthodox method, without hybrid argument. Suppose
there is a distinguisher that distinguishes LPN distribution and uniform
distribution, then we can construct an algorithm that on input \(A, Ax+e, r\),
output \(r^T, x\) with high probability. And from GL-theorem&rsquo;s proof (the list
decoding algorithm), this implies a solver for \(x\).</p>
<p>How to do that? First samples \(u \leftarrow \{0,1\}^q\), and then let \(\bar{A}
= A - u\cdot r^T\). Observe that</p>
<p>\begin{align}
A x + e &amp;= (\bar{A} + u r^T) x + e \\
&amp; = \bar{A} x + e + u (r^T x)\enspace.
\end{align}</p>
<p>So when \(r^Tx = 0\), \(Ax + e\) follows LPN distribution with \(\bar{A}\) as
public matrix, whereas when \(r^T x = 1\) output is random.</p>
<p>And thus \(\bar{A}, y = Ax+e\) follows</p>
<ul>
<li>LPN distribution when \(r^T x = 0\)</li>
<li>Uniform distribution when \(r^T x = 1\)</li>
</ul>
<p>This implies an effective distinguisher for the GL-hardcore.</p>
<h4 id="domain-extension">Domain Extension<a hidden class="anchor" aria-hidden="true" href="#domain-extension">#</a></h4>
<p>Conditioned on no collision at \(R_1\), the two distributions are identical. So
we only have to bound the probability of collision. And the probability is just
a birthday attack bound. As a matter of details, I think the probability should
be computed as</p>
<p>\begin{equation}
\Pr[\neg \text{Collision}] \ge (1) (1 - \frac{1}{2^l}) (1 - \frac{2}{2^l})\ldots
(1 - \frac{q-1}{2^l}) = 1 - O(\frac{q^2}{2^{l+1}})\enspace,
\end{equation}</p>
<p>whereas I am
not sure how to formulate the \(\binom{q}{2}\)-pair bound, since collision can
occur at each level.</p>
<p>One tricky part is that after query, the hash function \(h\) can be made public.
So the attack can be made a two-stage process. First the attacker is given
oracle access to a PRF (\(R^{\prime} = R \circ H\)), and in the second stage,
the attacker is given the transcript of the attack, along with the hash
function. This is clearly a relaxation, but does not affect security.</p>
<h3 id="crhf-and-uowhf">CRHF and UOWHF<a hidden class="anchor" aria-hidden="true" href="#crhf-and-uowhf">#</a></h3>
<p>U(OW)HF is an one-way version of UHF. CRHF is considered to be the strongest
primitive in symmetric cryptography, although no black-box construction based on
OWF exists.</p>
<h4 id="collision-resistance-hash-function">Collision Resistance Hash Function<a hidden class="anchor" aria-hidden="true" href="#collision-resistance-hash-function">#</a></h4>
<p>CRHF is a family of Hash funcitons such that:</p>
<dl>
<dt>Efficient</dt>
<dd>polynomial computable sampling and evaluation algorithms</dd>
<dt>Shrinking</dt>
<dd>opposite to stretching</dd>
<dt>Collision Resistant</dt>
<dd>given random instance, any PPT adversary cannot find a collision</dd>
</dl>
<p>\begin{equation}
\Pr_{g\leftarrow G; (x, x^{\prime}) \gets A(1^n, g)} [x\ne x^{\prime}\land g(x) =
g(x^{\prime})] = \mathsf{negl}\end{equation}</p>
<p>Birthday attack. Use \(2^{\frac{m}{2}}\) time to find from \(2^m\)-output domain
a collision with a constant probability (since the collision probability with
random output among \(2^m\) and \(q\) queries is \(\Theta(\frac{q^2}{2^m})\)).
This implies that any CRHF with output size \(m\) has security no more than
\(\frac{m}{2}\).</p>
<p>Practical examples:</p>
<dl>
<dt>MD5</dt>
<dd>output 128bits, broken</dd>
<dt>SHA1</dt>
<dd>output 160bits, broken</dd>
<dt>SHA256</dt>
<dd>output 256bits, unlikely to break</dd>
</dl>
<p>Theoretically black-box construction of CRHF based on OWF is impossible.</p>
<h4 id="universal-one-way-hash-function">Universal One-Way Hash Function<a hidden class="anchor" aria-hidden="true" href="#universal-one-way-hash-function">#</a></h4>
<p>UOWHF is a family of Hash funcitons such that:</p>
<dl>
<dt>Efficient</dt>
<dd>polynomial computable sampling and computing</dd>
<dt>Shrinking</dt>
<dd>opposite to stretching</dd>
<dt>Target Collision Resistant</dt>
<dd>given random instance, a target, any PPT adversary cannot find a collision.
For any \(x\in \{0,1\}^n\),</dd>
</dl>
<p>\begin{equation}
\Pr_{g\leftarrow G; x^{\prime}\gets A(1^n, g,x))} [x\ne x^{\prime}\land g(x) =
g(x^{\prime})] = \mathsf{negl}. \end{equation}</p>
<p>TCR limits the form of collison (by setting a &ldquo;target&rdquo;), so it is a weaker
version of CR.</p>
<p>TCR is equivalent to another notion called TCR2. In this definition, the target
\(x\) is chosen uniformly at random. That TCR implies TCR2 is trivial, while in
the opposite direction, we can construct a TCR hash from a TCR2 hash, by adding
\(n\)-bit to function description, and xoring \(a\) with input before every
evaluation. That is, \(g^{\prime}(x) = g(x \oplus a)\).</p>
<p>The reduction is trivial. Suppose there exists a target \(a\) that allows an
algorithm \(A\) finds collision with non-negligible probability, then we can
first ask TCR2 challenger for a hash function \(g\) and target \(x\), then send
to algorithm \(A\) \(g_{x \oplus a}\) and \(a\). If such a collision \(b\) is
found, it holds that \(g(x) = g(x \oplus a \oplus b)\).</p>
<p>UOWHF is good enough for digital signatures, and it is implied from OWF. This
concept, together with a reduction from OWP, was presented by Naor and Yung.</p>
<p>UOWHF can be seen as dual to PRG.</p>
<h3 id="uowhf-from-owp">UOWHF from OWP<a hidden class="anchor" aria-hidden="true" href="#uowhf-from-owp">#</a></h3>
<p>Let \(f: \{0,1\}^n \to \{0,1\}^n\) be any (\(t\), \(\epsilon\))-one-way
permutation, and \(H\) be a family of universal hash permutations over
\(\{0,1\}^n\),</p>
<p>\begin{equation}
H = \{ h:\{0,1\}^n \to \{0,1\}^{n} | h(y) := h\cdot y, h\ne {\bf 0}, y\in
GF(2^n) \}\enspace,
\end{equation}</p>
<p>let \(\func{trunc}\) be the function that truncates
the last bit of its \(n\)-bit input. Then we argue that</p>
<p>\begin{equation}
G := \{ (\func{trunc} \circ h \circ f) | h\in H \}
\end{equation}</p>
<p>is a family
of (\(t - n^{O(1)}\), \(\epsilon\)) UOWHF with 1bit shrinkage.</p>
<p>\paragraph{Proof} We can construct an inversion algorithm for OWP based on
Collision finder of TCR2. The key is that we can &ldquo;program&rdquo; the hash function in
the middle to meet our need.</p>
<p>Given input \(y\), we first samples \(x^{\prime} \leftarrow \{0,1\}^n\). With
probability \(\frac{1}{2^n}\) we can success at this step (\(f(x^{\prime} =
y\)). If not, we continue by computing \(h = (00\ldots 01)\cdot (y -
x^{\prime})^{-1}\). Notice that this implies j\begin{equation} \func{trunc}
ˆ h ˆ \underbrace{f (x)}<sub>y</sub> = \func{trunc} ˆ h ˆ f
(x<sup>′</sup>)\enspace,
\end{equation}
and since \(x^{\prime} \) and \(x\) are iid, \(h\)
is indeed random. If the inversion algorithm has probability \(\epsilon\) when
the input is \(h, x^{\prime}\), then with the same probability we can find \(x\)
since the hash function is \(2\)-regular. Altogether, we obtain a OWP inverter
that succeed with at least \(\epsilon\) probability.</p>
<h3 id="merkle-damgard-domain-extension-for-crhfs-and-uowhfs">Merkle-Damgard Domain Extension for CRHFs and UOWHFs<a hidden class="anchor" aria-hidden="true" href="#merkle-damgard-domain-extension-for-crhfs-and-uowhfs">#</a></h3>
<p>\begin{lemma}
Let
\begin{equation}
G \subseteq \{ g: \{0,1\}^n \to \{0,1\}^{n-s} \}
\end{equation}
for each
\(g : (x_i,r_i) \to x_{i+1}\), where \(x_i, x_{i+1} \in \{0,1\}^{n-s}\), \(r_i
\in \{0,1\}^s\), be a (\(t\), \(\epsilon\))-secure CRHF, and for any \(q \in
\NN\) define \(G^q \subseteq \{0,1\}^{n + (q-1) s} \to \{0,1\}^{n-s}, g\in
G\) where
\begin{equation}
g^q(x_{1}, r_1, r_2, \ldots, r_q) = g(\ldots g(g(x_1, r_1), r_2), \ldots, r_q).
\end{equation}
Then we have (\(t - q t_g\), \(\epsilon\))-CRHF.
\end{lemma}</p>
<p>\paragraph{Proof} From the &ldquo;bigger&rdquo; collision we can find a smaller collison at
the \(i^{th}\) level such that \(g(x_i, r_i) = g(x^{\prime}_i, r^{\prime}_i)\)
and \((x_i, r_i) \ne (x_i^{\prime}, r_i^{\prime})\). And that contradicts the
assumption that \(g\) is CRHF. The time loss is incurred at the checking step.</p>
<p>\begin{lemma}[Merkle-Damgard Domain Extension for UOWHFs]
Let
\begin{equation}
G \subseteq \{ g: \{0,1\}^n \to \{0,1\}^{n-s} \}
\end{equation}
for each
\(g : (x_i,r_i) \to x_{i+1}\), where \(x_i, x_{i+1} \in \{0,1\}^{n-s}\), \(r_i
\in \{0,1\}^s\), be a (\(t\), \(\epsilon\))-secure UOWHF, and for any \(q \in
\NN\) define \(G^q \subseteq \{0,1\}^{n + (q-1) s} \to \{0,1\}^{n-s}\),
\(g_{1}, g_2, \ldots, g_q \in G\) where
\begin{equation}
g^q(x_{1}, r_1, r_2, \ldots, r_q) = g_q(\ldots g_2(g_1(x_1, r_1), r_2), \ldots,
r_q)\enspace.
\end{equation}
Then we have (\(t - q t_g\), \(q \epsilon \))-UOWHF.
\end{lemma}</p>
<p>\paragraph{Proof} This proof is somewhat tricker than the previous proof, since
we have to embed the target into it. Using the TCR (instead of TCR2) definition,
we can settle with arguing <strong>existential</strong> property, but throughout the proof one
must beware that the target \(y\) must be independent of the UOWHF function
(this is probabilty the reason behind \(q\)-many independent hash functions in
the definition).</p>
<p>Suppose through contradiction, there exists an algorithm running in \(t -
qt_g\)-time and a target \(y = (x_1, r_1, \ldots, r_q)\) such that</p>
<p>\begin{equation*}
\Pr_{g_1,g_2,\ldots,g_q \leftarrow G; y^{\prime} \gets A(y, g_1, \ldots, g_q)} [y
\ne y^{\prime} \land g^q(y) = g^q(y^{\prime})] \ge q\epsilon\enspace,
\end{equation*}</p>
<p>We can find a \(t\)-time algorithm \(A^{\prime}\) and target \((x_i^{*},
r_i^{*})\) finds with at least \(\epsilon\)-probability. First consider a random
index \(i^{*} \leftarrow [q]\), random hash functions \(g_1, \ldots, g_{i^{*} - 1}
\leftarrow G\), and define \(x_i^{*}, r_i^{*} = g^{i^{*} - 1} (x_1, r_1, \ldots,
r_{i^{*} - 1}\). Now we let \(g_{i^{*}} = g\) which is the algorithm
\(A^{\prime}\)&rsquo;s input, and sample the rest hash functions at random.</p>
<p>By the assumption, since our definition of \(q\) hash functions follows the
uniform distribution over \(G^q\), with probability \(q\epsilon\) the algorithm
\(A\) will return a collison \(y^{\prime}\). And since the index \(i^{*}\) is
independent with \(A\)&rsquo;s input, with probability at least \(\frac{1}{q}\), the
collision will occur at position \(i^{*}\). Id est, we can get
\(x_{i^{*}}^{\prime}, r_{i^{*}}^{\prime}\) that constitutes a collision for the
hash function \(g\). Formally, we have</p>
<p>\begin{align*}
&amp; \Pr_{ i^{*} \leftarrow [q]; g \leftarrow G; (x^{\prime}_{i^{*}}, r^{\prime}_{i^{*}})
\gets A(x_{i^{*}}, r_{i^{*}}) } [(x^{\prime}_{i^{*}}, r^{\prime}_{i^{*}}) \ne
(x_{i^{*}}, r_{i^{*}}) \land g(x_{i^{*}}, r_{i^{*}}) = g(x^{\prime}_{i^{*}},
r^{\prime}_{i^{*}})] \\
&amp; \ge \Pr_{\vec{g} \leftarrow G^q; y^{\prime} \leftarrow
A^{\prime}(\vec{g})} [y \ne y^{\prime} \land g^q(y) = g^q(y^{\prime})] \cdot
\Pr_{i^{*} \leftarrow [q]} [i = i^{*}] \\
&amp; \ge q\epsilon \cdot \frac{1}{q} \\
&amp; = \epsilon\enspace.
\end{align*}</p>
<p>Finally, since in the above argument, the target \(x_{i^{*}}, r_{i^{*}}\) only
depends on \(y\) and random choice of \(i^{*}\) and \(g_1, g_2, \ldots,
g_{i^{*} - 1}\), we conclude by average argument there exists one specific
target that has more than ε advantage.</p>
<p>\paragraph{Remarks} It seems that if we use only one hash function in the
construction, the target throughout the argument will be dependent on the hash
function itself, rendering the final averaing argument invalid. It is definitely
an obstacle, whether or not its an artifact I currently have no idea.</p>
<h3 id="merkle-damgard-tree-more-efficient-domain-extension">Merkle-Damgard Tree &mdash; More Efficient Domain Extension<a hidden class="anchor" aria-hidden="true" href="#merkle-damgard-tree-more-efficient-domain-extension">#</a></h3>
<p>If we have a length-halving function, then we can use an &ldquo;inverse&rdquo; GGM tree. One
caveat is that this tree has depth \(O(\log n)\) whereas GGM has linear depth.</p>
<h2 id="lecture-10">Lecture 10<a hidden class="anchor" aria-hidden="true" href="#lecture-10">#</a></h2>
<h3 id="continuing-on-hash-functions">Continuing on hash functions<a hidden class="anchor" aria-hidden="true" href="#continuing-on-hash-functions">#</a></h3>
<p>CRHF is a very natural definition, but no black-box construction based on OWF of
CRHF seems possible. UOWHF has a weaker definition, but still strong enough to
support many applications, including:</p>
<ul>
<li>Digital signatures</li>
<li>Cramer-Shoup PKE scheme</li>
<li>Statistical hiding commitment</li>
</ul>
<p>It should be noted that both UOWHFs and CRHFs are families of functions, rather
than a single one.</p>
<p>We have a simple, effective generic construction based on OWP and UHF. Quite
like the complimentary to the OWP based stretch-1 PRG construction.</p>
<p>Domain extension, in the inverse direction.</p>
<p>In the tree-like construction for UOWHF, one still have to use different
functions in different layers. Though there has not been any proof against using
the same hash function every layer, doing so would render the regular proof
invalid, since we have to embed a target (either <strong>some</strong> target in the TCR
definition or a random target in the TCR2 definition) into the challenge target,
this target has to be independent with the instance \(g\).</p>
<p>Specifically, if we use the instance \(g\) in every layer of the challenge
instance, there is a (seemingly) inherent correlation between \(g\) and the
challenge target \(t^{*}\). On the other hand, if we use independent hashes
every layer, we can guess one instance \(i^{*}\) and embed the input hash
instance \(g\) into that layer. In this case, success happens when the output
collision position coincides with our guess, and the collision target now will
only depend on \(y\) and random choice independent of \(g\). An averaging
argument can then be applied to argue the existence of some valid target.</p>
<h3 id="extension-to-uowhf">Extension to UOWHF<a hidden class="anchor" aria-hidden="true" href="#extension-to-uowhf">#</a></h3>
<p>(Almost) Optimal Constructions of UOWHFs from 1-to-1, Regular One way Functions
and Beyond.</p>
<p>As Prof. Lai pointed out, in some decsipline, 1-to-1 means bijective. So to
clearify the notation, the term &ldquo;1-to-1&rdquo; means injective in this lecture.</p>
<p>CHRFs are UOWHFs, but OWFs imply UOWHFs but not CRHFs.</p>
<h3 id="symmetric-crypto-hierarchy">Symmetric Crypto Hierarchy<a hidden class="anchor" aria-hidden="true" href="#symmetric-crypto-hierarchy">#</a></h3>
<!-- This HTML table template is generated by emacs/table.el -->
<table border="1">
  <tr>
    <td colspan="3" align="left" valign="top">
      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Many&nbsp;Crypto&nbsp;Applications&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
    </td>
  </tr>
  <tr>
    <td align="left" valign="top">
      &nbsp;PRF&nbsp;&nbsp;
    </td>
    <td align="left" valign="top">
      &nbsp;Digital&nbsp;Signature&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
    </td>
    <td align="left" valign="top">
      &nbsp;Stat&nbsp;ZK&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
    </td>
  </tr>
  <tr>
    <td align="left" valign="top">
      &nbsp;PRG&nbsp;&nbsp;
    </td>
    <td align="left" valign="top">
      &nbsp;UOWHFs&nbsp;[NY89,HHRVW10]&nbsp;
    </td>
    <td align="left" valign="top">
      &nbsp;Stat&nbsp;Hiding&nbsp;Com.&nbsp;
    </td>
  </tr>
  <tr>
    <td colspan="3" align="left" valign="top">
      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;One&nbsp;Way&nbsp;Functions&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
    </td>
  </tr>
</table>
<h3 id="duality-between-prgs-and-uowhfs">Duality Between PRGs and UOWHFs<a hidden class="anchor" aria-hidden="true" href="#duality-between-prgs-and-uowhfs">#</a></h3>
<p>From length-\(n\) OWF, we can have PRG with input length \(\tilde{O}(n^3)\). Or
UOWHF with output length \(\tilde{O}(n^7)\).</p>
<p>It seems like the PRG line is already pushed to the limit. In an annecdote, Yu
met with Zheng (a la [YZ12]) in a 2013 meeting, where Zheng informed him after
this work with PRG, he decided to ditch theory and instead work in industry
(Google).</p>
<p><a id="figure--fig:label"></a></p>
<figure>
    <img loading="lazy" src="/ox-hugo/overview.png"
         alt="Figure 6: Overview of this work"/> <figcaption>
            <p><span class="figure-number">Figure 6: </span>Overview of this work</p>
        </figcaption>
</figure>

<h3 id="universal-hashing">Universal Hashing<a hidden class="anchor" aria-hidden="true" href="#universal-hashing">#</a></h3>
<p>UHF from finite group multiplication and truncating.</p>
<p>Well-known hashing properties:</p>
<dl>
<dt>Leftover hash lemma</dt>
<dd>For any \(X\in\{0,1\}^n\) with \(\minentropy{X} \ge m + d\), conditioned on \(h \leftarrow H\), \(h(X)\) is \(2^{-\frac{d}{2}}\)-close to uniform.</dd>
<dt>Injective hash lemma</dt>
<dd>For any \(X \in \{0,1\}^n\) with \(H_0(X) \le m - d\), we have \(\Pr_{h\leftarrow H, x\leftarrow X}[ \exists x^{\prime} \ne x: h(x) = h(x^{\prime} ] \le 2^{-\Omega(d)}\). This can be proved using a simple union bound on \(x^{\prime}\).</dd>
</dl>
<h3 id="original-uowhfs-from-owp">Original UOWHFs from OWP<a hidden class="anchor" aria-hidden="true" href="#original-uowhfs-from-owp">#</a></h3>
<p>\paragraph{Assumption} (\(t\), ε)-one-way permutation \(f : \{0,1\}^n \to
\{0,1\}^n\). We use a UHF family \(H\) and a truncating function \(\func{trunc} :
\{0,1\}^n \to \{0,1\}^{n-s} \).</p>
<p>\paragraph{Statement} \(G : \{ \func{trunc} \circ h \circ f : h \in H\}\) is a
family of (\(t - n^{O(1)}\), \(2^s \epsilon\))-secure UOWHFs.</p>
<p>\paragraph{Proof} We can adapt the proof for the original 1-bit shrinkage
construction to this case. First we make a guess \(x \leftarrow \{0,1\}^n\) and
returns if the guess is correct. Or else, we guess \(v = 0\ldots0\bar{v},
\bar{v} \leftarrow \{0,1\}^s\) and compute \(h = (y^{*} - f(x))^{-1} v\). After that,
we send \(g = \func{trunc} \circ h \circ f\) and \(x\) to \(A\) and receives its
result \(x^{\prime}\). Notice that we have \( h \cdot (f(x) - f(x^{\prime}) \ne
0\). So if it happens that the choice of \(v\) makes this \(x^{\prime}\) the
preimage of \(y^{*}\) with probability \(\frac{1}{2^s - 1}\).</p>
<h3 id="original-uowhfs-from-1-to-1-owfs">Original UOWHFs from 1-to-1 OWFs<a hidden class="anchor" aria-hidden="true" href="#original-uowhfs-from-1-to-1-owfs">#</a></h3>
<p>\paragraph{Assumption} (\(t\), \(\epsilon\))-1-to-1 OWF \(f : \{0,1\}^n \to
\{0,1\}^l\) (\(l &gt; n\))</p>
<p>\paragraph{Tools} UHF \(H_0\), \(\ldots\), \(H_{l - n}\), where \(H_i : \{ h_i :
\{0,1\}^{l-i} \to \{0,1\}^{l-i-1}\}\).</p>
<p>\paragraph{Statement} \(G : \{h_{l-n} \circ \ldots \circ h_0 \circ f\}\) is a
family of (\(t - n^{O(1)}\), \(\epsilon\))-UOWHFs.</p>
<p>Use \(l - n + 1\) independent hash functions to shrink \(f(x)\) where \(f :
\{0,1\}^n \to \{0,1\}^l\) is a OWF. But the excessive use of hash function seems to be
an artifact of its proof. But right now I have yet found out how to prove it.</p>
<h3 id="construction-1-uowhfs-from-1-to-1-owfs">Construction 1: UOWHFs from 1-to-1 OWFs<a hidden class="anchor" aria-hidden="true" href="#construction-1-uowhfs-from-1-to-1-owfs">#</a></h3>
<p>\paragraph{Assumption} (t, ε)-1-to-1 OWF \(f: \{0,1\}^n \to \{0,1\}^l\) ( \(l &gt;
n\) ).</p>
<p>\paragraph{Tool} Universal hash function \(H = \{ h: \{0,1\}^l \to \{0,1\}^l\} \),
Truncating function \(\func{trunc} : \{0,1\}^l \to \{0,1\}^{n-s}\)</p>
<p>\paragraph{Statement} \(G : \{ \func{trunc} \circ h \circ f : h\in H\} \) is a
family of (\(t - n^{O(1)}\), \(2^{s+1} \epsilon\))-UOWHFs.</p>
<p>\paragraph{Proof} We can use an alternative definition of OWF, taking account of
the fact that \(f\)&rsquo;s range is sparse.</p>
<h3 id="construction-2">Construction 2<a hidden class="anchor" aria-hidden="true" href="#construction-2">#</a></h3>
<p>Skipped.</p>
<h3 id="crhf-from-lpn">CRHF from LPN<a hidden class="anchor" aria-hidden="true" href="#crhf-from-lpn">#</a></h3>
<h4 id="russell-impagliazzo-s-complexity-worlds">Russell Impagliazzo&rsquo;s Complexity Worlds<a hidden class="anchor" aria-hidden="true" href="#russell-impagliazzo-s-complexity-worlds">#</a></h4>
<dl>
<dt>Algorithmica</dt>
<dd>\(\P = \NP\) (or \(\NP \subseteq \BPP\))</dd>
<dt>Heuristica</dt>
<dd>\(\NP \ne \P\) but \((\NP, \class{U}) \subseteq \class{AvgP}\);
\(\NP \not\subseteq \BPP\) but \((\NP, \class{U}) \subseteq \class{HeurBPP}\)</dd>
<dt>Pessiland</dt>
<dd>\(\NP, \class{PSamp} \not\subseteq \class{HeurBPP}\), but \(\not\exists \func{OWF}\))</dd>
<dt>Minicrypt</dt>
<dd>\(\exists\) one way function ( 单向函数 ) but \(\not\exists\)
public key crypto( 公钥密码)</dd>
<dt>Cryptomania</dt>
<dd>\(\exists\) public key crypto ( 公钥密码 ) &amp; multiparty
computation 安全多方计算</dd>
<dt>Obfustopia</dt>
<dd>\(\exists\) fully homomorphic encryption ( 全同态加密 ) &amp;
obfuscation 混淆</dd>
</dl>
<h4 id="np-vs-dot-owf">\(\NP\) vs. OWF<a hidden class="anchor" aria-hidden="true" href="#np-vs-dot-owf">#</a></h4>
<p>\(\NP\) problem: easy to verify. \(\NP\)-hardness is defined via reduction. Its
conjectured however, that \NP is superpolynomially hard.</p>
<h4 id="lpn-problem">LPN Problem<a hidden class="anchor" aria-hidden="true" href="#lpn-problem">#</a></h4>
<p>It seems like that Learning with Error, Nearest Codeword Problem, Learning
Parity with Noise are all related.</p>
<p>With smoothing lemma, we can prove the reduction from worst-case NCP to
average-case LPN.</p>
<p>\paragraph{Overview of the reduction} Consider the a NCP instance \(A, c = Ax +
e\), we want to randomize it by multiplying a matrix \(B\) and randomizing the
secret accordingly. So we sample \(x^{\prime}\) at random and comput \(BA\), and
\(Bc + BAx^{\prime} = BA (x + x^{\prime}) + B e\). To ensure low noise, we have
to make \(B\) sparse. The smoothing lemma states that for A that corresponds to
<strong>balanced code</strong>, if \(B \gets Ber_{\mu}^{q \times m}\) we have</p>
<p>\begin{equation*}
(BA, Be) \approx_s (U^{q \times n}, Ber_{\mu}^q). \end{equation*}</p>
<p>There is however a <a href="https://eprint.iacr.org/2020/870">simpler proof</a> using Vazirani&rsquo;s XOR lemma, that I have proof
read but have yet finished. I have already read Vazirani&rsquo;s XOR lemma, perhaps I
should read it.</p>
<h4 id="hardness-of-ncp-and-lpn">Hardness of NCP and LPN<a hidden class="anchor" aria-hidden="true" href="#hardness-of-ncp-and-lpn">#</a></h4>
<p>It seems that worst case NCP has time complexity \(\poly(n) \cdot e^{\mu n}\).
For average LPN, the BKW algorithm gives \(2^{O(\frac{n}{\log n})}\) complexity.
So it seems that worst case NCP is indeed very hard.</p>
<h4 id="cryptographic-hashing-from-lpn">Cryptographic Hashing from LPN<a hidden class="anchor" aria-hidden="true" href="#cryptographic-hashing-from-lpn">#</a></h4>
<p>Construct a intermediate problem \(\lang{bSVP}\) that is the analogue to SIS
problem. We then construct an Expand function that is</p>
<ol>
<li>1-to-1</li>
<li>output sparse 0-1 vector</li>
<li>parallel</li>
</ol>
<p>We can then directly get a CRHF.</p>
<p>\paragraph{Expand} The expand function is very easy. For \(L\cdot t\) bit input,
the function expand it to \(2^L \cdot t\) bit output, by first partition the
input into \(t\) \(L\)-bit blocks, translate each block into &ldquo;one-hot&rdquo; encoding,
and then output. The output has exactly \(t\) ones, and by definition it is an
injective map.</p>
<h4 id="lpn-implies-bsvp">LPN Implies bSVP<a hidden class="anchor" aria-hidden="true" href="#lpn-implies-bsvp">#</a></h4>
<p>Suppose we have a bSVP solver \(O\), we can construct a distringuisher \(A^O(A,
y)\).</p>
<p>We can first find a solution \(x\) to \(A^T\), them determine which is the case
by the bias of \(y^Tx\). If \(y\) is uniform, then \(y^Tx\) is also uniformly
random. Otherwise, \(y^Tx\) has biased Bernoulli distribution from piling up
lemma.</p>
<p>This reminds me of knapsack LPN problem.</p>
<h4 id="hardness">Hardness<a hidden class="anchor" aria-hidden="true" href="#hardness">#</a></h4>
<p>\begin{theorem}
T-hard (\(n\), \(\mu\), \(m\))-LPN implies \(\sqrt{T}\)-hard CRH \(h_A\), where
\(h_A (y) = A \cdot \func{Expand}(y)\), \(t^2 \le m \le T = 2^{\frac{\mu t}{1 -
2\mu}}\). \end{theorem}</p>
<p>I wonder if Knapsack-LPN can be used to construct a CRHF <strong>and</strong> how this theorem
is proved.</p>
<h3 id="overcoming-weak-expectations">Overcoming Weak Expectations<a hidden class="anchor" aria-hidden="true" href="#overcoming-weak-expectations">#</a></h3>
<p>Typical crypto setting \(P\): pick random secret key \(R \leftarrow \{0,1\}^m\). But
in practice, we can only guarantee that \(R\) has large entropy.</p>
<p>There are three options. (\(X\) is the weak source)</p>
<dl>
<dt>Clever</dt>
<dd>Design \(P\) so that it can withstand weak randomness</dd>
<dt>Modular</dt>
<dd>Design key deriviation function \(h : \{0,1\}^n \to \{0,1\}^m\) subject to \(R = h(X)\)  is good for \(P\). The goal is to assume little-to-nothing about \(P\).</dd>
<dt>Dumb</dt>
<dd>Use \(R = X\) and hope for the best.</dd>
</dl>
<h4 id="pedantic-viewpoint">Pedantic Viewpoint<a hidden class="anchor" aria-hidden="true" href="#pedantic-viewpoint">#</a></h4>
<p>Fix \(P\) and any &ldquo;legal&rdquo; \(A\) Let \(f( r)\) be the advantage of \(A\) on key
\(r\).</p>
<ul>
<li>Unpredictability apps: \(f( r) \in [0,1]\)</li>
<li>Indistinguishability apps: \(f( r) \in [-\frac{1}{2}, \frac{1}{2}]\)</li>
<li>In the ideal world, the advantage of \(A\) is \(|E(f(U_m))| = |\sum_r \frac{1}{2^m} f( r)|\)</li>
<li>In the real world, the advantage of \(A\) is \(|E(f( R))| = |\sum_r p( r) \cdot f( r) |\)</li>
</ul>
<h4 id="simple-case">Simple Case<a hidden class="anchor" aria-hidden="true" href="#simple-case">#</a></h4>
<p>For unpredictability application, we have any (\(t\), \(\epsilon\))-secure \(P\)
in the ideal model is also (\(t\), \(\ 2^d \cdot epsilon\))-secure in the
\(m-d\)-real model.</p>
<p>\paragraph{Proof}. \(E_r(p( r)\cdot f( r)) \le 2^m \frac{1}{2^{m-d}} \sum_r
\frac{1}{2^m} f( r) = 2^d E(f(U_m))\).</p>
<p>Notice that we used the fact \(f( r)\) is non-negative throughout the proof.</p>
<h4 id="indistinguishablility-application">Indistinguishablility Application<a hidden class="anchor" aria-hidden="true" href="#indistinguishablility-application">#</a></h4>
<p>The paper introduced a square security notation, but I have yet grasped it.</p>
<h2 id="lecture-11">Lecture 11<a hidden class="anchor" aria-hidden="true" href="#lecture-11">#</a></h2>
<p>From this lecture through the next three or four lectures, Prof. Liu will take
on this lecture. 两节课讲一下现代密码学的主要原则，然后在之后讲IBE，ABE，FHE等内容，再讲一两个证明。</p>
<h3 id="outline">Outline<a hidden class="anchor" aria-hidden="true" href="#outline">#</a></h3>
<ol>
<li>A brief introduction</li>
<li>Principles of Modern Crypto</li>
<li>framework of modern crypto</li>
<li>mathematics of pkc</li>
<li>PKE</li>
<li>Digital signature</li>
<li>Hash function</li>
<li>Hybrid encryption and PKE</li>
</ol>
<h3 id="a-brief-introduction-to-crypto">A Brief Introduction to Crypto<a hidden class="anchor" aria-hidden="true" href="#a-brief-introduction-to-crypto">#</a></h3>
<p>Crypto ≈ Cryptography + Cryptanalysis</p>
<p>Usually cryptanalysis is very important in symmetric-key cryptography (e.g. Hash
function, secret-key cryptography).</p>
<h3 id="the-basis-goals-of-cryptography">The Basis Goals of Cryptography<a hidden class="anchor" aria-hidden="true" href="#the-basis-goals-of-cryptography">#</a></h3>
<ul>
<li>Enabling parties to communicate over an open communiation channel in a secure (confidentiality, integrity) way.</li>
<li>Cryptogrpahic primintives
<ul>
<li><strong>Secrecy / Confidentiality:</strong> SKE / PKE</li>
<li><strong>Integrity / Authenticity:</strong> MAC / PKE, using Hash Function (this primitive is keyless, isn&rsquo;t there public coins?)</li>
</ul>
</li>
</ul>
<h3 id="private-key-encryption">Private Key Encryption<a hidden class="anchor" aria-hidden="true" href="#private-key-encryption">#</a></h3>
<p>Two parties share keys previously.</p>
<h3 id="message-authentication-code">Message Authentication Code<a hidden class="anchor" aria-hidden="true" href="#message-authentication-code">#</a></h3>
<p>Only sender and receiver can compute and verify MAC.</p>
<h3 id="public-key-cryptography">Public Key Cryptography<a hidden class="anchor" aria-hidden="true" href="#public-key-cryptography">#</a></h3>
<p>Modern provable security is (arguably) more biased towards PKC.</p>
<p>In pure symmetric crypto, people typically use a centralized online key
distribution server to handle session key establishment requests. Whereas in
public key setting, one can use certificates to do this.</p>
<p>In 1976, W. Diffie and M. Hellman purposed a paper &ldquo;New Directions in
Cryptography&rdquo; to motivate simplifaction of key distribution and management in
symmetric-key cryptography.</p>
<h3 id="digital-signature">Digital Signature<a hidden class="anchor" aria-hidden="true" href="#digital-signature">#</a></h3>
<p>Like MAC, but publicly verifiable.</p>
<ul>
<li>Public Verifiability</li>
<li>Transferability</li>
<li>Non-repudiation</li>
</ul>
<h3 id="principles-and-framework-of-modern-cryptography">Principles and Framework of Modern Cryptography<a hidden class="anchor" aria-hidden="true" href="#principles-and-framework-of-modern-cryptography">#</a></h3>
<p>Classic cryptography &mdash; symmetric key encryption algorithms.</p>
<ul>
<li>Classical Cryptography
<ul>
<li>Art</li>
<li>Ad-hoc</li>
</ul>
</li>
<li>Modern Cryptography (Methodological)
<ul>
<li>Science</li>
<li>Components
<ul>
<li>Syntax (what components should a system have)</li>
<li>Security Models (what is the definition of security and what is the adversary&rsquo;s ability)</li>
<li>Provable Security (reduction)</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="private-key-encryption">Private Key Encryption<a hidden class="anchor" aria-hidden="true" href="#private-key-encryption">#</a></h3>
<p>Syntax: three algorithms</p>
<ul>
<li>\(KeyGen(1^n) \to k\)</li>
<li>\(Enc(k, m) \to c\)</li>
<li>\(Dec(k, c) \to m\)</li>
</ul>
<p>We can then define key space \(\mathcal{K}\), messsage space \(\mathcal{m}\) and
correctness of private-key encryption.</p>
<p>Key space for single-table substitution: \(26!\)</p>
<h3 id="kerckhoff-s-principle">Kerckhoff&rsquo;s Principle<a hidden class="anchor" aria-hidden="true" href="#kerckhoff-s-principle">#</a></h3>
<p>Security only depends on secrecy of key, rather than the algorithm. The
rationale behind this principle is that changing keys is much easier than
changing algorithms. So to be more complete, cryptographic designs should be
made completely public.</p>
<p>Moreover, it feels safer after witnessing every one around the globe failed to
break a published cryptographic scheme.</p>
<p>So It appears there are indeed people who believe that algorithms should be kept
secret (at least in the civilian application).</p>
<h3 id="brute-force">Brute-Force<a hidden class="anchor" aria-hidden="true" href="#brute-force">#</a></h3>
<p>At least the key space should be large enough to make exhaust-search attack
infeasible. But note that this is not sufficient.</p>
<h3 id="principles-of-modern-cryptography">Principles of Modern Cryptography<a hidden class="anchor" aria-hidden="true" href="#principles-of-modern-cryptography">#</a></h3>
<h4 id="principle-1">Principle 1<a hidden class="anchor" aria-hidden="true" href="#principle-1">#</a></h4>
<p>Formal Definitions, provides what threats are in scope and what security
guarantees are desired. Security guarantee and threat model.</p>
<ul>
<li>Security gurantee &mdash; semantic security, not a bit of additional information is leaked</li>
<li>Threat model &mdash; Ciphertext-only attack, known-plaintext attack, chosen-plaintext attack, chosen-ciphertext attack.</li>
</ul>
<h2 id="lecture-12">Lecture 12<a hidden class="anchor" aria-hidden="true" href="#lecture-12">#</a></h2>
<h3 id="现代密码学的原则">现代密码学的原则<a hidden class="anchor" aria-hidden="true" href="#现代密码学的原则">#</a></h3>
<dl>
<dt>明确定义</dt>
<dd>包括正确性、安全性的定义(threat model, security guarantee)</dd>
<dt>精确的假设</dt>
<dd>由于需要使用计算安全性，而统计意义上的安全性很难得到
We are almost entirely talked away from using <strong>ad hoc</strong> assumptions. Though
this principle has nothing to do with the content of assumptions.</dd>
<dt>安全性证明</dt>
<dd>定义与假设允许我们分析，安全保证能否在相应的模型下被假设蕴含，这就是安全性证明的功能</dd>
</dl>
<h3 id="provable-security-and-real-world-security">Provable Security and Real-World Security<a hidden class="anchor" aria-hidden="true" href="#provable-security-and-real-world-security">#</a></h3>
<p>The <strong>art</strong> part of modern cryptography: rigorous approach leaves room for
creativity in:</p>
<ul>
<li>Developing definitions suited to contemporary applications and environments (e.g. CCA, UC)</li>
<li>Proposing new mathematical assumptions (e.g. Coppersmith, Shor)</li>
<li>Designing new primitives (e.g. IBE a la Shamir, PKE a la Diffie and Hellman)</li>
<li>Constructing novel schemes and proving them secure</li>
<li>Attacking deployed cryptosystems</li>
</ul>
<h3 id="provable-security-and-real-world-security">Provable Security and Real-World Security<a hidden class="anchor" aria-hidden="true" href="#provable-security-and-real-world-security">#</a></h3>
<p>A proof of security is always relative to the definition being considered and
the assumptions being used.</p>
<p>The proof may be irrelevant if</p>
<ul>
<li>The security guarantee does not match what is needed</li>
<li>The threat model does not capture the adversary&rsquo;s ture abilities</li>
</ul>
<p>The proof of security is meaningless if the assumption is refuted.</p>
<h3 id="framework-of-modern-cryptography">Framework of Modern Cryptography<a hidden class="anchor" aria-hidden="true" href="#framework-of-modern-cryptography">#</a></h3>
<p>Personal summary of Prof. Liu. Framework</p>
<ul>
<li>Symmetric Cryptography
<ul>
<li>Encryption</li>
<li>Message Authentication Code</li>
</ul>
</li>
<li>Asymmetric Cryptography
<ul>
<li>Public Key Encryption</li>
<li>Digital Signature</li>
<li>IBE, ABE, FHE</li>
<li>Blind Signature, Ring Signature</li>
<li>Commitment, Zero-Knowledge Proof</li>
</ul>
</li>
<li>Hash function</li>
</ul>
<h3 id="research-directions-in-asymmetric-cryptogrpahy">Research Directions in Asymmetric Cryptogrpahy<a hidden class="anchor" aria-hidden="true" href="#research-directions-in-asymmetric-cryptogrpahy">#</a></h3>
<ul>
<li>应用密码算法的业务系统</li>
<li>应用密码算法的协议</li>
<li>密码原语的定义：应用驱动、密码理论研究</li>
<li>密码原语方案设计：构造符合源于定义并在其模型下证明安全的方案</li>
<li>困难设计：困难问题的求解算法研究</li>
</ul>
<h3 id="number-theory">Number Theory<a hidden class="anchor" aria-hidden="true" href="#number-theory">#</a></h3>
<p>Cyclic Group</p>
<h3 id="primes">Primes<a hidden class="anchor" aria-hidden="true" href="#primes">#</a></h3>
<p>Generating large primes &mdash; a probablistic method. Sample a random large enough
number, using a conjecture we can argue that with large probability we can
actually get a prime number, if we repeat the process a small number of times.
The primality test can be a \coRP algorithm.</p>
<h3 id="discrete-logarithm-assumption">Discrete Logarithm Assumption<a hidden class="anchor" aria-hidden="true" href="#discrete-logarithm-assumption">#</a></h3>
<p>We always work on finite groups. The groupgen algorithm generates algorithms for
&ldquo;translation&rdquo; in \(\mathbb{G}\). Theoretically, a GroupGen algorithm is related
to the instance of DL, CDH, DDH instance, but in practice we can simply choose
NIST recommended standard values.</p>
<p>An Example GenGroup Algorithm</p>
<ul>
<li>Generate a uniform n-bit prime \(q\)</li>
<li>Choose a \(l\)-bit prime \(p\) such that \(q | (p - 1)\)</li>
<li>Choose a uniform \(h \leftarrow \ZZ_p^{*}\)</li>
<li>Set \(g = h^{\frac{p - 1}{q}}\)</li>
<li>Output \(g, q, p\)</li>
</ul>
<p>Another GenGroup Algorithm</p>
<ul>
<li>On subgroups of finite <strong>field</strong></li>
<li>On Elliptic Curves (cf. ECDSA)</li>
</ul>
<h3 id="inverse-on-a-generic-group">Inverse on a Generic Group<a hidden class="anchor" aria-hidden="true" href="#inverse-on-a-generic-group">#</a></h3>
<p>Simply \(h^{-1} = h^{q - 1}\).</p>
<h3 id="public-key-cryptography">Public Key Cryptography<a hidden class="anchor" aria-hidden="true" href="#public-key-cryptography">#</a></h3>
<p>CPA / CCA threat model and IND / SS security guarantee.</p>
<p>Trick: if the fine-defined constraint, e.g. challenge ciphertext cannot be
further queried, is not used, then the proof itself is most certainly useless.</p>
<h2 id="lecture-13">Lecture 13<a hidden class="anchor" aria-hidden="true" href="#lecture-13">#</a></h2>
<p>Some kind of code: 787228. Last lecture we have covered public key encryption.
This lecture we will continue with digital signature.</p>
<h3 id="digital-signature">Digital Signature<a hidden class="anchor" aria-hidden="true" href="#digital-signature">#</a></h3>
<p>Patches need to be verified publicly.</p>
<p>Properties:</p>
<ol>
<li>
<p>Correctness.
\(\verify (\pk, m, \sig (\sk, m)) = 1\) for every \(m\)</p>
</li>
<li>
<p>Security (EUF).</p>
<ul>
<li><strong>Security guarantee:</strong> non-forgeability</li>
<li><strong>Threat model:</strong> signing oracle, the advantage is just the success probability of forgery.</li>
</ul>
</li>
</ol>
<p>Extension: strong unforgeability, which means challenge (\(m\), \(\sigma\)) pair
needs to be unique, rather than \(m\) has to be unique.</p>
<h3 id="example">Example<a hidden class="anchor" aria-hidden="true" href="#example">#</a></h3>
<p>\paragraph{DSA / ECDSA} Both are included in the current Digital Signature
Standard, issued by NIST.</p>
<p>Although ECDSA is no longer the recommended DS standard, it is still considered
more efficient and have at least the same security level as RSA signatures. In
ECDSA, the group parameter can be shared, whereas in RSA the encryption modulus
cannot be shared.</p>
<p>Syntax: A group generation algorithm that generates the description of a cyclic
group, its order and a generator. An example is to generate the
prime-\(q\)-order subgroup of a larger multiplicative group \(\ZZ_p^{*}\).</p>
<ul>
<li>\(KeyGen(1^n) \to (\pk, \sk)\)</li>
</ul>
<p>The group parameter can be considered public. In practice, this algorithm can
just sample a private order and output \(\pk = \mbox{group}, g^x\) and \(\sk =
x\).</p>
<p>Also, two functions \(H: \{0,1\}^{*} \to \ZZ_q\) and \(F: \mathbb{G} \to \ZZ_q\)
are included in the public key as auxiliary information.</p>
<ul>
<li>\(\sig(\sk, m) \to c\)
First hash the message to \(\mu = H(m) \), and then sample \(k \leftarrow
\ZZ_q\). Then compute \(r =F(g^k) \), and \(s = k^{-1} (\mu + xr)\). If \(r =
0\) or \(s = 0\), sample \(k\) again and repeat. Output \(\sigma = (r, s)\).</li>
<li>\(\verify(\pk, m, \sigma) \to \bin\)
Output 1 iff. \(r = F(g^{H(m) s^{-1}} y^{r s^{-1}})\).</li>
</ul>
<p>Security: to prove the euf-cma security of DSA / ECDSA, the function \(F, H\)
should be modelled as random oracle. \(H\) can sometimes be considered as a
random oracle, \(F\) is completely not like a hash function. In DSA, \(F\) is
just modulo \(q\); In ECDSA, \(F\) is the first coordinate modulo \(q\).</p>
<h3 id="hash-function">Hash Function<a hidden class="anchor" aria-hidden="true" href="#hash-function">#</a></h3>
<p>Syntax: \(H: \{0,1\}^n \to \{0,1\}^{l(n)}\).</p>
<p>Security guarantee: collision-resistant.</p>
<p>Weaker Security: second-preimage or target-collision resistance: given a uniform
\(x\) it is infeasible to find \(x^{\prime}\) such that \(x\) and \(x^{\prime}\)
collides.</p>
<p>Preimage resistance: given a uniform target \(y\) it is infeasible to find \(x\)
such that \(y = H(x)\).</p>
<p>Birthday attack: an upper bound on the security of \(l(n)\)-long is \(l(n) /
2\).</p>
<p>Popular Crypto Hashes:</p>
<dl>
<dt>MD5</dt>
<dd>Broken</dd>
<dt>SHA1</dt>
<dd>Nearly broken</dd>
<dt>SHA2</dt>
<dd>OK</dd>
<dt>SHA3</dt>
<dd>Secure but slow</dd>
</dl>
<h3 id="hybrid-encryption">Hybrid Encryption<a hidden class="anchor" aria-hidden="true" href="#hybrid-encryption">#</a></h3>
<p>Encapsulate a symmetric session key from public key encryption, and then use
this session key to encrypt subsequent data.</p>
<p>KEM / DEM are a new pair of primitives to capture / simplify hybrid encryption
method.</p>
<h4 id="key-encapsulation-method">Key Encapsulation Method<a hidden class="anchor" aria-hidden="true" href="#key-encapsulation-method">#</a></h4>
<p>Syntax: there are three algorithms \(KeyGen\), \(Encap\), \(Decap\)</p>
<p>The CPA security is defined as follows. The challenge text is a ciphertext and a
key. If \(b = 0\), the ciphertext is the encryption of the key; if \(k = 1\),
the key and the ciphertext are independent. The adversary guesses the value
\(b\).</p>
<p>The CCA security is defined by adding a decryption oracle.</p>
<h4 id="example">Example<a hidden class="anchor" aria-hidden="true" href="#example">#</a></h4>
<p>El Gamal-like KEM: actually I think it is more like DH-key exchange. Up on
agreeing \(g^{xy}\), both sides hash this value to produce a key.</p>
<h2 id="lecture-14">Lecture 14<a hidden class="anchor" aria-hidden="true" href="#lecture-14">#</a></h2>
<p>Introduction to IBE</p>
<p>Starting from motivation (i.e. application in real life), abstract the
definition.</p>
<p>From definition derive a construction and the security threat model.</p>
<p>From security model and construction, derive a security proof.</p>
<h3 id="motivation-of-idenity-based-encryption">Motivation of Idenity-based Encryption<a hidden class="anchor" aria-hidden="true" href="#motivation-of-idenity-based-encryption">#</a></h3>
<p>Public key cryptogrpahy <strong>partly</strong> solved the key distribution nuisance in
symmetric key cryptography, but PKI is still somewhat troublesome. So key
distribution should not be considered completely solved in PKC.</p>
<h3 id="introduction-to-ibe">Introduction to IBE<a hidden class="anchor" aria-hidden="true" href="#introduction-to-ibe">#</a></h3>
<p>Certification issuing is not free.</p>
<p>Adi Shamir introduced IBE in 1984. The application scenario is one-time key
distribution in a large system (e.g. bank and multinational corporation).</p>
<p>One generalization is that an arbitrary string can be used as the public key.</p>
<h3 id="the-concept-of-identity-based-cryptography">The concept of Identity-based Cryptography<a hidden class="anchor" aria-hidden="true" href="#the-concept-of-identity-based-cryptography">#</a></h3>
<ul>
<li>Introduced by A. Shamir in 1984</li>
<li>Identity-based Signature Scheme was proposed in 1987</li>
<li>The first usable identity-based encryption shcemes were purposed in 2001 from pairing and QR</li>
</ul>
<h3 id="correctness">Correctness<a hidden class="anchor" aria-hidden="true" href="#correctness">#</a></h3>
<p>If the same \(id\) is used, decryption will ensure plaintext recovery.</p>
<h3 id="security">Security<a hidden class="anchor" aria-hidden="true" href="#security">#</a></h3>
<p>IND-ID-CCA: Define two oracles</p>
<ul>
<li>\(OKeyGen(id) \mapsto KeyGen(mpk, msk, id)\)</li>
<li>\(ODec(id, ct) \mapsto Dec(mpk, KeyGen(mpk, msk, id), ct)\)</li>
</ul>
<p>And a number of restrictions:</p>
<ol>
<li>The challenge identity must not be previously queried to \(OKeyGen\)</li>
<li>After challenge phase, the adversary must not query \(OKeyGen\) with \(id^{*}\) or query \(ODec\) with \(id^{*}, c^{*}\).</li>
</ol>
<h3 id="construction">Construction<a hidden class="anchor" aria-hidden="true" href="#construction">#</a></h3>
<h4 id="underlying-mathematics">Underlying Mathematics<a hidden class="anchor" aria-hidden="true" href="#underlying-mathematics">#</a></h4>
<p>Bilinear Map Groups: Let \(G\) and \(G_T\) be two cyclic groups of order \(p\)
and \(q\), then a map \(e: G \times G \mapsto G_T\) is a bilinear map if</p>
<dl>
<dt>Bilinear</dt>
<dd>for all \(u, v \in G\) and \(a, b \in \ZZ\) it holds that \(e(u^a, v^b) = e(u, v)^{ab}\).</dd>
<dt>Non-degenerate</dt>
<dd>\(e (g, g) \ne q_{G_T}\).</dd>
</dl>
<p>We say \(G\) is a bilinear group if the group operation in \(G\) can be computed
efficiently and there exists a group \(G_T\) and an efficiently computable
bilinear map \(e: G \times G \to G_T\) as above.</p>
<p>We let \(GenGroup\) a group generation algorithm that generates \(G, G_T, p, q,
e\).</p>
<p>BDH assumption: It is hard to compute \(e(g, g)^{abc}\) given random \(g, g^a,
g^b, g^c\).</p>
<h4 id="original-construciton">Original Construciton<a hidden class="anchor" aria-hidden="true" href="#original-construciton">#</a></h4>
<p>The original construction satisfies IND-ID-CCA security in the RO model. Some
considered selective IND-sID-CCA security in the standard model.</p>
<p>A number of subsequent works improved the security.</p>
<h3 id="further-development">Further Development<a hidden class="anchor" aria-hidden="true" href="#further-development">#</a></h3>
<p>The PKG can read any ciphertexts. This can introduce</p>
<ul>
<li>key escrow problem</li>
<li>The revocation of user secret keys</li>
<li>Anonymous IBE (Homework)</li>
<li>Hierarchical IBE</li>
</ul>
<h3 id="digital-signature">Digital Signature<a hidden class="anchor" aria-hidden="true" href="#digital-signature">#</a></h3>
<p>ECDSA is the key algorithm to ensure Bitcoin&rsquo;s functionality.</p>
<p>In Bitcoin, transaction is authenticated by ECDSA. A wallet is the database of
pk / sk pairs. In Bitcoin and other cryptocurrency, it is a desireable thing to
have deterministic wallets.</p>
<p>Advantages of Deterministic Wallet</p>
<ul>
<li>Low-maintenance wallets with easy backup and recovery (just backup the seed)</li>
<li>Freshly generated cold addresses (cold means never been on the Internet)</li>
<li>Trustless audit</li>
<li>Hierarchical wallet allowing a treasurer to allocate funds to departments</li>
</ul>
<p>Though it should be noted that the treasurer use case and auditor use case
cannot be used together.</p>
<p>Stealth address and determinstic wallet.</p>
<h2 id="lecture-15">Lecture 15<a hidden class="anchor" aria-hidden="true" href="#lecture-15">#</a></h2>
<h3 id="deterministic-wallet">Deterministic Wallet<a hidden class="anchor" aria-hidden="true" href="#deterministic-wallet">#</a></h3>
<p>Cryptographically, not very sound.</p>
<h3 id="wallet-vs-dot-stealth-address">Wallet vs. Stealth Address<a hidden class="anchor" aria-hidden="true" href="#wallet-vs-dot-stealth-address">#</a></h3>
<p>Wallet: managing the keys from the wallet owner.</p>
<p>Stealth address: to send money to a certain publicly visible master key in such
a way that this key does not appear in the ledger at all, so that users&rsquo; privacy
gets more protection.</p>
<p>Stealth address can serve as wallet, as a matter of fact.</p>
<h3 id="monero">Monero<a hidden class="anchor" aria-hidden="true" href="#monero">#</a></h3>
<table>
<thead>
<tr>
<th>The Payer</th>
<th>The public</th>
<th>The Payee</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>A = aG, B = bG</td>
<td>\((a,b)\in\ZZ_p^2\)</td>
</tr>
<tr>
<td>\(r\leftarrow \ZZ_p\)</td>
<td>\(R = rG\)</td>
<td>\(s = H(aR) + b\)</td>
</tr>
<tr>
<td></td>
<td>\(S = H(rA)G + B\)</td>
<td></td>
</tr>
</tbody>
</table>
<p>For each transaction, the payer uses a different \(r\).</p>
<p>Properties (intuitive)</p>
<dl>
<dt>Privacy</dt>
<dd>Each coin receiving address is freshly generated, with random \(r\)</dd>
<dt>Security</dt>
<dd>Only the payee knows \(b\)</dd>
<dt>Convenience</dt>
<dd>The check needs to be run each for each transaction</dd>
<dt>Enhanced Security and Convenience</dt>
<dd>\(b\) can be stored in cold storage
<ul>
<li>Can be used to implement trustless audit.</li>
</ul>
</dd>
</dl>
<p>\paragraph{Problem} If one secret key is compromised, the master secret key may
be compromised.</p>
<h4 id="rationale-of-the-problem">Rationale of the Problem<a hidden class="anchor" aria-hidden="true" href="#rationale-of-the-problem">#</a></h4>
<p>Functionality</p>
<ul>
<li>User has a <strong>Master Public Key</strong></li>
<li>Payer can compute a DVK from MPK without interaction</li>
<li>User can examine from DVK if its the recepient</li>
</ul>
<h4 id="correctness">Correctness<a hidden class="anchor" aria-hidden="true" href="#correctness">#</a></h4>
<p>Checking transaction and signature verification algorithms are both correct</p>
<h4 id="unforgeability">Unforgeability<a hidden class="anchor" aria-hidden="true" href="#unforgeability">#</a></h4>
<p>Three oracles: verification key adding oracle, signing key corruption oracle,
and signing oracle.</p>
<p>Notice that <strong>signing key corruption</strong> orecle, designed to take care of signing
key corruption, is not considered in Monero. That is way Monero has the
aforementioned problem.</p>
<h3 id="commitment-schemes">Commitment Schemes<a hidden class="anchor" aria-hidden="true" href="#commitment-schemes">#</a></h3>
<p>This part is presented by Prof. Yu.</p>
<h4 id="definitions">Definitions<a hidden class="anchor" aria-hidden="true" href="#definitions">#</a></h4>
<ul>
<li>Correctness</li>
<li>Hiding</li>
<li>Binding</li>
</ul>
<h4 id="two-types-of-commitment-schemes">Two Types of Commitment Schemes<a hidden class="anchor" aria-hidden="true" href="#two-types-of-commitment-schemes">#</a></h4>
<dl>
<dt>Standard</dt>
<dd>Statistically binding, computationally hiding</dd>
<dt>Perfect</dt>
<dd>Statistically hiding, computationally hiding</dd>
</dl>
<h2 id="lecture-16">Lecture 16<a hidden class="anchor" aria-hidden="true" href="#lecture-16">#</a></h2>
<p>In this lecture we are talking about FHE.</p>
<h3 id="application">Application<a hidden class="anchor" aria-hidden="true" href="#application">#</a></h3>
<p>Secure cloud computing. Securely deligate processing of data without giving away
access to it.</p>
<h3 id="definition">Definition<a hidden class="anchor" aria-hidden="true" href="#definition">#</a></h3>
<p>Homomorphism: We can apply some class of function \(f\) to \(Enc(m)\) to get
\(Enc(f(m))\).</p>
<h3 id="first-attempt-rsa">First Attempt: RSA<a hidden class="anchor" aria-hidden="true" href="#first-attempt-rsa">#</a></h3>
<p>RSA satisfies multiplicative homomorphism. The &ldquo;plain&rdquo; RSA satisfies that after
multiplying two ciphertexts, we get the ciphertext of multiplying two
plaintexts.</p>
<h3 id="homomorphism-on-arbitrary-operation">Homomorphism on Arbitrary Operation<a hidden class="anchor" aria-hidden="true" href="#homomorphism-on-arbitrary-operation">#</a></h3>
<p>AND, XOR is Turing-complete.</p>
<p>The first breakthough is ascribed to Craig Gentry. ACM best doctoral paper.
<img loading="lazy" src="/ox-hugo/FHE.png" alt=""  />
</p>
<h3 id="mechanism-behind-he">Mechanism Behind HE<a hidden class="anchor" aria-hidden="true" href="#mechanism-behind-he">#</a></h3>
<p>What objects support addition and multiplication? polynomials, matrices, and
integers.</p>
<p>Today we use [GHDV09] as an example, which may seems a bit untidy, but still
good enough to demonstrate the basic ideas of HE.</p>
<p>The construction of [GHDV09]:</p>
<dl>
<dt>Secret Key</dt>
<dd>large odd prime \(p\)</dd>
</dl>
<p>Encrypt a bit \(b\)
-   Pick a random large multiple of \(p\), \(q \cdot p\)
-   Pick a small \(r\) and let cipher text be \(c = q\cdot p + 2r + b\)</p>
<dl>
<dt>Decrypt a ciphertext \(c\)</dt>
<dd>first \(\mod p\) then \(\mod 2\)</dd>
</dl>
<p>The noise is added to prevent GCD attacks in the IND-CPA game: GCD(\(p \cdot
q_1\), \(p \cdot q_2\)) = \(p\). We rely on an &ldquo;approximate-GCD&rdquo; assumption.</p>
<p>When we perform homomorphic multiplication, there will be a quadratic blow-up in
noise. When the noise grows too big, and becomes bigger than \(\frac{p}{2}\)
then decryption security will be violated.</p>
<p>Now we can do a lot of additions and some multiplications. We have a &ldquo;somewhat&rdquo;
homomorphic scheme. Enough to perform some low-multiplicative-depth tasks, like
database search, spam filtering, etc.</p>
<p>The last step is accomplished through bootstrapping.</p>
<h3 id="from-somewhat-he-to-full-he">From Somewhat HE to Full HE<a hidden class="anchor" aria-hidden="true" href="#from-somewhat-he-to-full-he">#</a></h3>
<p>Consider an &ldquo;augmented decryption circuit&rdquo;</p>
<p>First decrypt \(c_1\) and \(c_2\) and them perform an NAND. We call this circuit
\(\hat{C}\). The first layer of circuit \(\hat{C}\) has input \(c_1\) (resp.
\(c_2\)) and \(\sk\). If \(\hat{C}\) is in the evaluatable range of SHE, then
Gentry shows that this SHE scheme actually implies a FHE scheme.</p>
<p>The natural idea is that decryption will kill all noise, so we can use
decryption circuit to reduce all noise. Only the secret key are encryption,
since the ciphertext is already public. So the output only carries noise from
encryption of secret key, which is fresh every time. To summarize, we thus have
obtained a &ldquo;refresh&rdquo; operation.</p>
<h3 id="issues-omitted">Issues Omitted<a hidden class="anchor" aria-hidden="true" href="#issues-omitted">#</a></h3>
<ul>
<li>The SWHE cannot correctly evaluate its decryption circuit, we have to &ldquo;squash&rdquo; this circuit by leaking some information of decryption key</li>
<li>Is it safe to encrypt the key by itself? The <strong>circular security</strong> assumption still seems not proven to this day. In this example its self-loop.</li>
<li>How to better control the noise accumulation? There are new scheme like GSW.</li>
<li>Is it practical? NO.</li>
</ul>
<h3 id="fhe-from-lwe">FHE from LWE<a hidden class="anchor" aria-hidden="true" href="#fhe-from-lwe">#</a></h3>
<h4 id="lwe">LWE<a hidden class="anchor" aria-hidden="true" href="#lwe">#</a></h4>
<p>Parameters: modulus \(q\), dimension \(n\), number of samples \(m\) Secret:
uniformly random vector \(s \in \ZZ^n_q\). Noise: \(e\) sampled from some
distribution such that \(|e| \ll q\) whp</p>
<h4 id="construction">Construction<a hidden class="anchor" aria-hidden="true" href="#construction">#</a></h4>
<dl>
<dt>Public key</dt>
<dd>\(A, b = As + 2e\), notice that here the multiple \(2\) is fine, since GCD(2, q) = 1, and we can reduce plain LWE to this version of &ldquo;2LWE&rdquo; by multiplying \(2^{-1}\) on both sides.</dd>
<dt>Encryption</dt>
<dd>Sample \(t \leftarrow \{0,1\}^m\) and \(c = t A, t b + m\).</dd>
</dl>
<h4 id="homomorphic-addition">Homomorphic Addition<a hidden class="anchor" aria-hidden="true" href="#homomorphic-addition">#</a></h4>
<p>Adding two ciphertexts together, also, since the modulus is \(q\), the
ciphertext will not expand every time.</p>
<h4 id="homomorphic-multiplication">Homomorphic Multiplication<a hidden class="anchor" aria-hidden="true" href="#homomorphic-multiplication">#</a></h4>
<p>If \(|e_1| \ll q\) and \(|e_2| \ll q\) then \(m_1\cdot m_2 = (2e_1 +
m_1)(2e_2 + m_2) \mod q \mod 2\).</p>
<p>Then let \(a^{\prime} = t A\), \(e^{\prime} te \), we have</p>
<p>\begin{align*}
m_1 \cdot m_2 &amp;= (2e_1 + m_1) (2e_2 + m_2) \\
&amp;= (b_1 - s^T a_1) (b_2 - s^T a_2)
\end{align*}</p>
<p>So we have to provide quadratic terms of \(s_i s_j\) and 1-degree term
\(s_i\) in encrypted form. But there is also a problem of coefficient
of \(Enc(s_i)\), \(Enc(s_i\cdot s_j)\) too big. We then apply the
binary representation trick, i.e. publish encryption of \(2^0s_i\),
\(2^1s_i\), \(2^2 s_i\), \(\ldots\).</p>
<h4 id="issues-omitted">Issues Omitted<a hidden class="anchor" aria-hidden="true" href="#issues-omitted">#</a></h4>
<p>If we do not want to rely on circular security, we have to resort to limited
multipliation depth, and the key length will be linear to the depth.</p>
<p>[BV14] presented some better noise management tricks, using a
&ldquo;sequentialization&rdquo; technique.</p>
<h3 id="secure-computation">Secure Computation<a hidden class="anchor" aria-hidden="true" href="#secure-computation">#</a></h3>
<p>In this chapter we discuss secure multiparty computation.</p>
<p>First we construct an OT scheme based on PKE with obviously sampleable PKs. This
property requires that</p>
<ol>
<li>A sampling algorithm can sample pk identically distributed to the
pk in real \(KeyGen\) algorithm</li>
<li>The sampled pk cannot have a decryption key.</li>
</ol>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2024 <a href="http://localhost:1313/">Hongrui Cui&#39;s Homepage</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>



<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
